{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import transformers\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import datetime as dt\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0,1,2,3'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "model_name_dict = {\n",
    "    \"PubMedBERT\": \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\",\n",
    "    \"biomed_roberta_base\": \"allenai/biomed_roberta_base\",\n",
    "    \"Bio_ClinicalBERT\":\"emilyalsentzer/Bio_ClinicalBERT\",\n",
    "}\n",
    "\n",
    "class Hparams:\n",
    "    def __init__(self):\n",
    "        self.random_seed = 0 # BAD:2021\n",
    "        self.data_dir = './data'\n",
    "        self.output_dir = './outputs'\n",
    "        self.batch_size = 128\n",
    "        self.token_max_length = 512\n",
    "        self.model_name = model_name_dict['PubMedBERT']\n",
    "        self.num_epochs = 5\n",
    "        self.class_1_weight = 150\n",
    "        self.initial_lr = 2e-5  # 2e-5\n",
    "        self.model_type = 'lstm_ex'  # cnn, lstm, lstm_ex\n",
    "        self.upsample_pos_n = 1\n",
    "        self.use_col = 'title_abstract'  # title, abstract, title_abstract\n",
    "        self.train_argument = True\n",
    "        self.cv_n = 5\n",
    "\n",
    "hps = Hparams()\n",
    "\n",
    "\n",
    "def seed_torch(seed:int):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(hps.random_seed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DataFrame"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "orig_df = pd.read_csv(os.path.join(hps.data_dir, 'train.csv'), index_col=0)\n",
    "submit_df = pd.read_csv(os.path.join(hps.data_dir, 'test.csv'), index_col=0)\n",
    "sample_submit_df = pd.read_csv(os.path.join(hps.data_dir, 'sample_submit.csv'), index_col=0, header=None, names=['judgement'])\n",
    "\n",
    "# 修正\n",
    "orig_df.loc[2488, 'judgement'] = 0\n",
    "orig_df.loc[7708, 'judgement'] = 0\n",
    "\n",
    "# 補完\n",
    "orig_df['abstract'].fillna('', inplace=True)\n",
    "orig_df['title_abstract'] = orig_df.title + orig_df.abstract\n",
    "\n",
    "submit_df['abstract'].fillna('', inplace=True)\n",
    "submit_df['title_abstract'] = submit_df.title + submit_df.abstract\n",
    "submit_df['judgement'] = -1\n",
    "submit_df.reset_index(inplace=True, drop=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross Validations SetUp"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_df, test_df = train_test_split(orig_df, test_size=0.2, random_state=hps.random_seed, shuffle=True, stratify=orig_df.judgement)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def get_cv_number(df, cv_n):\n",
    "\n",
    "    df['cv_id'] = 0\n",
    "\n",
    "    neg_idx = df.loc[df.judgement==0].index.tolist()\n",
    "    pos_idx = df.loc[df.judgement==1].index.tolist()\n",
    "\n",
    "    neg_idx = [list(a) for a in list(np.array_split(random.sample(neg_idx, len(neg_idx)), cv_n))]\n",
    "    pos_idx = [list(a) for a in list(np.array_split(random.sample(pos_idx, len(pos_idx)), cv_n))]\n",
    "\n",
    "    for i in range(cv_n):\n",
    "        n_id = neg_idx[i]\n",
    "        p_id = pos_idx[i]\n",
    "        df.loc[n_id, 'cv_id'] = i\n",
    "        df.loc[p_id, 'cv_id'] = i\n",
    "\n",
    "    df = df.sort_index()\n",
    "\n",
    "    for i in range(cv_n):\n",
    "        tmp_df = df.loc[df.cv_id==i]\n",
    "        print('cv_id:', i, '->  pos:', len(tmp_df.loc[tmp_df.judgement==1]), ' / neg:', len(tmp_df.loc[tmp_df.judgement==0]), ' / all:', len(tmp_df))\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = get_cv_number(train_df, cv_n=hps.cv_n)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cv_id: 0 ->  pos: 101  / neg: 4243  / all: 4344\n",
      "cv_id: 1 ->  pos: 101  / neg: 4243  / all: 4344\n",
      "cv_id: 2 ->  pos: 101  / neg: 4242  / all: 4343\n",
      "cv_id: 3 ->  pos: 101  / neg: 4242  / all: 4343\n",
      "cv_id: 4 ->  pos: 100  / neg: 4242  / all: 4342\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipykernel_309282/4072971457.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['cv_id'] = 0\n",
      "/opt/miniconda3/envs/srws/lib/python3.9/site-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hugging Face"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "base_tokenizer = transformers.AutoTokenizer.from_pretrained(hps.model_name)\n",
    "\n",
    "bert_config = transformers.AutoConfig.from_pretrained(hps.model_name)\n",
    "bert_config.output_hidden_states = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DataSet / DataLoader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, use_col='title_abstract', token_max_length=512, argument=False, upsample_pos_n=1):\n",
    "\n",
    "        if upsample_pos_n > 1:\n",
    "            df_pos = df.loc[df.judgement==1]\n",
    "            df_pos = pd.concat([df_pos for i in range(int(upsample_pos_n))], axis=0).reset_index(drop=True)\n",
    "            df_neg = df.loc[df.judgement==0]\n",
    "            self.df = pd.concat([df_pos, df_neg], axis=0).reset_index(drop=True)\n",
    "        else:\n",
    "            self.df = df\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.argument = argument\n",
    "        self.use_col = use_col\n",
    "\n",
    "    def text_argument(self, text, drop_min_seq=3, seq_sort=True):\n",
    "        seq_list = text.split('. ')\n",
    "        seq_len = len(seq_list)\n",
    "        if seq_len >= drop_min_seq:\n",
    "            orig_idx_list = list(range(0, seq_len))\n",
    "            idx_list = random.sample(orig_idx_list, random.randint(round(seq_len * 0.7), seq_len))\n",
    "            if seq_sort:\n",
    "                idx_list = sorted(idx_list)\n",
    "            insert_idx_list = random.sample(orig_idx_list, random.randint(0, seq_len//3))\n",
    "            for x in insert_idx_list:\n",
    "                idx = random.randint(0, len(idx_list))\n",
    "                idx_list.insert(idx, x)\n",
    "            seq_list = [seq_list[i] for i in idx_list]\n",
    "        text = '. '.join(seq_list)\n",
    "        return text\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        text = self.df.loc[idx, self.use_col]\n",
    "\n",
    "        if self.argument:\n",
    "            text = self.text_argument(text, drop_min_seq=3, seq_sort=True)\n",
    "\n",
    "        token = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            padding = 'max_length', max_length = hps.token_max_length, truncation = True,\n",
    "            return_attention_mask=True, return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        sample = dict(\n",
    "            input_ids=token['input_ids'][0],\n",
    "            attention_mask=token['attention_mask'][0]\n",
    "        )\n",
    "        \n",
    "        label = torch.tensor(self.df.loc[idx, 'judgement'], dtype=torch.float32)\n",
    "        return sample, label\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "class BertLstmModel(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.bert = transformers.AutoModel.from_pretrained(hps.model_name, config=bert_config)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.regressor = nn.Linear(hidden_size*2, 1)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        self.lstm.flatten_parameters()\n",
    "        out, _ = self.lstm(outputs['last_hidden_state'], None)\n",
    "        out = self.leakyrelu(out)\n",
    "        sequence_output = out[:, -1, :]\n",
    "        output = self.dropout(sequence_output)\n",
    "        logits = torch.flatten(self.regressor(output))\n",
    "        return logits"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class BertLstmExModel(nn.Module):\n",
    "    def __init__(self, hidden_size, config, use_hidden_n=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = transformers.AutoModel.from_pretrained(hps.model_name, config=bert_config)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.use_hidden_n = use_hidden_n\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.conv1d = nn.Conv1d(in_channels=self.use_hidden_n, out_channels=1, kernel_size=3, padding='same')\n",
    "        self.regressor = nn.Linear(self.hidden_size*2, 1)\n",
    "        \n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_states_list = [outputs['hidden_states'][-1*i] for i in range(1, self.use_hidden_n+1)]\n",
    "        self.lstm.flatten_parameters()\n",
    "        out_list = [\n",
    "            self.dropout(\n",
    "                self.leakyrelu(\n",
    "                    self.lstm(hidden_state, None)[0]\n",
    "                )[:, -1, :]\n",
    "            ).view(-1, 1, self.hidden_size*2)  # (batch, use_hidden_n, hidden_size*2)\n",
    "        for hidden_state in hidden_states_list]\n",
    "\n",
    "        out = torch.cat(out_list, dim=1)\n",
    "\n",
    "        out = self.dropout(self.leakyrelu(self.conv1d(out)))\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        logits = torch.flatten(self.regressor(out))\n",
    "        return logits"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Checkpoint"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "class ModelCheckpoint:\n",
    "    def __init__(self, save_dir:str, save_name:str, cv_id:int):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        self.cv_id = cv_id\n",
    "        self.save_dir = save_dir\n",
    "        self.save_name = save_name\n",
    "        self.best_loss = self.best_acc = self.best_fbeta_score = 0.0\n",
    "\n",
    "    def get_checkpoint_name(self):\n",
    "        checkpoint_name = f\"{self.save_name.replace('/', '_')}_cv{self.cv_id}.pth\"\n",
    "        checkpoint_name = os.path.join(self.save_dir, checkpoint_name)\n",
    "        return checkpoint_name\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        torch.save(model.state_dict(), self.get_checkpoint_name())\n",
    "\n",
    "    def load_checkpoint(self, model=None, manual_name=None):\n",
    "        if manual_name is None:\n",
    "            checkpoint_name = self.get_checkpoint_name()\n",
    "        else:\n",
    "            checkpoint_name = manual_name\n",
    "        print(checkpoint_name)\n",
    "        model.load_state_dict(torch.load(checkpoint_name))\n",
    "        return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fit"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def fit(dataloaders, model, optimizer, num_epochs, device, batch_size, lr_scheduler, cv_id):\n",
    "\n",
    "    seed_torch(hps.random_seed)\n",
    "\n",
    "    history = {\n",
    "        'train':{'loss':[], 'acc':[], 'fbscore':[]},\n",
    "        'val':{'loss':[], 'acc':[], 'fbscore':[]},\n",
    "        'lr':[],\n",
    "    }\n",
    "\n",
    "    checkpoint = ModelCheckpoint(save_dir='cross_validation_weights', save_name='bert_text_classification', cv_id=cv_id)\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    print(f\"Using device : {device}\")\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"【Epoch {epoch+1: 3}/{num_epochs: 3}】   LR -> \", end='')\n",
    "        for i, params in enumerate(optimizer.param_groups):\n",
    "            print(f\"Group{i}: {params['lr']:.4e}\", end=' / ')\n",
    "        print('')\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            running_fbeta_score = 0.0\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            for i, (inputs, labels) in enumerate(tqdm(dataloaders[phase])):\n",
    "                input_ids = inputs['input_ids']\n",
    "                attention_mask = inputs['attention_mask']\n",
    "                input_ids = input_ids.to(device)\n",
    "                attention_mask = attention_mask.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    logits_outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    pos_weight = torch.tensor([hps.class_1_weight for i in range(input_ids.size(0))]).to(device)\n",
    "                    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "                    loss = criterion(logits_outputs, labels)\n",
    "\n",
    "                    outputs = torch.sigmoid(logits_outputs)\n",
    "                    preds = torch.where(outputs >= 0.5, 1, 0)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        lr_scheduler.step()\n",
    "\n",
    "                running_loss += loss.item() * input_ids.size(0)\n",
    "                running_corrects += torch.sum(preds == labels)\n",
    "                running_fbeta_score += fbeta_score(labels.to('cpu').detach().numpy(), preds.to('cpu').detach().numpy(), beta=7.0, zero_division=0) * input_ids.size(0)    \n",
    "\n",
    "                if phase == 'train':\n",
    "                    if i % 10 == 9:\n",
    "                        total_num = float((i * batch_size) + input_ids.size(0))\n",
    "                        print(f\"{i+1: 4}/{len(dataloaders[phase]): 4}  <{phase}> Loss:{(running_loss/total_num):.4f}  Acc:{(running_corrects/total_num):.4f}  fbScore:{(running_fbeta_score/total_num):.4f}   LR -> \", end='')\n",
    "                        for i, params in enumerate(optimizer.param_groups):\n",
    "                            print(f\"Group{i}: {params['lr']:.4e}\", end=' / ')\n",
    "                            if isinstance(optimizer.param_groups[0]['lr'], float):\n",
    "                                history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "                            else:\n",
    "                                history['lr'].append(optimizer.param_groups[0]['lr'].item())\n",
    "                        print('')\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n",
    "            epoch_fbscore = running_fbeta_score / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            print(f\"<{phase}> Loss:{epoch_loss:.4f}  Acc:{epoch_acc:.4f}  fbScore:{epoch_fbscore:.4f}\")\n",
    "\n",
    "            history[phase]['loss'].append(epoch_loss)\n",
    "            history[phase]['acc'].append(epoch_acc.item())\n",
    "            history[phase]['fbscore'].append(epoch_fbscore)\n",
    "\n",
    "\n",
    "            if phase == 'val' and epoch_fbscore > checkpoint.best_fbeta_score:\n",
    "                print(f\"Checkpoints have been updated to the epoch {epoch+1} weights.\")\n",
    "                checkpoint.best_loss = epoch_loss\n",
    "                checkpoint.best_acc = epoch_acc\n",
    "                checkpoint.best_fbeta_score = epoch_fbscore\n",
    "                checkpoint.best_epoch = epoch+1\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print('-' * 150)\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    checkpoint.save_checkpoint(model)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return model, history"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def inference(model, dataloader, device, evaluate=True):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    running_fbeta_score = 0.0\n",
    "\n",
    "    preds_labels_dict = dict(preds = np.empty(0), labels = np.empty(0))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(tqdm(dataloader)):\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits_outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            if evaluate:\n",
    "                pos_weight = torch.tensor([hps.class_1_weight for i in range(input_ids.size(0))]).to(device)\n",
    "                criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "                loss = criterion(logits_outputs, labels)\n",
    "\n",
    "            outputs = torch.sigmoid(logits_outputs)\n",
    "            preds = torch.where(outputs >= 0.5, 1, 0)\n",
    "            \n",
    "            if evaluate:\n",
    "                running_loss += loss.item() * input_ids.size(0)\n",
    "                running_corrects += torch.sum(preds == labels)\n",
    "                running_fbeta_score += fbeta_score(labels.to('cpu').detach().numpy(), preds.to('cpu').detach().numpy(), beta=7.0, zero_division=0) * input_ids.size(0)\n",
    "\n",
    "            preds_labels_dict['preds']  = np.hstack([preds_labels_dict['preds'], preds.to('cpu').detach().numpy().copy()])\n",
    "            preds_labels_dict['labels']  = np.hstack([preds_labels_dict['labels'], labels.to('cpu').detach().numpy().copy()])\n",
    "    \n",
    "    if evaluate:\n",
    "        loss = running_loss / len(dataloader.dataset)\n",
    "        acc = running_corrects / len(dataloader.dataset)\n",
    "        fbscore = running_fbeta_score / len(dataloader.dataset)\n",
    "        print(f\"Loss:{loss:.4f}  Acc:{acc:.4f}  fbScore:{fbscore:.4f}\")\n",
    "    return preds_labels_dict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CrossValidation Loop"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def model_setup(model, dataloaders):\n",
    "\n",
    "    optimizer = optim.AdamW(\n",
    "        params=[\n",
    "            {'params': model.bert.embeddings.parameters(), 'lr': 1e-5},\n",
    "            {'params': model.bert.encoder.parameters(), 'lr': 2e-5},\n",
    "            {'params': model.bert.pooler.parameters(), 'lr': 3e-5},\n",
    "            {'params': model.lstm.parameters(), 'lr': 5e-4},\n",
    "            {'params': model.conv1d.parameters(), 'lr': 5e-4},\n",
    "            {'params': model.regressor.parameters(), 'lr': 5e-4}\n",
    "        ]\n",
    "    )\n",
    "    num_warmup_steps = round(hps.num_epochs * len(dataloaders['train']) * 0.1)\n",
    "    num_training_steps = round(hps.num_epochs * len(dataloaders['train']))\n",
    "    print(f\"InitLR:{hps.initial_lr} / num_warmup_steps:{num_warmup_steps} / num_training_steps:{num_training_steps}\")\n",
    "    lr_scheduler = transformers.get_linear_schedule_with_warmup(optimizer=optimizer, num_warmup_steps=num_warmup_steps, \n",
    "                                                                num_training_steps=num_training_steps, last_epoch=-1)\n",
    "\n",
    "    return (optimizer, lr_scheduler)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def cross_validation(cv_n, orig_df, test_df):\n",
    "\n",
    "    logs = {\n",
    "        'fit_history':[],\n",
    "        'test_preds_labels':[],\n",
    "        'test_fb_score':[],\n",
    "    }\n",
    "\n",
    "    for i in range(cv_n):\n",
    "        print('\\033[32m' + f\"Cross-validation loop : {i+1}/{cv_n}\" + '\\033[0m')\n",
    "\n",
    "        # DataFrame\n",
    "        train_df = orig_df.loc[orig_df.cv_id != i].copy().reset_index(drop=True)\n",
    "        valid_df = orig_df.loc[orig_df.cv_id == i].copy().reset_index(drop=True)\n",
    "        test_df = test_df.reset_index(drop=True)\n",
    "        print(f\"Train  ->  label_1:{train_df.judgement.sum()} / all:{train_df.judgement.count()}   ({train_df.judgement.sum() / train_df.judgement.count() * 100:.3f}%)\")\n",
    "        print(f\"Valid  ->  label_1:{valid_df.judgement.sum()} / all:{valid_df.judgement.count()}   ({valid_df.judgement.sum() / valid_df.judgement.count() * 100:.3f}%)\")\n",
    "\n",
    "        # Dataset / Dataloader\n",
    "        phase_param = {\n",
    "            \"df\":{'train': train_df, 'val': valid_df, 'test': test_df, 'submit': submit_df},\n",
    "            \"argument\":{'train': hps.train_argument, 'val': False, 'test': False, 'submit': False},\n",
    "            \"batch_size\":{'train':hps.batch_size, 'val':hps.batch_size*4, 'test':hps.batch_size*4, 'submit': hps.batch_size*4},\n",
    "            \"shuffle\":{'train': True, 'val': False, 'test': False, 'submit': False},\n",
    "            \"upsample_pos_n\":{'train': hps.upsample_pos_n, 'val': 1, 'test': 1, 'submit': 1},\n",
    "        }\n",
    "        datasets = {phase:TextClassificationDataset(df=phase_param['df'][phase], tokenizer=base_tokenizer, use_col=hps.use_col,\\\n",
    "                                                    token_max_length=hps.token_max_length, argument=phase_param['argument'][phase],\\\n",
    "                                                    upsample_pos_n=phase_param['upsample_pos_n'][phase]) for phase in ['train', 'val', 'test', 'submit']}\n",
    "        dataloaders = {phase: DataLoader(datasets[phase], batch_size=phase_param['batch_size'][phase], \\\n",
    "                                        shuffle=phase_param['shuffle'][phase]) for phase in ['train', 'val', 'test', 'submit']}\n",
    "        \n",
    "        # Model / Optimizer\n",
    "        if hps.model_type == 'lstm':\n",
    "            print(f\"Choosed BertLstmModel\")\n",
    "            model = BertLstmModel(hidden_size=bert_config.hidden_size)\n",
    "        elif hps.model_type == 'lstm_ex':\n",
    "            print(f\"Choosed BertLstmExModel\")\n",
    "            model = BertLstmExModel(hidden_size=bert_config.hidden_size, config=bert_config, use_hidden_n=4)\n",
    "\n",
    "        optimizer, lr_scheduler = model_setup(model, dataloaders)\n",
    "        model = model.to(device)\n",
    "        device_num = torch.cuda.device_count()\n",
    "        if device_num > 1:\n",
    "            print(f\"Use {device_num} GPUs\")\n",
    "            model = nn.DataParallel(model)\n",
    "\n",
    "        # Training / Validation\n",
    "        model, fit_history = fit(dataloaders=dataloaders, model=model, optimizer=optimizer, num_epochs=hps.num_epochs, \n",
    "                             device=device, batch_size=hps.batch_size, lr_scheduler=lr_scheduler, cv_id=i)\n",
    "\n",
    "        # Evaluate\n",
    "        print(f\"Evaluate Test Dataset\")\n",
    "        test_preds_labels_dict = inference(model, dataloader=dataloaders['test'], device=device)\n",
    "        test_fb_score = fbeta_score(y_true=test_preds_labels_dict['labels'], y_pred=test_preds_labels_dict['preds'], beta=7.0)\n",
    "        print(f\"fb_score : {test_fb_score}\")   \n",
    "\n",
    "        logs['fit_history'].append(fit_history)\n",
    "        logs['test_preds_labels'].append(test_preds_labels_dict)\n",
    "        logs['test_fb_score'].append(test_fb_score)\n",
    "\n",
    "        del model, datasets, dataloaders\n",
    "        torch.cuda.empty_cache()\n",
    "        print()\n",
    "\n",
    "    return logs\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "logs = cross_validation(cv_n=hps.cv_n, orig_df=train_df, test_df=test_df)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[32mCross-validation loop : 1/5\u001b[0m\n",
      "Train  ->  label_1:403 / all:17372   (2.320%)\n",
      "Valid  ->  label_1:101 / all:4344   (2.325%)\n",
      "Choosed BertLstmExModel\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "InitLR:2e-05 / num_warmup_steps:68 / num_training_steps:680\n",
      "Use 4 GPUs\n",
      "Using device : cuda\n",
      "【Epoch   1/  5】   LR -> Group0: 0.0000e+00 / Group1: 0.0000e+00 / Group2: 0.0000e+00 / Group3: 0.0000e+00 / Group4: 0.0000e+00 / Group5: 0.0000e+00 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51bd52e094a146c99c7cc094f1a85416"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:2.7276  Acc:0.0563  fbScore:0.4855   LR -> Group0: 1.4706e-06 / Group1: 2.9412e-06 / Group2: 4.4118e-06 / Group3: 7.3529e-05 / Group4: 7.3529e-05 / Group5: 7.3529e-05 / \n",
      "  20/ 136  <train> Loss:2.4087  Acc:0.0363  fbScore:0.4355   LR -> Group0: 2.9412e-06 / Group1: 5.8824e-06 / Group2: 8.8235e-06 / Group3: 1.4706e-04 / Group4: 1.4706e-04 / Group5: 1.4706e-04 / \n",
      "  30/ 136  <train> Loss:2.4440  Acc:0.0333  fbScore:0.4762   LR -> Group0: 4.4118e-06 / Group1: 8.8235e-06 / Group2: 1.3235e-05 / Group3: 2.2059e-04 / Group4: 2.2059e-04 / Group5: 2.2059e-04 / \n",
      "  40/ 136  <train> Loss:2.4408  Acc:0.0311  fbScore:0.4866   LR -> Group0: 5.8824e-06 / Group1: 1.1765e-05 / Group2: 1.7647e-05 / Group3: 2.9412e-04 / Group4: 2.9412e-04 / Group5: 2.9412e-04 / \n",
      "  50/ 136  <train> Loss:2.3803  Acc:0.0287  fbScore:0.4839   LR -> Group0: 7.3529e-06 / Group1: 1.4706e-05 / Group2: 2.2059e-05 / Group3: 3.6765e-04 / Group4: 3.6765e-04 / Group5: 3.6765e-04 / \n",
      "  60/ 136  <train> Loss:2.3383  Acc:0.0281  fbScore:0.4919   LR -> Group0: 8.8235e-06 / Group1: 1.7647e-05 / Group2: 2.6471e-05 / Group3: 4.4118e-04 / Group4: 4.4118e-04 / Group5: 4.4118e-04 / \n",
      "  70/ 136  <train> Loss:2.2571  Acc:0.0552  fbScore:0.5028   LR -> Group0: 9.9673e-06 / Group1: 1.9935e-05 / Group2: 2.9902e-05 / Group3: 4.9837e-04 / Group4: 4.9837e-04 / Group5: 4.9837e-04 / \n",
      "  80/ 136  <train> Loss:2.1707  Acc:0.1174  fbScore:0.5279   LR -> Group0: 9.8039e-06 / Group1: 1.9608e-05 / Group2: 2.9412e-05 / Group3: 4.9020e-04 / Group4: 4.9020e-04 / Group5: 4.9020e-04 / \n",
      "  90/ 136  <train> Loss:2.0828  Acc:0.1681  fbScore:0.5482   LR -> Group0: 9.6405e-06 / Group1: 1.9281e-05 / Group2: 2.8922e-05 / Group3: 4.8203e-04 / Group4: 4.8203e-04 / Group5: 4.8203e-04 / \n",
      " 100/ 136  <train> Loss:1.9957  Acc:0.2226  fbScore:0.5602   LR -> Group0: 9.4771e-06 / Group1: 1.8954e-05 / Group2: 2.8431e-05 / Group3: 4.7386e-04 / Group4: 4.7386e-04 / Group5: 4.7386e-04 / \n",
      " 110/ 136  <train> Loss:1.9028  Acc:0.2700  fbScore:0.5765   LR -> Group0: 9.3137e-06 / Group1: 1.8627e-05 / Group2: 2.7941e-05 / Group3: 4.6569e-04 / Group4: 4.6569e-04 / Group5: 4.6569e-04 / \n",
      " 120/ 136  <train> Loss:1.8404  Acc:0.3167  fbScore:0.5920   LR -> Group0: 9.1503e-06 / Group1: 1.8301e-05 / Group2: 2.7451e-05 / Group3: 4.5752e-04 / Group4: 4.5752e-04 / Group5: 4.5752e-04 / \n",
      " 130/ 136  <train> Loss:1.7607  Acc:0.3523  fbScore:0.5971   LR -> Group0: 8.9869e-06 / Group1: 1.7974e-05 / Group2: 2.6961e-05 / Group3: 4.4935e-04 / Group4: 4.4935e-04 / Group5: 4.4935e-04 / \n",
      "<train> Loss:1.7214  Acc:0.3762  fbScore:0.6102\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "096daa46ba424952a3ba2af0adeb940b"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.7218  Acc:0.8557  fbScore:0.8562\n",
      "Checkpoints have been updated to the epoch 1 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   2/  5】   LR -> Group0: 8.8889e-06 / Group1: 1.7778e-05 / Group2: 2.6667e-05 / Group3: 4.4444e-04 / Group4: 4.4444e-04 / Group5: 4.4444e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24269e2c05ec469c99bca5d5abd47905"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:0.7792  Acc:0.7492  fbScore:0.7861   LR -> Group0: 8.7255e-06 / Group1: 1.7451e-05 / Group2: 2.6176e-05 / Group3: 4.3627e-04 / Group4: 4.3627e-04 / Group5: 4.3627e-04 / \n",
      "  20/ 136  <train> Loss:0.9310  Acc:0.7781  fbScore:0.7051   LR -> Group0: 8.5621e-06 / Group1: 1.7124e-05 / Group2: 2.5686e-05 / Group3: 4.2810e-04 / Group4: 4.2810e-04 / Group5: 4.2810e-04 / \n",
      "  30/ 136  <train> Loss:0.8893  Acc:0.7576  fbScore:0.7276   LR -> Group0: 8.3987e-06 / Group1: 1.6797e-05 / Group2: 2.5196e-05 / Group3: 4.1993e-04 / Group4: 4.1993e-04 / Group5: 4.1993e-04 / \n",
      "  40/ 136  <train> Loss:0.8160  Acc:0.7906  fbScore:0.7682   LR -> Group0: 8.2353e-06 / Group1: 1.6471e-05 / Group2: 2.4706e-05 / Group3: 4.1176e-04 / Group4: 4.1176e-04 / Group5: 4.1176e-04 / \n",
      "  50/ 136  <train> Loss:0.7657  Acc:0.8078  fbScore:0.7532   LR -> Group0: 8.0719e-06 / Group1: 1.6144e-05 / Group2: 2.4216e-05 / Group3: 4.0359e-04 / Group4: 4.0359e-04 / Group5: 4.0359e-04 / \n",
      "  60/ 136  <train> Loss:0.7161  Acc:0.8182  fbScore:0.7491   LR -> Group0: 7.9085e-06 / Group1: 1.5817e-05 / Group2: 2.3725e-05 / Group3: 3.9542e-04 / Group4: 3.9542e-04 / Group5: 3.9542e-04 / \n",
      "  70/ 136  <train> Loss:0.8346  Acc:0.8163  fbScore:0.7487   LR -> Group0: 7.7451e-06 / Group1: 1.5490e-05 / Group2: 2.3235e-05 / Group3: 3.8725e-04 / Group4: 3.8725e-04 / Group5: 3.8725e-04 / \n",
      "  80/ 136  <train> Loss:0.8289  Acc:0.8071  fbScore:0.7466   LR -> Group0: 7.5817e-06 / Group1: 1.5163e-05 / Group2: 2.2745e-05 / Group3: 3.7908e-04 / Group4: 3.7908e-04 / Group5: 3.7908e-04 / \n",
      "  90/ 136  <train> Loss:0.8040  Acc:0.8202  fbScore:0.7541   LR -> Group0: 7.4183e-06 / Group1: 1.4837e-05 / Group2: 2.2255e-05 / Group3: 3.7092e-04 / Group4: 3.7092e-04 / Group5: 3.7092e-04 / \n",
      " 100/ 136  <train> Loss:0.7893  Acc:0.8220  fbScore:0.7594   LR -> Group0: 7.2549e-06 / Group1: 1.4510e-05 / Group2: 2.1765e-05 / Group3: 3.6275e-04 / Group4: 3.6275e-04 / Group5: 3.6275e-04 / \n",
      " 110/ 136  <train> Loss:0.7583  Acc:0.8255  fbScore:0.7690   LR -> Group0: 7.0915e-06 / Group1: 1.4183e-05 / Group2: 2.1275e-05 / Group3: 3.5458e-04 / Group4: 3.5458e-04 / Group5: 3.5458e-04 / \n",
      " 120/ 136  <train> Loss:0.7789  Acc:0.8337  fbScore:0.7790   LR -> Group0: 6.9281e-06 / Group1: 1.3856e-05 / Group2: 2.0784e-05 / Group3: 3.4641e-04 / Group4: 3.4641e-04 / Group5: 3.4641e-04 / \n",
      " 130/ 136  <train> Loss:0.7616  Acc:0.8328  fbScore:0.7774   LR -> Group0: 6.7647e-06 / Group1: 1.3529e-05 / Group2: 2.0294e-05 / Group3: 3.3824e-04 / Group4: 3.3824e-04 / Group5: 3.3824e-04 / \n",
      "<train> Loss:0.7517  Acc:0.8326  fbScore:0.7748\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9087f52338ef4c00a46ae8ac9c3ac38e"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.5727  Acc:0.8725  fbScore:0.8783\n",
      "Checkpoints have been updated to the epoch 2 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   3/  5】   LR -> Group0: 6.6667e-06 / Group1: 1.3333e-05 / Group2: 2.0000e-05 / Group3: 3.3333e-04 / Group4: 3.3333e-04 / Group5: 3.3333e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0367324cff1246958786ff9014728e2b"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:0.3775  Acc:0.8961  fbScore:0.8870   LR -> Group0: 6.5033e-06 / Group1: 1.3007e-05 / Group2: 1.9510e-05 / Group3: 3.2516e-04 / Group4: 3.2516e-04 / Group5: 3.2516e-04 / \n",
      "  20/ 136  <train> Loss:0.4886  Acc:0.9094  fbScore:0.8784   LR -> Group0: 6.3399e-06 / Group1: 1.2680e-05 / Group2: 1.9020e-05 / Group3: 3.1699e-04 / Group4: 3.1699e-04 / Group5: 3.1699e-04 / \n",
      "  30/ 136  <train> Loss:0.5267  Acc:0.8771  fbScore:0.8585   LR -> Group0: 6.1765e-06 / Group1: 1.2353e-05 / Group2: 1.8529e-05 / Group3: 3.0882e-04 / Group4: 3.0882e-04 / Group5: 3.0882e-04 / \n",
      "  40/ 136  <train> Loss:0.5161  Acc:0.8682  fbScore:0.8625   LR -> Group0: 6.0131e-06 / Group1: 1.2026e-05 / Group2: 1.8039e-05 / Group3: 3.0065e-04 / Group4: 3.0065e-04 / Group5: 3.0065e-04 / \n",
      "  50/ 136  <train> Loss:0.5246  Acc:0.8733  fbScore:0.8650   LR -> Group0: 5.8497e-06 / Group1: 1.1699e-05 / Group2: 1.7549e-05 / Group3: 2.9248e-04 / Group4: 2.9248e-04 / Group5: 2.9248e-04 / \n",
      "  60/ 136  <train> Loss:0.5062  Acc:0.8764  fbScore:0.8722   LR -> Group0: 5.6863e-06 / Group1: 1.1373e-05 / Group2: 1.7059e-05 / Group3: 2.8431e-04 / Group4: 2.8431e-04 / Group5: 2.8431e-04 / \n",
      "  70/ 136  <train> Loss:0.4994  Acc:0.8794  fbScore:0.8583   LR -> Group0: 5.5229e-06 / Group1: 1.1046e-05 / Group2: 1.6569e-05 / Group3: 2.7614e-04 / Group4: 2.7614e-04 / Group5: 2.7614e-04 / \n",
      "  80/ 136  <train> Loss:0.4672  Acc:0.8847  fbScore:0.8515   LR -> Group0: 5.3595e-06 / Group1: 1.0719e-05 / Group2: 1.6078e-05 / Group3: 2.6797e-04 / Group4: 2.6797e-04 / Group5: 2.6797e-04 / \n",
      "  90/ 136  <train> Loss:0.4561  Acc:0.8895  fbScore:0.8506   LR -> Group0: 5.1961e-06 / Group1: 1.0392e-05 / Group2: 1.5588e-05 / Group3: 2.5980e-04 / Group4: 2.5980e-04 / Group5: 2.5980e-04 / \n",
      " 100/ 136  <train> Loss:0.4482  Acc:0.8911  fbScore:0.8564   LR -> Group0: 5.0327e-06 / Group1: 1.0065e-05 / Group2: 1.5098e-05 / Group3: 2.5163e-04 / Group4: 2.5163e-04 / Group5: 2.5163e-04 / \n",
      " 110/ 136  <train> Loss:0.4370  Acc:0.8920  fbScore:0.8606   LR -> Group0: 4.8693e-06 / Group1: 9.7386e-06 / Group2: 1.4608e-05 / Group3: 2.4346e-04 / Group4: 2.4346e-04 / Group5: 2.4346e-04 / \n",
      " 120/ 136  <train> Loss:0.4437  Acc:0.8949  fbScore:0.8624   LR -> Group0: 4.7059e-06 / Group1: 9.4118e-06 / Group2: 1.4118e-05 / Group3: 2.3529e-04 / Group4: 2.3529e-04 / Group5: 2.3529e-04 / \n",
      " 130/ 136  <train> Loss:0.4401  Acc:0.8956  fbScore:0.8608   LR -> Group0: 4.5425e-06 / Group1: 9.0850e-06 / Group2: 1.3627e-05 / Group3: 2.2712e-04 / Group4: 2.2712e-04 / Group5: 2.2712e-04 / \n",
      "<train> Loss:0.4366  Acc:0.8955  fbScore:0.8611\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5337f6f0fc11456da1d0d285e9bc17c7"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.6640  Acc:0.8994  fbScore:0.8888\n",
      "Checkpoints have been updated to the epoch 3 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   4/  5】   LR -> Group0: 4.4444e-06 / Group1: 8.8889e-06 / Group2: 1.3333e-05 / Group3: 2.2222e-04 / Group4: 2.2222e-04 / Group5: 2.2222e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8a5c348ab424ab2b1ae85fd31284b1b"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:0.2858  Acc:0.9094  fbScore:0.8691   LR -> Group0: 4.2810e-06 / Group1: 8.5621e-06 / Group2: 1.2843e-05 / Group3: 2.1405e-04 / Group4: 2.1405e-04 / Group5: 2.1405e-04 / \n",
      "  20/ 136  <train> Loss:0.2882  Acc:0.9309  fbScore:0.9122   LR -> Group0: 4.1176e-06 / Group1: 8.2353e-06 / Group2: 1.2353e-05 / Group3: 2.0588e-04 / Group4: 2.0588e-04 / Group5: 2.0588e-04 / \n",
      "  30/ 136  <train> Loss:0.2987  Acc:0.9354  fbScore:0.9257   LR -> Group0: 3.9542e-06 / Group1: 7.9085e-06 / Group2: 1.1863e-05 / Group3: 1.9771e-04 / Group4: 1.9771e-04 / Group5: 1.9771e-04 / \n",
      "  40/ 136  <train> Loss:0.2743  Acc:0.9365  fbScore:0.9275   LR -> Group0: 3.7908e-06 / Group1: 7.5817e-06 / Group2: 1.1373e-05 / Group3: 1.8954e-04 / Group4: 1.8954e-04 / Group5: 1.8954e-04 / \n",
      "  50/ 136  <train> Loss:0.2568  Acc:0.9397  fbScore:0.8553   LR -> Group0: 3.6275e-06 / Group1: 7.2549e-06 / Group2: 1.0882e-05 / Group3: 1.8137e-04 / Group4: 1.8137e-04 / Group5: 1.8137e-04 / \n",
      "  60/ 136  <train> Loss:0.2489  Acc:0.9427  fbScore:0.8552   LR -> Group0: 3.4641e-06 / Group1: 6.9281e-06 / Group2: 1.0392e-05 / Group3: 1.7320e-04 / Group4: 1.7320e-04 / Group5: 1.7320e-04 / \n",
      "  70/ 136  <train> Loss:0.2643  Acc:0.9455  fbScore:0.8684   LR -> Group0: 3.3007e-06 / Group1: 6.6013e-06 / Group2: 9.9020e-06 / Group3: 1.6503e-04 / Group4: 1.6503e-04 / Group5: 1.6503e-04 / \n",
      "  80/ 136  <train> Loss:0.2620  Acc:0.9446  fbScore:0.8784   LR -> Group0: 3.1373e-06 / Group1: 6.2745e-06 / Group2: 9.4118e-06 / Group3: 1.5686e-04 / Group4: 1.5686e-04 / Group5: 1.5686e-04 / \n",
      "  90/ 136  <train> Loss:0.2706  Acc:0.9424  fbScore:0.8858   LR -> Group0: 2.9739e-06 / Group1: 5.9477e-06 / Group2: 8.9216e-06 / Group3: 1.4869e-04 / Group4: 1.4869e-04 / Group5: 1.4869e-04 / \n",
      " 100/ 136  <train> Loss:0.2735  Acc:0.9407  fbScore:0.8904   LR -> Group0: 2.8105e-06 / Group1: 5.6209e-06 / Group2: 8.4314e-06 / Group3: 1.4052e-04 / Group4: 1.4052e-04 / Group5: 1.4052e-04 / \n",
      " 110/ 136  <train> Loss:0.2764  Acc:0.9396  fbScore:0.8938   LR -> Group0: 2.6471e-06 / Group1: 5.2941e-06 / Group2: 7.9412e-06 / Group3: 1.3235e-04 / Group4: 1.3235e-04 / Group5: 1.3235e-04 / \n",
      " 120/ 136  <train> Loss:0.3057  Acc:0.9392  fbScore:0.8911   LR -> Group0: 2.4837e-06 / Group1: 4.9673e-06 / Group2: 7.4510e-06 / Group3: 1.2418e-04 / Group4: 1.2418e-04 / Group5: 1.2418e-04 / \n",
      " 130/ 136  <train> Loss:0.3081  Acc:0.9359  fbScore:0.8905   LR -> Group0: 2.3203e-06 / Group1: 4.6405e-06 / Group2: 6.9608e-06 / Group3: 1.1601e-04 / Group4: 1.1601e-04 / Group5: 1.1601e-04 / \n",
      "<train> Loss:0.3107  Acc:0.9347  fbScore:0.8912\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e8f27c806f84418a1d232aa6f718138"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.6793  Acc:0.8877  fbScore:0.8795\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   5/  5】   LR -> Group0: 2.2222e-06 / Group1: 4.4444e-06 / Group2: 6.6667e-06 / Group3: 1.1111e-04 / Group4: 1.1111e-04 / Group5: 1.1111e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "addf22d38cf540b49da0b9d9efd52456"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:0.3026  Acc:0.9094  fbScore:0.8182   LR -> Group0: 2.0588e-06 / Group1: 4.1176e-06 / Group2: 6.1765e-06 / Group3: 1.0294e-04 / Group4: 1.0294e-04 / Group5: 1.0294e-04 / \n",
      "  20/ 136  <train> Loss:0.2977  Acc:0.9176  fbScore:0.8688   LR -> Group0: 1.8954e-06 / Group1: 3.7908e-06 / Group2: 5.6863e-06 / Group3: 9.4771e-05 / Group4: 9.4771e-05 / Group5: 9.4771e-05 / \n",
      "  30/ 136  <train> Loss:0.3122  Acc:0.9216  fbScore:0.8872   LR -> Group0: 1.7320e-06 / Group1: 3.4641e-06 / Group2: 5.1961e-06 / Group3: 8.6601e-05 / Group4: 8.6601e-05 / Group5: 8.6601e-05 / \n",
      "  40/ 136  <train> Loss:0.3109  Acc:0.9215  fbScore:0.8966   LR -> Group0: 1.5686e-06 / Group1: 3.1373e-06 / Group2: 4.7059e-06 / Group3: 7.8431e-05 / Group4: 7.8431e-05 / Group5: 7.8431e-05 / \n",
      "  50/ 136  <train> Loss:0.2966  Acc:0.9248  fbScore:0.9057   LR -> Group0: 1.4052e-06 / Group1: 2.8105e-06 / Group2: 4.2157e-06 / Group3: 7.0261e-05 / Group4: 7.0261e-05 / Group5: 7.0261e-05 / \n",
      "  60/ 136  <train> Loss:0.2807  Acc:0.9283  fbScore:0.9101   LR -> Group0: 1.2418e-06 / Group1: 2.4837e-06 / Group2: 3.7255e-06 / Group3: 6.2092e-05 / Group4: 6.2092e-05 / Group5: 6.2092e-05 / \n",
      "  70/ 136  <train> Loss:0.2741  Acc:0.9299  fbScore:0.9167   LR -> Group0: 1.0784e-06 / Group1: 2.1569e-06 / Group2: 3.2353e-06 / Group3: 5.3922e-05 / Group4: 5.3922e-05 / Group5: 5.3922e-05 / \n",
      "  80/ 136  <train> Loss:0.2684  Acc:0.9322  fbScore:0.9221   LR -> Group0: 9.1503e-07 / Group1: 1.8301e-06 / Group2: 2.7451e-06 / Group3: 4.5752e-05 / Group4: 4.5752e-05 / Group5: 4.5752e-05 / \n",
      "  90/ 136  <train> Loss:0.2610  Acc:0.9331  fbScore:0.9226   LR -> Group0: 7.5163e-07 / Group1: 1.5033e-06 / Group2: 2.2549e-06 / Group3: 3.7582e-05 / Group4: 3.7582e-05 / Group5: 3.7582e-05 / \n",
      " 100/ 136  <train> Loss:0.2600  Acc:0.9347  fbScore:0.9240   LR -> Group0: 5.8824e-07 / Group1: 1.1765e-06 / Group2: 1.7647e-06 / Group3: 2.9412e-05 / Group4: 2.9412e-05 / Group5: 2.9412e-05 / \n",
      " 110/ 136  <train> Loss:0.2578  Acc:0.9355  fbScore:0.9254   LR -> Group0: 4.2484e-07 / Group1: 8.4967e-07 / Group2: 1.2745e-06 / Group3: 2.1242e-05 / Group4: 2.1242e-05 / Group5: 2.1242e-05 / \n",
      " 120/ 136  <train> Loss:0.2527  Acc:0.9367  fbScore:0.9270   LR -> Group0: 2.6144e-07 / Group1: 5.2288e-07 / Group2: 7.8431e-07 / Group3: 1.3072e-05 / Group4: 1.3072e-05 / Group5: 1.3072e-05 / \n",
      " 130/ 136  <train> Loss:0.2487  Acc:0.9375  fbScore:0.9293   LR -> Group0: 9.8039e-08 / Group1: 1.9608e-07 / Group2: 2.9412e-07 / Group3: 4.9020e-06 / Group4: 4.9020e-06 / Group5: 4.9020e-06 / \n",
      "<train> Loss:0.2441  Acc:0.9384  fbScore:0.9299\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59e15b6beb0c4b62bb3b7e03296badc8"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.7810  Acc:0.9466  fbScore:0.9166\n",
      "Checkpoints have been updated to the epoch 5 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Evaluate Test Dataset\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba93ea71588048889a035f702fe32a45"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss:0.7331  Acc:0.9440  fbScore:0.9039\n",
      "fb_score : 0.9028831562974203\n",
      "\n",
      "\u001b[32mCross-validation loop : 2/5\u001b[0m\n",
      "Train  ->  label_1:403 / all:17372   (2.320%)\n",
      "Valid  ->  label_1:101 / all:4344   (2.325%)\n",
      "Choosed BertLstmExModel\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "InitLR:2e-05 / num_warmup_steps:68 / num_training_steps:680\n",
      "Use 4 GPUs\n",
      "Using device : cuda\n",
      "【Epoch   1/  5】   LR -> Group0: 0.0000e+00 / Group1: 0.0000e+00 / Group2: 0.0000e+00 / Group3: 0.0000e+00 / Group4: 0.0000e+00 / Group5: 0.0000e+00 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2eb1398c6f44705b0015cf027bf28a6"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:3.2418  Acc:0.0250  fbScore:0.4800   LR -> Group0: 1.4706e-06 / Group1: 2.9412e-06 / Group2: 4.4118e-06 / Group3: 7.3529e-05 / Group4: 7.3529e-05 / Group5: 7.3529e-05 / \n",
      "  20/ 136  <train> Loss:3.2798  Acc:0.0254  fbScore:0.5135   LR -> Group0: 2.9412e-06 / Group1: 5.8824e-06 / Group2: 8.8235e-06 / Group3: 1.4706e-04 / Group4: 1.4706e-04 / Group5: 1.4706e-04 / \n",
      "  30/ 136  <train> Loss:3.1058  Acc:0.0237  fbScore:0.4959   LR -> Group0: 4.4118e-06 / Group1: 8.8235e-06 / Group2: 1.3235e-05 / Group3: 2.2059e-04 / Group4: 2.2059e-04 / Group5: 2.2059e-04 / \n",
      "  40/ 136  <train> Loss:3.1136  Acc:0.0238  fbScore:0.4986   LR -> Group0: 5.8824e-06 / Group1: 1.1765e-05 / Group2: 1.7647e-05 / Group3: 2.9412e-04 / Group4: 2.9412e-04 / Group5: 2.9412e-04 / \n",
      "  50/ 136  <train> Loss:3.0183  Acc:0.0230  fbScore:0.4925   LR -> Group0: 7.3529e-06 / Group1: 1.4706e-05 / Group2: 2.2059e-05 / Group3: 3.6765e-04 / Group4: 3.6765e-04 / Group5: 3.6765e-04 / \n",
      "  60/ 136  <train> Loss:2.9867  Acc:0.0229  fbScore:0.4923   LR -> Group0: 8.8235e-06 / Group1: 1.7647e-05 / Group2: 2.6471e-05 / Group3: 4.4118e-04 / Group4: 4.4118e-04 / Group5: 4.4118e-04 / \n",
      "  70/ 136  <train> Loss:2.9532  Acc:0.0231  fbScore:0.4842   LR -> Group0: 9.9673e-06 / Group1: 1.9935e-05 / Group2: 2.9902e-05 / Group3: 4.9837e-04 / Group4: 4.9837e-04 / Group5: 4.9837e-04 / \n",
      "  80/ 136  <train> Loss:2.9410  Acc:0.0229  fbScore:0.4806   LR -> Group0: 9.8039e-06 / Group1: 1.9608e-05 / Group2: 2.9412e-05 / Group3: 4.9020e-04 / Group4: 4.9020e-04 / Group5: 4.9020e-04 / \n",
      "  90/ 136  <train> Loss:2.9264  Acc:0.0229  fbScore:0.4838   LR -> Group0: 9.6405e-06 / Group1: 1.9281e-05 / Group2: 2.8922e-05 / Group3: 4.8203e-04 / Group4: 4.8203e-04 / Group5: 4.8203e-04 / \n",
      " 100/ 136  <train> Loss:2.9185  Acc:0.0234  fbScore:0.4923   LR -> Group0: 9.4771e-06 / Group1: 1.8954e-05 / Group2: 2.8431e-05 / Group3: 4.7386e-04 / Group4: 4.7386e-04 / Group5: 4.7386e-04 / \n",
      " 110/ 136  <train> Loss:2.8701  Acc:0.0239  fbScore:0.4997   LR -> Group0: 9.3137e-06 / Group1: 1.8627e-05 / Group2: 2.7941e-05 / Group3: 4.6569e-04 / Group4: 4.6569e-04 / Group5: 4.6569e-04 / \n",
      " 120/ 136  <train> Loss:2.7832  Acc:0.0236  fbScore:0.4928   LR -> Group0: 9.1503e-06 / Group1: 1.8301e-05 / Group2: 2.7451e-05 / Group3: 4.5752e-04 / Group4: 4.5752e-04 / Group5: 4.5752e-04 / \n",
      " 130/ 136  <train> Loss:2.6944  Acc:0.0244  fbScore:0.4931   LR -> Group0: 8.9869e-06 / Group1: 1.7974e-05 / Group2: 2.6961e-05 / Group3: 4.4935e-04 / Group4: 4.4935e-04 / Group5: 4.4935e-04 / \n",
      "<train> Loss:2.6465  Acc:0.0355  fbScore:0.4958\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af675034a71c4ad0858e20b819d5d1da"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:1.3290  Acc:0.7884  fbScore:0.8326\n",
      "Checkpoints have been updated to the epoch 1 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   2/  5】   LR -> Group0: 8.8889e-06 / Group1: 1.7778e-05 / Group2: 2.6667e-05 / Group3: 4.4444e-04 / Group4: 4.4444e-04 / Group5: 4.4444e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a01f2e44958346d091633f9bc2e8ef57"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:1.2511  Acc:0.6477  fbScore:0.7373   LR -> Group0: 8.7255e-06 / Group1: 1.7451e-05 / Group2: 2.6176e-05 / Group3: 4.3627e-04 / Group4: 4.3627e-04 / Group5: 4.3627e-04 / \n",
      "  20/ 136  <train> Loss:1.1637  Acc:0.7492  fbScore:0.7477   LR -> Group0: 8.5621e-06 / Group1: 1.7124e-05 / Group2: 2.5686e-05 / Group3: 4.2810e-04 / Group4: 4.2810e-04 / Group5: 4.2810e-04 / \n",
      "  30/ 136  <train> Loss:1.2462  Acc:0.7281  fbScore:0.7194   LR -> Group0: 8.3987e-06 / Group1: 1.6797e-05 / Group2: 2.5196e-05 / Group3: 4.1993e-04 / Group4: 4.1993e-04 / Group5: 4.1993e-04 / \n",
      "  40/ 136  <train> Loss:1.1731  Acc:0.7143  fbScore:0.7052   LR -> Group0: 8.2353e-06 / Group1: 1.6471e-05 / Group2: 2.4706e-05 / Group3: 4.1176e-04 / Group4: 4.1176e-04 / Group5: 4.1176e-04 / \n",
      "  50/ 136  <train> Loss:1.1888  Acc:0.7483  fbScore:0.7362   LR -> Group0: 8.0719e-06 / Group1: 1.6144e-05 / Group2: 2.4216e-05 / Group3: 4.0359e-04 / Group4: 4.0359e-04 / Group5: 4.0359e-04 / \n",
      "  60/ 136  <train> Loss:1.1670  Acc:0.7552  fbScore:0.7420   LR -> Group0: 7.9085e-06 / Group1: 1.5817e-05 / Group2: 2.3725e-05 / Group3: 3.9542e-04 / Group4: 3.9542e-04 / Group5: 3.9542e-04 / \n",
      "  70/ 136  <train> Loss:1.0710  Acc:0.7808  fbScore:0.7699   LR -> Group0: 7.7451e-06 / Group1: 1.5490e-05 / Group2: 2.3235e-05 / Group3: 3.8725e-04 / Group4: 3.8725e-04 / Group5: 3.8725e-04 / \n",
      "  80/ 136  <train> Loss:1.0679  Acc:0.7893  fbScore:0.7646   LR -> Group0: 7.5817e-06 / Group1: 1.5163e-05 / Group2: 2.2745e-05 / Group3: 3.7908e-04 / Group4: 3.7908e-04 / Group5: 3.7908e-04 / \n",
      "  90/ 136  <train> Loss:1.0356  Acc:0.7948  fbScore:0.7752   LR -> Group0: 7.4183e-06 / Group1: 1.4837e-05 / Group2: 2.2255e-05 / Group3: 3.7092e-04 / Group4: 3.7092e-04 / Group5: 3.7092e-04 / \n",
      " 100/ 136  <train> Loss:1.0134  Acc:0.8016  fbScore:0.7771   LR -> Group0: 7.2549e-06 / Group1: 1.4510e-05 / Group2: 2.1765e-05 / Group3: 3.6275e-04 / Group4: 3.6275e-04 / Group5: 3.6275e-04 / \n",
      " 110/ 136  <train> Loss:1.0108  Acc:0.8051  fbScore:0.7782   LR -> Group0: 7.0915e-06 / Group1: 1.4183e-05 / Group2: 2.1275e-05 / Group3: 3.5458e-04 / Group4: 3.5458e-04 / Group5: 3.5458e-04 / \n",
      " 120/ 136  <train> Loss:1.0055  Acc:0.8015  fbScore:0.7797   LR -> Group0: 6.9281e-06 / Group1: 1.3856e-05 / Group2: 2.0784e-05 / Group3: 3.4641e-04 / Group4: 3.4641e-04 / Group5: 3.4641e-04 / \n",
      " 130/ 136  <train> Loss:0.9742  Acc:0.8038  fbScore:0.7861   LR -> Group0: 6.7647e-06 / Group1: 1.3529e-05 / Group2: 2.0294e-05 / Group3: 3.3824e-04 / Group4: 3.3824e-04 / Group5: 3.3824e-04 / \n",
      "<train> Loss:0.9661  Acc:0.8059  fbScore:0.7775\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eda178762e944406b57f533e388c1546"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.6394  Acc:0.8543  fbScore:0.8685\n",
      "Checkpoints have been updated to the epoch 2 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   3/  5】   LR -> Group0: 6.6667e-06 / Group1: 1.3333e-05 / Group2: 2.0000e-05 / Group3: 3.3333e-04 / Group4: 3.3333e-04 / Group5: 3.3333e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a298d3733714a70bf3bcaf583ab27da"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:0.5307  Acc:0.8797  fbScore:0.8248   LR -> Group0: 6.5033e-06 / Group1: 1.3007e-05 / Group2: 1.9510e-05 / Group3: 3.2516e-04 / Group4: 3.2516e-04 / Group5: 3.2516e-04 / \n",
      "  20/ 136  <train> Loss:0.4862  Acc:0.8941  fbScore:0.8613   LR -> Group0: 6.3399e-06 / Group1: 1.2680e-05 / Group2: 1.9020e-05 / Group3: 3.1699e-04 / Group4: 3.1699e-04 / Group5: 3.1699e-04 / \n",
      "  30/ 136  <train> Loss:0.5260  Acc:0.8875  fbScore:0.8704   LR -> Group0: 6.1765e-06 / Group1: 1.2353e-05 / Group2: 1.8529e-05 / Group3: 3.0882e-04 / Group4: 3.0882e-04 / Group5: 3.0882e-04 / \n",
      "  40/ 136  <train> Loss:0.4954  Acc:0.8867  fbScore:0.8676   LR -> Group0: 6.0131e-06 / Group1: 1.2026e-05 / Group2: 1.8039e-05 / Group3: 3.0065e-04 / Group4: 3.0065e-04 / Group5: 3.0065e-04 / \n",
      "  50/ 136  <train> Loss:0.5444  Acc:0.8975  fbScore:0.8774   LR -> Group0: 5.8497e-06 / Group1: 1.1699e-05 / Group2: 1.7549e-05 / Group3: 2.9248e-04 / Group4: 2.9248e-04 / Group5: 2.9248e-04 / \n",
      "  60/ 136  <train> Loss:0.5728  Acc:0.8866  fbScore:0.8664   LR -> Group0: 5.6863e-06 / Group1: 1.1373e-05 / Group2: 1.7059e-05 / Group3: 2.8431e-04 / Group4: 2.8431e-04 / Group5: 2.8431e-04 / \n",
      "  70/ 136  <train> Loss:0.6090  Acc:0.8756  fbScore:0.8600   LR -> Group0: 5.5229e-06 / Group1: 1.1046e-05 / Group2: 1.6569e-05 / Group3: 2.7614e-04 / Group4: 2.7614e-04 / Group5: 2.7614e-04 / \n",
      "  80/ 136  <train> Loss:0.5830  Acc:0.8776  fbScore:0.8643   LR -> Group0: 5.3595e-06 / Group1: 1.0719e-05 / Group2: 1.6078e-05 / Group3: 2.6797e-04 / Group4: 2.6797e-04 / Group5: 2.6797e-04 / \n",
      "  90/ 136  <train> Loss:0.5793  Acc:0.8841  fbScore:0.8630   LR -> Group0: 5.1961e-06 / Group1: 1.0392e-05 / Group2: 1.5588e-05 / Group3: 2.5980e-04 / Group4: 2.5980e-04 / Group5: 2.5980e-04 / \n",
      " 100/ 136  <train> Loss:0.5577  Acc:0.8870  fbScore:0.8689   LR -> Group0: 5.0327e-06 / Group1: 1.0065e-05 / Group2: 1.5098e-05 / Group3: 2.5163e-04 / Group4: 2.5163e-04 / Group5: 2.5163e-04 / \n",
      " 110/ 136  <train> Loss:0.5595  Acc:0.8892  fbScore:0.8493   LR -> Group0: 4.8693e-06 / Group1: 9.7386e-06 / Group2: 1.4608e-05 / Group3: 2.4346e-04 / Group4: 2.4346e-04 / Group5: 2.4346e-04 / \n",
      " 120/ 136  <train> Loss:0.5353  Acc:0.8922  fbScore:0.8543   LR -> Group0: 4.7059e-06 / Group1: 9.4118e-06 / Group2: 1.4118e-05 / Group3: 2.3529e-04 / Group4: 2.3529e-04 / Group5: 2.3529e-04 / \n",
      " 130/ 136  <train> Loss:0.5116  Acc:0.8967  fbScore:0.8619   LR -> Group0: 4.5425e-06 / Group1: 9.0850e-06 / Group2: 1.3627e-05 / Group3: 2.2712e-04 / Group4: 2.2712e-04 / Group5: 2.2712e-04 / \n",
      "<train> Loss:0.5020  Acc:0.8988  fbScore:0.8648\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23067139fe55418cbd6bad1bd528d4b5"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.8938  Acc:0.9475  fbScore:0.8904\n",
      "Checkpoints have been updated to the epoch 3 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   4/  5】   LR -> Group0: 4.4444e-06 / Group1: 8.8889e-06 / Group2: 1.3333e-05 / Group3: 2.2222e-04 / Group4: 2.2222e-04 / Group5: 2.2222e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "929b4ba4b05f4ab0a4a06980de569453"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:0.8074  Acc:0.9453  fbScore:0.8177   LR -> Group0: 4.2810e-06 / Group1: 8.5621e-06 / Group2: 1.2843e-05 / Group3: 2.1405e-04 / Group4: 2.1405e-04 / Group5: 2.1405e-04 / \n",
      "  20/ 136  <train> Loss:0.5718  Acc:0.9344  fbScore:0.8606   LR -> Group0: 4.1176e-06 / Group1: 8.2353e-06 / Group2: 1.2353e-05 / Group3: 2.0588e-04 / Group4: 2.0588e-04 / Group5: 2.0588e-04 / \n",
      "  30/ 136  <train> Loss:0.5057  Acc:0.9250  fbScore:0.8781   LR -> Group0: 3.9542e-06 / Group1: 7.9085e-06 / Group2: 1.1863e-05 / Group3: 1.9771e-04 / Group4: 1.9771e-04 / Group5: 1.9771e-04 / \n",
      "  40/ 136  <train> Loss:0.4985  Acc:0.9287  fbScore:0.8932   LR -> Group0: 3.7908e-06 / Group1: 7.5817e-06 / Group2: 1.1373e-05 / Group3: 1.8954e-04 / Group4: 1.8954e-04 / Group5: 1.8954e-04 / \n",
      "  50/ 136  <train> Loss:0.4698  Acc:0.9272  fbScore:0.8785   LR -> Group0: 3.6275e-06 / Group1: 7.2549e-06 / Group2: 1.0882e-05 / Group3: 1.8137e-04 / Group4: 1.8137e-04 / Group5: 1.8137e-04 / \n",
      "  60/ 136  <train> Loss:0.4544  Acc:0.9254  fbScore:0.8857   LR -> Group0: 3.4641e-06 / Group1: 6.9281e-06 / Group2: 1.0392e-05 / Group3: 1.7320e-04 / Group4: 1.7320e-04 / Group5: 1.7320e-04 / \n",
      "  70/ 136  <train> Loss:0.4880  Acc:0.9237  fbScore:0.8758   LR -> Group0: 3.3007e-06 / Group1: 6.6013e-06 / Group2: 9.9020e-06 / Group3: 1.6503e-04 / Group4: 1.6503e-04 / Group5: 1.6503e-04 / \n",
      "  80/ 136  <train> Loss:0.4681  Acc:0.9251  fbScore:0.8718   LR -> Group0: 3.1373e-06 / Group1: 6.2745e-06 / Group2: 9.4118e-06 / Group3: 1.5686e-04 / Group4: 1.5686e-04 / Group5: 1.5686e-04 / \n",
      "  90/ 136  <train> Loss:0.4403  Acc:0.9275  fbScore:0.8797   LR -> Group0: 2.9739e-06 / Group1: 5.9477e-06 / Group2: 8.9216e-06 / Group3: 1.4869e-04 / Group4: 1.4869e-04 / Group5: 1.4869e-04 / \n",
      " 100/ 136  <train> Loss:0.4200  Acc:0.9298  fbScore:0.8850   LR -> Group0: 2.8105e-06 / Group1: 5.6209e-06 / Group2: 8.4314e-06 / Group3: 1.4052e-04 / Group4: 1.4052e-04 / Group5: 1.4052e-04 / \n",
      " 110/ 136  <train> Loss:0.4057  Acc:0.9325  fbScore:0.8920   LR -> Group0: 2.6471e-06 / Group1: 5.2941e-06 / Group2: 7.9412e-06 / Group3: 1.3235e-04 / Group4: 1.3235e-04 / Group5: 1.3235e-04 / \n",
      " 120/ 136  <train> Loss:0.3907  Acc:0.9331  fbScore:0.8950   LR -> Group0: 2.4837e-06 / Group1: 4.9673e-06 / Group2: 7.4510e-06 / Group3: 1.2418e-04 / Group4: 1.2418e-04 / Group5: 1.2418e-04 / \n",
      " 130/ 136  <train> Loss:0.3759  Acc:0.9349  fbScore:0.8988   LR -> Group0: 2.3203e-06 / Group1: 4.6405e-06 / Group2: 6.9608e-06 / Group3: 1.1601e-04 / Group4: 1.1601e-04 / Group5: 1.1601e-04 / \n",
      "<train> Loss:0.3781  Acc:0.9359  fbScore:0.8952\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e2f9cb82fe6d4a669cc24fc95090a192"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.6628  Acc:0.9438  fbScore:0.8910\n",
      "Checkpoints have been updated to the epoch 4 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   5/  5】   LR -> Group0: 2.2222e-06 / Group1: 4.4444e-06 / Group2: 6.6667e-06 / Group3: 1.1111e-04 / Group4: 1.1111e-04 / Group5: 1.1111e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eef26a705fa5415d8a72f29d58edcaa9"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:0.2665  Acc:0.9398  fbScore:0.8556   LR -> Group0: 2.0588e-06 / Group1: 4.1176e-06 / Group2: 6.1765e-06 / Group3: 1.0294e-04 / Group4: 1.0294e-04 / Group5: 1.0294e-04 / \n",
      "  20/ 136  <train> Loss:0.2295  Acc:0.9465  fbScore:0.8576   LR -> Group0: 1.8954e-06 / Group1: 3.7908e-06 / Group2: 5.6863e-06 / Group3: 9.4771e-05 / Group4: 9.4771e-05 / Group5: 9.4771e-05 / \n",
      "  30/ 136  <train> Loss:0.2249  Acc:0.9490  fbScore:0.8876   LR -> Group0: 1.7320e-06 / Group1: 3.4641e-06 / Group2: 5.1961e-06 / Group3: 8.6601e-05 / Group4: 8.6601e-05 / Group5: 8.6601e-05 / \n",
      "  40/ 136  <train> Loss:0.2055  Acc:0.9529  fbScore:0.9061   LR -> Group0: 1.5686e-06 / Group1: 3.1373e-06 / Group2: 4.7059e-06 / Group3: 7.8431e-05 / Group4: 7.8431e-05 / Group5: 7.8431e-05 / \n",
      "  50/ 136  <train> Loss:0.2225  Acc:0.9539  fbScore:0.8932   LR -> Group0: 1.4052e-06 / Group1: 2.8105e-06 / Group2: 4.2157e-06 / Group3: 7.0261e-05 / Group4: 7.0261e-05 / Group5: 7.0261e-05 / \n",
      "  60/ 136  <train> Loss:0.2440  Acc:0.9547  fbScore:0.9043   LR -> Group0: 1.2418e-06 / Group1: 2.4837e-06 / Group2: 3.7255e-06 / Group3: 6.2092e-05 / Group4: 6.2092e-05 / Group5: 6.2092e-05 / \n",
      "  70/ 136  <train> Loss:0.2418  Acc:0.9539  fbScore:0.8964   LR -> Group0: 1.0784e-06 / Group1: 2.1569e-06 / Group2: 3.2353e-06 / Group3: 5.3922e-05 / Group4: 5.3922e-05 / Group5: 5.3922e-05 / \n",
      "  80/ 136  <train> Loss:0.2298  Acc:0.9556  fbScore:0.8802   LR -> Group0: 9.1503e-07 / Group1: 1.8301e-06 / Group2: 2.7451e-06 / Group3: 4.5752e-05 / Group4: 4.5752e-05 / Group5: 4.5752e-05 / \n",
      "  90/ 136  <train> Loss:0.2313  Acc:0.9558  fbScore:0.8898   LR -> Group0: 7.5163e-07 / Group1: 1.5033e-06 / Group2: 2.2549e-06 / Group3: 3.7582e-05 / Group4: 3.7582e-05 / Group5: 3.7582e-05 / \n",
      " 100/ 136  <train> Loss:0.2271  Acc:0.9564  fbScore:0.8981   LR -> Group0: 5.8824e-07 / Group1: 1.1765e-06 / Group2: 1.7647e-06 / Group3: 2.9412e-05 / Group4: 2.9412e-05 / Group5: 2.9412e-05 / \n",
      " 110/ 136  <train> Loss:0.2259  Acc:0.9565  fbScore:0.9032   LR -> Group0: 4.2484e-07 / Group1: 8.4967e-07 / Group2: 1.2745e-06 / Group3: 2.1242e-05 / Group4: 2.1242e-05 / Group5: 2.1242e-05 / \n",
      " 120/ 136  <train> Loss:0.2190  Acc:0.9573  fbScore:0.9077   LR -> Group0: 2.6144e-07 / Group1: 5.2288e-07 / Group2: 7.8431e-07 / Group3: 1.3072e-05 / Group4: 1.3072e-05 / Group5: 1.3072e-05 / \n",
      " 130/ 136  <train> Loss:0.2183  Acc:0.9567  fbScore:0.9108   LR -> Group0: 9.8039e-08 / Group1: 1.9608e-07 / Group2: 2.9412e-07 / Group3: 4.9020e-06 / Group4: 4.9020e-06 / Group5: 4.9020e-06 / \n",
      "<train> Loss:0.2201  Acc:0.9566  fbScore:0.9132\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14e6e6344e4b4e65a3151d6a8d89ae2b"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.9869  Acc:0.9523  fbScore:0.8784\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Evaluate Test Dataset\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5d37674fc074787b157a53cb45c62c7"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss:0.9032  Acc:0.9492  fbScore:0.9020\n",
      "fb_score : 0.9067357512953368\n",
      "\n",
      "\u001b[32mCross-validation loop : 3/5\u001b[0m\n",
      "Train  ->  label_1:403 / all:17373   (2.320%)\n",
      "Valid  ->  label_1:101 / all:4343   (2.326%)\n",
      "Choosed BertLstmExModel\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "InitLR:2e-05 / num_warmup_steps:68 / num_training_steps:680\n",
      "Use 4 GPUs\n",
      "Using device : cuda\n",
      "【Epoch   1/  5】   LR -> Group0: 0.0000e+00 / Group1: 0.0000e+00 / Group2: 0.0000e+00 / Group3: 0.0000e+00 / Group4: 0.0000e+00 / Group5: 0.0000e+00 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a94bbd666634a7d9063cf15c1854680"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:3.3205  Acc:0.0258  fbScore:0.5331   LR -> Group0: 1.4706e-06 / Group1: 2.9412e-06 / Group2: 4.4118e-06 / Group3: 7.3529e-05 / Group4: 7.3529e-05 / Group5: 7.3529e-05 / \n",
      "  20/ 136  <train> Loss:3.2395  Acc:0.0250  fbScore:0.5154   LR -> Group0: 2.9412e-06 / Group1: 5.8824e-06 / Group2: 8.8235e-06 / Group3: 1.4706e-04 / Group4: 1.4706e-04 / Group5: 1.4706e-04 / \n",
      "  30/ 136  <train> Loss:3.2069  Acc:0.0247  fbScore:0.5155   LR -> Group0: 4.4118e-06 / Group1: 8.8235e-06 / Group2: 1.3235e-05 / Group3: 2.2059e-04 / Group4: 2.2059e-04 / Group5: 2.2059e-04 / \n",
      "  40/ 136  <train> Loss:3.2158  Acc:0.0250  fbScore:0.5179   LR -> Group0: 5.8824e-06 / Group1: 1.1765e-05 / Group2: 1.7647e-05 / Group3: 2.9412e-04 / Group4: 2.9412e-04 / Group5: 2.9412e-04 / \n",
      "  50/ 136  <train> Loss:3.1489  Acc:0.0248  fbScore:0.5172   LR -> Group0: 7.3529e-06 / Group1: 1.4706e-05 / Group2: 2.2059e-05 / Group3: 3.6765e-04 / Group4: 3.6765e-04 / Group5: 3.6765e-04 / \n",
      "  60/ 136  <train> Loss:3.1408  Acc:0.0259  fbScore:0.5314   LR -> Group0: 8.8235e-06 / Group1: 1.7647e-05 / Group2: 2.6471e-05 / Group3: 4.4118e-04 / Group4: 4.4118e-04 / Group5: 4.4118e-04 / \n",
      "  70/ 136  <train> Loss:2.9777  Acc:0.0247  fbScore:0.5051   LR -> Group0: 9.9673e-06 / Group1: 1.9935e-05 / Group2: 2.9902e-05 / Group3: 4.9837e-04 / Group4: 4.9837e-04 / Group5: 4.9837e-04 / \n",
      "  80/ 136  <train> Loss:2.9019  Acc:0.0238  fbScore:0.4953   LR -> Group0: 9.8039e-06 / Group1: 1.9608e-05 / Group2: 2.9412e-05 / Group3: 4.9020e-04 / Group4: 4.9020e-04 / Group5: 4.9020e-04 / \n",
      "  90/ 136  <train> Loss:2.8894  Acc:0.0241  fbScore:0.5026   LR -> Group0: 9.6405e-06 / Group1: 1.9281e-05 / Group2: 2.8922e-05 / Group3: 4.8203e-04 / Group4: 4.8203e-04 / Group5: 4.8203e-04 / \n",
      " 100/ 136  <train> Loss:2.8491  Acc:0.0244  fbScore:0.5029   LR -> Group0: 9.4771e-06 / Group1: 1.8954e-05 / Group2: 2.8431e-05 / Group3: 4.7386e-04 / Group4: 4.7386e-04 / Group5: 4.7386e-04 / \n",
      " 110/ 136  <train> Loss:2.7790  Acc:0.0241  fbScore:0.5011   LR -> Group0: 9.3137e-06 / Group1: 1.8627e-05 / Group2: 2.7941e-05 / Group3: 4.6569e-04 / Group4: 4.6569e-04 / Group5: 4.6569e-04 / \n",
      " 120/ 136  <train> Loss:2.6858  Acc:0.0255  fbScore:0.4975   LR -> Group0: 9.1503e-06 / Group1: 1.8301e-05 / Group2: 2.7451e-05 / Group3: 4.5752e-04 / Group4: 4.5752e-04 / Group5: 4.5752e-04 / \n",
      " 130/ 136  <train> Loss:2.6061  Acc:0.0490  fbScore:0.5065   LR -> Group0: 8.9869e-06 / Group1: 1.7974e-05 / Group2: 2.6961e-05 / Group3: 4.4935e-04 / Group4: 4.4935e-04 / Group5: 4.4935e-04 / \n",
      "<train> Loss:2.5522  Acc:0.0804  fbScore:0.5057\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca9e271c8aeb4f8da2fcc0c9c8733b4a"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:1.2794  Acc:0.7138  fbScore:0.7818\n",
      "Checkpoints have been updated to the epoch 1 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   2/  5】   LR -> Group0: 8.8889e-06 / Group1: 1.7778e-05 / Group2: 2.6667e-05 / Group3: 4.4444e-04 / Group4: 4.4444e-04 / Group5: 4.4444e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "acd7cac614e948f8b26f3c2d026d0137"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:1.3371  Acc:0.8164  fbScore:0.7251   LR -> Group0: 8.7255e-06 / Group1: 1.7451e-05 / Group2: 2.6176e-05 / Group3: 4.3627e-04 / Group4: 4.3627e-04 / Group5: 4.3627e-04 / \n",
      "  20/ 136  <train> Loss:1.0341  Acc:0.8359  fbScore:0.8000   LR -> Group0: 8.5621e-06 / Group1: 1.7124e-05 / Group2: 2.5686e-05 / Group3: 4.2810e-04 / Group4: 4.2810e-04 / Group5: 4.2810e-04 / \n",
      "  30/ 136  <train> Loss:0.9558  Acc:0.8505  fbScore:0.8326   LR -> Group0: 8.3987e-06 / Group1: 1.6797e-05 / Group2: 2.5196e-05 / Group3: 4.1993e-04 / Group4: 4.1993e-04 / Group5: 4.1993e-04 / \n",
      "  40/ 136  <train> Loss:0.9309  Acc:0.8541  fbScore:0.8344   LR -> Group0: 8.2353e-06 / Group1: 1.6471e-05 / Group2: 2.4706e-05 / Group3: 4.1176e-04 / Group4: 4.1176e-04 / Group5: 4.1176e-04 / \n",
      "  50/ 136  <train> Loss:0.9818  Acc:0.8517  fbScore:0.8076   LR -> Group0: 8.0719e-06 / Group1: 1.6144e-05 / Group2: 2.4216e-05 / Group3: 4.0359e-04 / Group4: 4.0359e-04 / Group5: 4.0359e-04 / \n",
      "  60/ 136  <train> Loss:0.9836  Acc:0.8432  fbScore:0.7962   LR -> Group0: 7.9085e-06 / Group1: 1.5817e-05 / Group2: 2.3725e-05 / Group3: 3.9542e-04 / Group4: 3.9542e-04 / Group5: 3.9542e-04 / \n",
      "  70/ 136  <train> Loss:0.9626  Acc:0.8316  fbScore:0.7984   LR -> Group0: 7.7451e-06 / Group1: 1.5490e-05 / Group2: 2.3235e-05 / Group3: 3.8725e-04 / Group4: 3.8725e-04 / Group5: 3.8725e-04 / \n",
      "  80/ 136  <train> Loss:0.9930  Acc:0.8374  fbScore:0.7910   LR -> Group0: 7.5817e-06 / Group1: 1.5163e-05 / Group2: 2.2745e-05 / Group3: 3.7908e-04 / Group4: 3.7908e-04 / Group5: 3.7908e-04 / \n",
      "  90/ 136  <train> Loss:1.0134  Acc:0.8439  fbScore:0.7962   LR -> Group0: 7.4183e-06 / Group1: 1.4837e-05 / Group2: 2.2255e-05 / Group3: 3.7092e-04 / Group4: 3.7092e-04 / Group5: 3.7092e-04 / \n",
      " 100/ 136  <train> Loss:1.0202  Acc:0.8369  fbScore:0.8004   LR -> Group0: 7.2549e-06 / Group1: 1.4510e-05 / Group2: 2.1765e-05 / Group3: 3.6275e-04 / Group4: 3.6275e-04 / Group5: 3.6275e-04 / \n",
      " 110/ 136  <train> Loss:0.9987  Acc:0.8312  fbScore:0.7930   LR -> Group0: 7.0915e-06 / Group1: 1.4183e-05 / Group2: 2.1275e-05 / Group3: 3.5458e-04 / Group4: 3.5458e-04 / Group5: 3.5458e-04 / \n",
      " 120/ 136  <train> Loss:0.9703  Acc:0.8353  fbScore:0.7900   LR -> Group0: 6.9281e-06 / Group1: 1.3856e-05 / Group2: 2.0784e-05 / Group3: 3.4641e-04 / Group4: 3.4641e-04 / Group5: 3.4641e-04 / \n",
      " 130/ 136  <train> Loss:0.9822  Acc:0.8392  fbScore:0.7940   LR -> Group0: 6.7647e-06 / Group1: 1.3529e-05 / Group2: 2.0294e-05 / Group3: 3.3824e-04 / Group4: 3.3824e-04 / Group5: 3.3824e-04 / \n",
      "<train> Loss:0.9621  Acc:0.8396  fbScore:0.7778\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1be75c274ce346309d8dbb6f76989d9e"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.7118  Acc:0.8416  fbScore:0.8554\n",
      "Checkpoints have been updated to the epoch 2 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   3/  5】   LR -> Group0: 6.6667e-06 / Group1: 1.3333e-05 / Group2: 2.0000e-05 / Group3: 3.3333e-04 / Group4: 3.3333e-04 / Group5: 3.3333e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b03963f2b3944799919f429f9fa3c2dc"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:0.5409  Acc:0.8734  fbScore:0.8762   LR -> Group0: 6.5033e-06 / Group1: 1.3007e-05 / Group2: 1.9510e-05 / Group3: 3.2516e-04 / Group4: 3.2516e-04 / Group5: 3.2516e-04 / \n",
      "  20/ 136  <train> Loss:0.4521  Acc:0.9043  fbScore:0.9050   LR -> Group0: 6.3399e-06 / Group1: 1.2680e-05 / Group2: 1.9020e-05 / Group3: 3.1699e-04 / Group4: 3.1699e-04 / Group5: 3.1699e-04 / \n",
      "  30/ 136  <train> Loss:0.5653  Acc:0.9164  fbScore:0.9178   LR -> Group0: 6.1765e-06 / Group1: 1.2353e-05 / Group2: 1.8529e-05 / Group3: 3.0882e-04 / Group4: 3.0882e-04 / Group5: 3.0882e-04 / \n",
      "  40/ 136  <train> Loss:0.5821  Acc:0.8977  fbScore:0.9061   LR -> Group0: 6.0131e-06 / Group1: 1.2026e-05 / Group2: 1.8039e-05 / Group3: 3.0065e-04 / Group4: 3.0065e-04 / Group5: 3.0065e-04 / \n",
      "  50/ 136  <train> Loss:0.5643  Acc:0.8931  fbScore:0.8786   LR -> Group0: 5.8497e-06 / Group1: 1.1699e-05 / Group2: 1.7549e-05 / Group3: 2.9248e-04 / Group4: 2.9248e-04 / Group5: 2.9248e-04 / \n",
      "  60/ 136  <train> Loss:0.5952  Acc:0.9020  fbScore:0.8803   LR -> Group0: 5.6863e-06 / Group1: 1.1373e-05 / Group2: 1.7059e-05 / Group3: 2.8431e-04 / Group4: 2.8431e-04 / Group5: 2.8431e-04 / \n",
      "  70/ 136  <train> Loss:0.6321  Acc:0.8975  fbScore:0.8803   LR -> Group0: 5.5229e-06 / Group1: 1.1046e-05 / Group2: 1.6569e-05 / Group3: 2.7614e-04 / Group4: 2.7614e-04 / Group5: 2.7614e-04 / \n",
      "  80/ 136  <train> Loss:0.6461  Acc:0.8813  fbScore:0.8652   LR -> Group0: 5.3595e-06 / Group1: 1.0719e-05 / Group2: 1.6078e-05 / Group3: 2.6797e-04 / Group4: 2.6797e-04 / Group5: 2.6797e-04 / \n",
      "  90/ 136  <train> Loss:0.6284  Acc:0.8807  fbScore:0.8678   LR -> Group0: 5.1961e-06 / Group1: 1.0392e-05 / Group2: 1.5588e-05 / Group3: 2.5980e-04 / Group4: 2.5980e-04 / Group5: 2.5980e-04 / \n",
      " 100/ 136  <train> Loss:0.6399  Acc:0.8812  fbScore:0.8553   LR -> Group0: 5.0327e-06 / Group1: 1.0065e-05 / Group2: 1.5098e-05 / Group3: 2.5163e-04 / Group4: 2.5163e-04 / Group5: 2.5163e-04 / \n",
      " 110/ 136  <train> Loss:0.6422  Acc:0.8852  fbScore:0.8529   LR -> Group0: 4.8693e-06 / Group1: 9.7386e-06 / Group2: 1.4608e-05 / Group3: 2.4346e-04 / Group4: 2.4346e-04 / Group5: 2.4346e-04 / \n",
      " 120/ 136  <train> Loss:0.6159  Acc:0.8883  fbScore:0.8497   LR -> Group0: 4.7059e-06 / Group1: 9.4118e-06 / Group2: 1.4118e-05 / Group3: 2.3529e-04 / Group4: 2.3529e-04 / Group5: 2.3529e-04 / \n",
      " 130/ 136  <train> Loss:0.6249  Acc:0.8919  fbScore:0.8529   LR -> Group0: 4.5425e-06 / Group1: 9.0850e-06 / Group2: 1.3627e-05 / Group3: 2.2712e-04 / Group4: 2.2712e-04 / Group5: 2.2712e-04 / \n",
      "<train> Loss:0.6169  Acc:0.8923  fbScore:0.8486\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad6dd3747b3c43f1880b50afbb0c8e6d"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.6003  Acc:0.8837  fbScore:0.8777\n",
      "Checkpoints have been updated to the epoch 3 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   4/  5】   LR -> Group0: 4.4444e-06 / Group1: 8.8889e-06 / Group2: 1.3333e-05 / Group3: 2.2222e-04 / Group4: 2.2222e-04 / Group5: 2.2222e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12ba8782bc9146689e021e0f01d00e1c"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:0.4055  Acc:0.8953  fbScore:0.9014   LR -> Group0: 4.2810e-06 / Group1: 8.5621e-06 / Group2: 1.2843e-05 / Group3: 2.1405e-04 / Group4: 2.1405e-04 / Group5: 2.1405e-04 / \n",
      "  20/ 136  <train> Loss:0.6148  Acc:0.8977  fbScore:0.8587   LR -> Group0: 4.1176e-06 / Group1: 8.2353e-06 / Group2: 1.2353e-05 / Group3: 2.0588e-04 / Group4: 2.0588e-04 / Group5: 2.0588e-04 / \n",
      "  30/ 136  <train> Loss:0.5464  Acc:0.8990  fbScore:0.8166   LR -> Group0: 3.9542e-06 / Group1: 7.9085e-06 / Group2: 1.1863e-05 / Group3: 1.9771e-04 / Group4: 1.9771e-04 / Group5: 1.9771e-04 / \n",
      "  40/ 136  <train> Loss:0.4845  Acc:0.9076  fbScore:0.8427   LR -> Group0: 3.7908e-06 / Group1: 7.5817e-06 / Group2: 1.1373e-05 / Group3: 1.8954e-04 / Group4: 1.8954e-04 / Group5: 1.8954e-04 / \n",
      "  50/ 136  <train> Loss:0.4752  Acc:0.9128  fbScore:0.8383   LR -> Group0: 3.6275e-06 / Group1: 7.2549e-06 / Group2: 1.0882e-05 / Group3: 1.8137e-04 / Group4: 1.8137e-04 / Group5: 1.8137e-04 / \n",
      "  60/ 136  <train> Loss:0.4553  Acc:0.9151  fbScore:0.8566   LR -> Group0: 3.4641e-06 / Group1: 6.9281e-06 / Group2: 1.0392e-05 / Group3: 1.7320e-04 / Group4: 1.7320e-04 / Group5: 1.7320e-04 / \n",
      "  70/ 136  <train> Loss:0.4362  Acc:0.9173  fbScore:0.8662   LR -> Group0: 3.3007e-06 / Group1: 6.6013e-06 / Group2: 9.9020e-06 / Group3: 1.6503e-04 / Group4: 1.6503e-04 / Group5: 1.6503e-04 / \n",
      "  80/ 136  <train> Loss:0.4406  Acc:0.9199  fbScore:0.8731   LR -> Group0: 3.1373e-06 / Group1: 6.2745e-06 / Group2: 9.4118e-06 / Group3: 1.5686e-04 / Group4: 1.5686e-04 / Group5: 1.5686e-04 / \n",
      "  90/ 136  <train> Loss:0.4256  Acc:0.9201  fbScore:0.8799   LR -> Group0: 2.9739e-06 / Group1: 5.9477e-06 / Group2: 8.9216e-06 / Group3: 1.4869e-04 / Group4: 1.4869e-04 / Group5: 1.4869e-04 / \n",
      " 100/ 136  <train> Loss:0.4154  Acc:0.9215  fbScore:0.8825   LR -> Group0: 2.8105e-06 / Group1: 5.6209e-06 / Group2: 8.4314e-06 / Group3: 1.4052e-04 / Group4: 1.4052e-04 / Group5: 1.4052e-04 / \n",
      " 110/ 136  <train> Loss:0.4117  Acc:0.9242  fbScore:0.8889   LR -> Group0: 2.6471e-06 / Group1: 5.2941e-06 / Group2: 7.9412e-06 / Group3: 1.3235e-04 / Group4: 1.3235e-04 / Group5: 1.3235e-04 / \n",
      " 120/ 136  <train> Loss:0.4022  Acc:0.9240  fbScore:0.8837   LR -> Group0: 2.4837e-06 / Group1: 4.9673e-06 / Group2: 7.4510e-06 / Group3: 1.2418e-04 / Group4: 1.2418e-04 / Group5: 1.2418e-04 / \n",
      " 130/ 136  <train> Loss:0.3932  Acc:0.9238  fbScore:0.8863   LR -> Group0: 2.3203e-06 / Group1: 4.6405e-06 / Group2: 6.9608e-06 / Group3: 1.1601e-04 / Group4: 1.1601e-04 / Group5: 1.1601e-04 / \n",
      "<train> Loss:0.3907  Acc:0.9238  fbScore:0.8875\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7adc9d246b04b3e8930d15210f21fb4"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.5573  Acc:0.9215  fbScore:0.8911\n",
      "Checkpoints have been updated to the epoch 4 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   5/  5】   LR -> Group0: 2.2222e-06 / Group1: 4.4444e-06 / Group2: 6.6667e-06 / Group3: 1.1111e-04 / Group4: 1.1111e-04 / Group5: 1.1111e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7009351c52414cd49a4b792bfd941d4e"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:0.2657  Acc:0.9242  fbScore:0.7452   LR -> Group0: 2.0588e-06 / Group1: 4.1176e-06 / Group2: 6.1765e-06 / Group3: 1.0294e-04 / Group4: 1.0294e-04 / Group5: 1.0294e-04 / \n",
      "  20/ 136  <train> Loss:0.3769  Acc:0.9352  fbScore:0.8320   LR -> Group0: 1.8954e-06 / Group1: 3.7908e-06 / Group2: 5.6863e-06 / Group3: 9.4771e-05 / Group4: 9.4771e-05 / Group5: 9.4771e-05 / \n",
      "  30/ 136  <train> Loss:0.3441  Acc:0.9346  fbScore:0.8639   LR -> Group0: 1.7320e-06 / Group1: 3.4641e-06 / Group2: 5.1961e-06 / Group3: 8.6601e-05 / Group4: 8.6601e-05 / Group5: 8.6601e-05 / \n",
      "  40/ 136  <train> Loss:0.3292  Acc:0.9352  fbScore:0.8801   LR -> Group0: 1.5686e-06 / Group1: 3.1373e-06 / Group2: 4.7059e-06 / Group3: 7.8431e-05 / Group4: 7.8431e-05 / Group5: 7.8431e-05 / \n",
      "  50/ 136  <train> Loss:0.3081  Acc:0.9367  fbScore:0.8940   LR -> Group0: 1.4052e-06 / Group1: 2.8105e-06 / Group2: 4.2157e-06 / Group3: 7.0261e-05 / Group4: 7.0261e-05 / Group5: 7.0261e-05 / \n",
      "  60/ 136  <train> Loss:0.3091  Acc:0.9365  fbScore:0.8960   LR -> Group0: 1.2418e-06 / Group1: 2.4837e-06 / Group2: 3.7255e-06 / Group3: 6.2092e-05 / Group4: 6.2092e-05 / Group5: 6.2092e-05 / \n",
      "  70/ 136  <train> Loss:0.2950  Acc:0.9393  fbScore:0.9048   LR -> Group0: 1.0784e-06 / Group1: 2.1569e-06 / Group2: 3.2353e-06 / Group3: 5.3922e-05 / Group4: 5.3922e-05 / Group5: 5.3922e-05 / \n",
      "  80/ 136  <train> Loss:0.2887  Acc:0.9404  fbScore:0.9112   LR -> Group0: 9.1503e-07 / Group1: 1.8301e-06 / Group2: 2.7451e-06 / Group3: 4.5752e-05 / Group4: 4.5752e-05 / Group5: 4.5752e-05 / \n",
      "  90/ 136  <train> Loss:0.2904  Acc:0.9418  fbScore:0.9047   LR -> Group0: 7.5163e-07 / Group1: 1.5033e-06 / Group2: 2.2549e-06 / Group3: 3.7582e-05 / Group4: 3.7582e-05 / Group5: 3.7582e-05 / \n",
      " 100/ 136  <train> Loss:0.2856  Acc:0.9416  fbScore:0.8996   LR -> Group0: 5.8824e-07 / Group1: 1.1765e-06 / Group2: 1.7647e-06 / Group3: 2.9412e-05 / Group4: 2.9412e-05 / Group5: 2.9412e-05 / \n",
      " 110/ 136  <train> Loss:0.2787  Acc:0.9421  fbScore:0.9036   LR -> Group0: 4.2484e-07 / Group1: 8.4967e-07 / Group2: 1.2745e-06 / Group3: 2.1242e-05 / Group4: 2.1242e-05 / Group5: 2.1242e-05 / \n",
      " 120/ 136  <train> Loss:0.2740  Acc:0.9430  fbScore:0.9078   LR -> Group0: 2.6144e-07 / Group1: 5.2288e-07 / Group2: 7.8431e-07 / Group3: 1.3072e-05 / Group4: 1.3072e-05 / Group5: 1.3072e-05 / \n",
      " 130/ 136  <train> Loss:0.2733  Acc:0.9424  fbScore:0.9090   LR -> Group0: 9.8039e-08 / Group1: 1.9608e-07 / Group2: 2.9412e-07 / Group3: 4.9020e-06 / Group4: 4.9020e-06 / Group5: 4.9020e-06 / \n",
      "<train> Loss:0.2700  Acc:0.9428  fbScore:0.9110\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4308ff1220d04096a4f4ee4667e3cbe1"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.6454  Acc:0.9397  fbScore:0.9049\n",
      "Checkpoints have been updated to the epoch 5 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Evaluate Test Dataset\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "554db8415ac14c59a4682687a1a66b2f"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss:1.0350  Acc:0.9390  fbScore:0.8780\n",
      "fb_score : 0.884621200665356\n",
      "\n",
      "\u001b[32mCross-validation loop : 4/5\u001b[0m\n",
      "Train  ->  label_1:403 / all:17373   (2.320%)\n",
      "Valid  ->  label_1:101 / all:4343   (2.326%)\n",
      "Choosed BertLstmExModel\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "InitLR:2e-05 / num_warmup_steps:68 / num_training_steps:680\n",
      "Use 4 GPUs\n",
      "Using device : cuda\n",
      "【Epoch   1/  5】   LR -> Group0: 0.0000e+00 / Group1: 0.0000e+00 / Group2: 0.0000e+00 / Group3: 0.0000e+00 / Group4: 0.0000e+00 / Group5: 0.0000e+00 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9641467042154316b8ea3a1a5dbfd3b7"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:2.4497  Acc:0.0172  fbScore:0.4168   LR -> Group0: 1.4706e-06 / Group1: 2.9412e-06 / Group2: 4.4118e-06 / Group3: 7.3529e-05 / Group4: 7.3529e-05 / Group5: 7.3529e-05 / \n",
      "  20/ 136  <train> Loss:2.6064  Acc:0.0188  fbScore:0.4431   LR -> Group0: 2.9412e-06 / Group1: 5.8824e-06 / Group2: 8.8235e-06 / Group3: 1.4706e-04 / Group4: 1.4706e-04 / Group5: 1.4706e-04 / \n",
      "  30/ 136  <train> Loss:2.7091  Acc:0.0198  fbScore:0.4653   LR -> Group0: 4.4118e-06 / Group1: 8.8235e-06 / Group2: 1.3235e-05 / Group3: 2.2059e-04 / Group4: 2.2059e-04 / Group5: 2.2059e-04 / \n",
      "  40/ 136  <train> Loss:2.9103  Acc:0.0219  fbScore:0.4868   LR -> Group0: 5.8824e-06 / Group1: 1.1765e-05 / Group2: 1.7647e-05 / Group3: 2.9412e-04 / Group4: 2.9412e-04 / Group5: 2.9412e-04 / \n",
      "  50/ 136  <train> Loss:2.9151  Acc:0.0222  fbScore:0.4872   LR -> Group0: 7.3529e-06 / Group1: 1.4706e-05 / Group2: 2.2059e-05 / Group3: 3.6765e-04 / Group4: 3.6765e-04 / Group5: 3.6765e-04 / \n",
      "  60/ 136  <train> Loss:2.9910  Acc:0.0237  fbScore:0.5039   LR -> Group0: 8.8235e-06 / Group1: 1.7647e-05 / Group2: 2.6471e-05 / Group3: 4.4118e-04 / Group4: 4.4118e-04 / Group5: 4.4118e-04 / \n",
      "  70/ 136  <train> Loss:2.9794  Acc:0.0240  fbScore:0.5079   LR -> Group0: 9.9673e-06 / Group1: 1.9935e-05 / Group2: 2.9902e-05 / Group3: 4.9837e-04 / Group4: 4.9837e-04 / Group5: 4.9837e-04 / \n",
      "  80/ 136  <train> Loss:2.8939  Acc:0.0235  fbScore:0.5020   LR -> Group0: 9.8039e-06 / Group1: 1.9608e-05 / Group2: 2.9412e-05 / Group3: 4.9020e-04 / Group4: 4.9020e-04 / Group5: 4.9020e-04 / \n",
      "  90/ 136  <train> Loss:2.8312  Acc:0.0234  fbScore:0.5007   LR -> Group0: 9.6405e-06 / Group1: 1.9281e-05 / Group2: 2.8922e-05 / Group3: 4.8203e-04 / Group4: 4.8203e-04 / Group5: 4.8203e-04 / \n",
      " 100/ 136  <train> Loss:2.7488  Acc:0.0231  fbScore:0.4948   LR -> Group0: 9.4771e-06 / Group1: 1.8954e-05 / Group2: 2.8431e-05 / Group3: 4.7386e-04 / Group4: 4.7386e-04 / Group5: 4.7386e-04 / \n",
      " 110/ 136  <train> Loss:2.7200  Acc:0.0239  fbScore:0.5010   LR -> Group0: 9.3137e-06 / Group1: 1.8627e-05 / Group2: 2.7941e-05 / Group3: 4.6569e-04 / Group4: 4.6569e-04 / Group5: 4.6569e-04 / \n",
      " 120/ 136  <train> Loss:2.6639  Acc:0.0240  fbScore:0.5035   LR -> Group0: 9.1503e-06 / Group1: 1.8301e-05 / Group2: 2.7451e-05 / Group3: 4.5752e-04 / Group4: 4.5752e-04 / Group5: 4.5752e-04 / \n",
      " 130/ 136  <train> Loss:2.5960  Acc:0.0242  fbScore:0.4958   LR -> Group0: 8.9869e-06 / Group1: 1.7974e-05 / Group2: 2.6961e-05 / Group3: 4.4935e-04 / Group4: 4.4935e-04 / Group5: 4.4935e-04 / \n",
      "<train> Loss:2.5425  Acc:0.0264  fbScore:0.4926\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d823a75cc5994b1390c4bb10be2964ed"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:1.7615  Acc:0.0262  fbScore:0.5386\n",
      "Checkpoints have been updated to the epoch 1 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   2/  5】   LR -> Group0: 8.8889e-06 / Group1: 1.7778e-05 / Group2: 2.6667e-05 / Group3: 4.4444e-04 / Group4: 4.4444e-04 / Group5: 4.4444e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f3b9045317540acb902cb7c463d25e6"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:1.4709  Acc:0.3461  fbScore:0.6034   LR -> Group0: 8.7255e-06 / Group1: 1.7451e-05 / Group2: 2.6176e-05 / Group3: 4.3627e-04 / Group4: 4.3627e-04 / Group5: 4.3627e-04 / \n",
      "  20/ 136  <train> Loss:1.3680  Acc:0.5652  fbScore:0.6192   LR -> Group0: 8.5621e-06 / Group1: 1.7124e-05 / Group2: 2.5686e-05 / Group3: 4.2810e-04 / Group4: 4.2810e-04 / Group5: 4.2810e-04 / \n",
      "  30/ 136  <train> Loss:1.2727  Acc:0.6445  fbScore:0.6558   LR -> Group0: 8.3987e-06 / Group1: 1.6797e-05 / Group2: 2.5196e-05 / Group3: 4.1993e-04 / Group4: 4.1993e-04 / Group5: 4.1993e-04 / \n",
      "  40/ 136  <train> Loss:1.3671  Acc:0.6203  fbScore:0.6587   LR -> Group0: 8.2353e-06 / Group1: 1.6471e-05 / Group2: 2.4706e-05 / Group3: 4.1176e-04 / Group4: 4.1176e-04 / Group5: 4.1176e-04 / \n",
      "  50/ 136  <train> Loss:1.3485  Acc:0.6570  fbScore:0.6584   LR -> Group0: 8.0719e-06 / Group1: 1.6144e-05 / Group2: 2.4216e-05 / Group3: 4.0359e-04 / Group4: 4.0359e-04 / Group5: 4.0359e-04 / \n",
      "  60/ 136  <train> Loss:1.3545  Acc:0.6486  fbScore:0.6584   LR -> Group0: 7.9085e-06 / Group1: 1.5817e-05 / Group2: 2.3725e-05 / Group3: 3.9542e-04 / Group4: 3.9542e-04 / Group5: 3.9542e-04 / \n",
      "  70/ 136  <train> Loss:1.3282  Acc:0.6645  fbScore:0.6640   LR -> Group0: 7.7451e-06 / Group1: 1.5490e-05 / Group2: 2.3235e-05 / Group3: 3.8725e-04 / Group4: 3.8725e-04 / Group5: 3.8725e-04 / \n",
      "  80/ 136  <train> Loss:1.3100  Acc:0.6837  fbScore:0.6905   LR -> Group0: 7.5817e-06 / Group1: 1.5163e-05 / Group2: 2.2745e-05 / Group3: 3.7908e-04 / Group4: 3.7908e-04 / Group5: 3.7908e-04 / \n",
      "  90/ 136  <train> Loss:1.2437  Acc:0.7006  fbScore:0.7016   LR -> Group0: 7.4183e-06 / Group1: 1.4837e-05 / Group2: 2.2255e-05 / Group3: 3.7092e-04 / Group4: 3.7092e-04 / Group5: 3.7092e-04 / \n",
      " 100/ 136  <train> Loss:1.1780  Acc:0.7206  fbScore:0.7084   LR -> Group0: 7.2549e-06 / Group1: 1.4510e-05 / Group2: 2.1765e-05 / Group3: 3.6275e-04 / Group4: 3.6275e-04 / Group5: 3.6275e-04 / \n",
      " 110/ 136  <train> Loss:1.1217  Acc:0.7311  fbScore:0.7139   LR -> Group0: 7.0915e-06 / Group1: 1.4183e-05 / Group2: 2.1275e-05 / Group3: 3.5458e-04 / Group4: 3.5458e-04 / Group5: 3.5458e-04 / \n",
      " 120/ 136  <train> Loss:1.1380  Acc:0.7456  fbScore:0.7215   LR -> Group0: 6.9281e-06 / Group1: 1.3856e-05 / Group2: 2.0784e-05 / Group3: 3.4641e-04 / Group4: 3.4641e-04 / Group5: 3.4641e-04 / \n",
      " 130/ 136  <train> Loss:1.1285  Acc:0.7433  fbScore:0.7274   LR -> Group0: 6.7647e-06 / Group1: 1.3529e-05 / Group2: 2.0294e-05 / Group3: 3.3824e-04 / Group4: 3.3824e-04 / Group5: 3.3824e-04 / \n",
      "<train> Loss:1.1146  Acc:0.7430  fbScore:0.7301\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8ee74f255184d088a0e97c9259554fa"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.8172  Acc:0.8671  fbScore:0.8556\n",
      "Checkpoints have been updated to the epoch 2 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   3/  5】   LR -> Group0: 6.6667e-06 / Group1: 1.3333e-05 / Group2: 2.0000e-05 / Group3: 3.3333e-04 / Group4: 3.3333e-04 / Group5: 3.3333e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e80e48cb5eb941a9a6635f004fde2f54"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:0.6567  Acc:0.9258  fbScore:0.7812   LR -> Group0: 6.5033e-06 / Group1: 1.3007e-05 / Group2: 1.9510e-05 / Group3: 3.2516e-04 / Group4: 3.2516e-04 / Group5: 3.2516e-04 / \n",
      "  20/ 136  <train> Loss:0.5339  Acc:0.9137  fbScore:0.8385   LR -> Group0: 6.3399e-06 / Group1: 1.2680e-05 / Group2: 1.9020e-05 / Group3: 3.1699e-04 / Group4: 3.1699e-04 / Group5: 3.1699e-04 / \n",
      "  30/ 136  <train> Loss:0.6529  Acc:0.8971  fbScore:0.8445   LR -> Group0: 6.1765e-06 / Group1: 1.2353e-05 / Group2: 1.8529e-05 / Group3: 3.0882e-04 / Group4: 3.0882e-04 / Group5: 3.0882e-04 / \n",
      "  40/ 136  <train> Loss:0.6282  Acc:0.8885  fbScore:0.8329   LR -> Group0: 6.0131e-06 / Group1: 1.2026e-05 / Group2: 1.8039e-05 / Group3: 3.0065e-04 / Group4: 3.0065e-04 / Group5: 3.0065e-04 / \n",
      "  50/ 136  <train> Loss:0.5876  Acc:0.8914  fbScore:0.8495   LR -> Group0: 5.8497e-06 / Group1: 1.1699e-05 / Group2: 1.7549e-05 / Group3: 2.9248e-04 / Group4: 2.9248e-04 / Group5: 2.9248e-04 / \n",
      "  60/ 136  <train> Loss:0.6085  Acc:0.8930  fbScore:0.8528   LR -> Group0: 5.6863e-06 / Group1: 1.1373e-05 / Group2: 1.7059e-05 / Group3: 2.8431e-04 / Group4: 2.8431e-04 / Group5: 2.8431e-04 / \n",
      "  70/ 136  <train> Loss:0.6157  Acc:0.8854  fbScore:0.8550   LR -> Group0: 5.5229e-06 / Group1: 1.1046e-05 / Group2: 1.6569e-05 / Group3: 2.7614e-04 / Group4: 2.7614e-04 / Group5: 2.7614e-04 / \n",
      "  80/ 136  <train> Loss:0.6467  Acc:0.8701  fbScore:0.8290   LR -> Group0: 5.3595e-06 / Group1: 1.0719e-05 / Group2: 1.6078e-05 / Group3: 2.6797e-04 / Group4: 2.6797e-04 / Group5: 2.6797e-04 / \n",
      "  90/ 136  <train> Loss:0.6437  Acc:0.8585  fbScore:0.8195   LR -> Group0: 5.1961e-06 / Group1: 1.0392e-05 / Group2: 1.5588e-05 / Group3: 2.5980e-04 / Group4: 2.5980e-04 / Group5: 2.5980e-04 / \n",
      " 100/ 136  <train> Loss:0.6349  Acc:0.8576  fbScore:0.8057   LR -> Group0: 5.0327e-06 / Group1: 1.0065e-05 / Group2: 1.5098e-05 / Group3: 2.5163e-04 / Group4: 2.5163e-04 / Group5: 2.5163e-04 / \n",
      " 110/ 136  <train> Loss:0.6536  Acc:0.8548  fbScore:0.7988   LR -> Group0: 4.8693e-06 / Group1: 9.7386e-06 / Group2: 1.4608e-05 / Group3: 2.4346e-04 / Group4: 2.4346e-04 / Group5: 2.4346e-04 / \n",
      " 120/ 136  <train> Loss:0.6437  Acc:0.8536  fbScore:0.8003   LR -> Group0: 4.7059e-06 / Group1: 9.4118e-06 / Group2: 1.4118e-05 / Group3: 2.3529e-04 / Group4: 2.3529e-04 / Group5: 2.3529e-04 / \n",
      " 130/ 136  <train> Loss:0.6248  Acc:0.8553  fbScore:0.7935   LR -> Group0: 4.5425e-06 / Group1: 9.0850e-06 / Group2: 1.3627e-05 / Group3: 2.2712e-04 / Group4: 2.2712e-04 / Group5: 2.2712e-04 / \n",
      "<train> Loss:0.6203  Acc:0.8570  fbScore:0.7994\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "262b790fd9f14de5b2ffbcbda9d6ed21"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.6658  Acc:0.9127  fbScore:0.8893\n",
      "Checkpoints have been updated to the epoch 3 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   4/  5】   LR -> Group0: 4.4444e-06 / Group1: 8.8889e-06 / Group2: 1.3333e-05 / Group3: 2.2222e-04 / Group4: 2.2222e-04 / Group5: 2.2222e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e2a363cb9ab4f318eaa760d1ecdfdc5"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:0.3119  Acc:0.9102  fbScore:0.7378   LR -> Group0: 4.2810e-06 / Group1: 8.5621e-06 / Group2: 1.2843e-05 / Group3: 2.1405e-04 / Group4: 2.1405e-04 / Group5: 2.1405e-04 / \n",
      "  20/ 136  <train> Loss:0.3088  Acc:0.9184  fbScore:0.8235   LR -> Group0: 4.1176e-06 / Group1: 8.2353e-06 / Group2: 1.2353e-05 / Group3: 2.0588e-04 / Group4: 2.0588e-04 / Group5: 2.0588e-04 / \n",
      "  30/ 136  <train> Loss:0.3389  Acc:0.9227  fbScore:0.8535   LR -> Group0: 3.9542e-06 / Group1: 7.9085e-06 / Group2: 1.1863e-05 / Group3: 1.9771e-04 / Group4: 1.9771e-04 / Group5: 1.9771e-04 / \n",
      "  40/ 136  <train> Loss:0.4701  Acc:0.9143  fbScore:0.8549   LR -> Group0: 3.7908e-06 / Group1: 7.5817e-06 / Group2: 1.1373e-05 / Group3: 1.8954e-04 / Group4: 1.8954e-04 / Group5: 1.8954e-04 / \n",
      "  50/ 136  <train> Loss:0.5067  Acc:0.8905  fbScore:0.8581   LR -> Group0: 3.6275e-06 / Group1: 7.2549e-06 / Group2: 1.0882e-05 / Group3: 1.8137e-04 / Group4: 1.8137e-04 / Group5: 1.8137e-04 / \n",
      "  60/ 136  <train> Loss:0.4941  Acc:0.8854  fbScore:0.8594   LR -> Group0: 3.4641e-06 / Group1: 6.9281e-06 / Group2: 1.0392e-05 / Group3: 1.7320e-04 / Group4: 1.7320e-04 / Group5: 1.7320e-04 / \n",
      "  70/ 136  <train> Loss:0.4891  Acc:0.8890  fbScore:0.8544   LR -> Group0: 3.3007e-06 / Group1: 6.6013e-06 / Group2: 9.9020e-06 / Group3: 1.6503e-04 / Group4: 1.6503e-04 / Group5: 1.6503e-04 / \n",
      "  80/ 136  <train> Loss:0.4809  Acc:0.8900  fbScore:0.8605   LR -> Group0: 3.1373e-06 / Group1: 6.2745e-06 / Group2: 9.4118e-06 / Group3: 1.5686e-04 / Group4: 1.5686e-04 / Group5: 1.5686e-04 / \n",
      "  90/ 136  <train> Loss:0.4683  Acc:0.8928  fbScore:0.8664   LR -> Group0: 2.9739e-06 / Group1: 5.9477e-06 / Group2: 8.9216e-06 / Group3: 1.4869e-04 / Group4: 1.4869e-04 / Group5: 1.4869e-04 / \n",
      " 100/ 136  <train> Loss:0.4524  Acc:0.8945  fbScore:0.8679   LR -> Group0: 2.8105e-06 / Group1: 5.6209e-06 / Group2: 8.4314e-06 / Group3: 1.4052e-04 / Group4: 1.4052e-04 / Group5: 1.4052e-04 / \n",
      " 110/ 136  <train> Loss:0.4544  Acc:0.8979  fbScore:0.8743   LR -> Group0: 2.6471e-06 / Group1: 5.2941e-06 / Group2: 7.9412e-06 / Group3: 1.3235e-04 / Group4: 1.3235e-04 / Group5: 1.3235e-04 / \n",
      " 120/ 136  <train> Loss:0.4366  Acc:0.9007  fbScore:0.8778   LR -> Group0: 2.4837e-06 / Group1: 4.9673e-06 / Group2: 7.4510e-06 / Group3: 1.2418e-04 / Group4: 1.2418e-04 / Group5: 1.2418e-04 / \n",
      " 130/ 136  <train> Loss:0.4297  Acc:0.9040  fbScore:0.8827   LR -> Group0: 2.3203e-06 / Group1: 4.6405e-06 / Group2: 6.9608e-06 / Group3: 1.1601e-04 / Group4: 1.1601e-04 / Group5: 1.1601e-04 / \n",
      "<train> Loss:0.4223  Acc:0.9058  fbScore:0.8852\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "075722a27509462b96b60f3c7072529d"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.5842  Acc:0.9388  fbScore:0.9090\n",
      "Checkpoints have been updated to the epoch 4 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   5/  5】   LR -> Group0: 2.2222e-06 / Group1: 4.4444e-06 / Group2: 6.6667e-06 / Group3: 1.1111e-04 / Group4: 1.1111e-04 / Group5: 1.1111e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f459927a7b4c449997693438d83e1bae"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:0.2587  Acc:0.9313  fbScore:0.7411   LR -> Group0: 2.0588e-06 / Group1: 4.1176e-06 / Group2: 6.1765e-06 / Group3: 1.0294e-04 / Group4: 1.0294e-04 / Group5: 1.0294e-04 / \n",
      "  20/ 136  <train> Loss:0.2611  Acc:0.9336  fbScore:0.7912   LR -> Group0: 1.8954e-06 / Group1: 3.7908e-06 / Group2: 5.6863e-06 / Group3: 9.4771e-05 / Group4: 9.4771e-05 / Group5: 9.4771e-05 / \n",
      "  30/ 136  <train> Loss:0.3527  Acc:0.9375  fbScore:0.8221   LR -> Group0: 1.7320e-06 / Group1: 3.4641e-06 / Group2: 5.1961e-06 / Group3: 8.6601e-05 / Group4: 8.6601e-05 / Group5: 8.6601e-05 / \n",
      "  40/ 136  <train> Loss:0.3153  Acc:0.9410  fbScore:0.8559   LR -> Group0: 1.5686e-06 / Group1: 3.1373e-06 / Group2: 4.7059e-06 / Group3: 7.8431e-05 / Group4: 7.8431e-05 / Group5: 7.8431e-05 / \n",
      "  50/ 136  <train> Loss:0.3128  Acc:0.9386  fbScore:0.8717   LR -> Group0: 1.4052e-06 / Group1: 2.8105e-06 / Group2: 4.2157e-06 / Group3: 7.0261e-05 / Group4: 7.0261e-05 / Group5: 7.0261e-05 / \n",
      "  60/ 136  <train> Loss:0.3062  Acc:0.9370  fbScore:0.8675   LR -> Group0: 1.2418e-06 / Group1: 2.4837e-06 / Group2: 3.7255e-06 / Group3: 6.2092e-05 / Group4: 6.2092e-05 / Group5: 6.2092e-05 / \n",
      "  70/ 136  <train> Loss:0.3190  Acc:0.9356  fbScore:0.8727   LR -> Group0: 1.0784e-06 / Group1: 2.1569e-06 / Group2: 3.2353e-06 / Group3: 5.3922e-05 / Group4: 5.3922e-05 / Group5: 5.3922e-05 / \n",
      "  80/ 136  <train> Loss:0.3150  Acc:0.9353  fbScore:0.8806   LR -> Group0: 9.1503e-07 / Group1: 1.8301e-06 / Group2: 2.7451e-06 / Group3: 4.5752e-05 / Group4: 4.5752e-05 / Group5: 4.5752e-05 / \n",
      "  90/ 136  <train> Loss:0.3127  Acc:0.9359  fbScore:0.8882   LR -> Group0: 7.5163e-07 / Group1: 1.5033e-06 / Group2: 2.2549e-06 / Group3: 3.7582e-05 / Group4: 3.7582e-05 / Group5: 3.7582e-05 / \n",
      " 100/ 136  <train> Loss:0.3078  Acc:0.9346  fbScore:0.8715   LR -> Group0: 5.8824e-07 / Group1: 1.1765e-06 / Group2: 1.7647e-06 / Group3: 2.9412e-05 / Group4: 2.9412e-05 / Group5: 2.9412e-05 / \n",
      " 110/ 136  <train> Loss:0.3010  Acc:0.9351  fbScore:0.8768   LR -> Group0: 4.2484e-07 / Group1: 8.4967e-07 / Group2: 1.2745e-06 / Group3: 2.1242e-05 / Group4: 2.1242e-05 / Group5: 2.1242e-05 / \n",
      " 120/ 136  <train> Loss:0.3019  Acc:0.9355  fbScore:0.8828   LR -> Group0: 2.6144e-07 / Group1: 5.2288e-07 / Group2: 7.8431e-07 / Group3: 1.3072e-05 / Group4: 1.3072e-05 / Group5: 1.3072e-05 / \n",
      " 130/ 136  <train> Loss:0.2988  Acc:0.9352  fbScore:0.8876   LR -> Group0: 9.8039e-08 / Group1: 1.9608e-07 / Group2: 2.9412e-07 / Group3: 4.9020e-06 / Group4: 4.9020e-06 / Group5: 4.9020e-06 / \n",
      "<train> Loss:0.3023  Acc:0.9350  fbScore:0.8894\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a88de1fafd7415797f7c7e8abcad75d"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.6661  Acc:0.9445  fbScore:0.9133\n",
      "Checkpoints have been updated to the epoch 5 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Evaluate Test Dataset\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "daed7cdad44b4e06bce6c50fb579264e"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss:0.8791  Acc:0.9392  fbScore:0.8874\n",
      "fb_score : 0.892047172664046\n",
      "\n",
      "\u001b[32mCross-validation loop : 5/5\u001b[0m\n",
      "Train  ->  label_1:404 / all:17374   (2.325%)\n",
      "Valid  ->  label_1:100 / all:4342   (2.303%)\n",
      "Choosed BertLstmExModel\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "InitLR:2e-05 / num_warmup_steps:68 / num_training_steps:680\n",
      "Use 4 GPUs\n",
      "Using device : cuda\n",
      "【Epoch   1/  5】   LR -> Group0: 0.0000e+00 / Group1: 0.0000e+00 / Group2: 0.0000e+00 / Group3: 0.0000e+00 / Group4: 0.0000e+00 / Group5: 0.0000e+00 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c66f1b86e3b4cfd86ca33dd9fcb94eb"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:2.9240  Acc:0.0219  fbScore:0.4991   LR -> Group0: 1.4706e-06 / Group1: 2.9412e-06 / Group2: 4.4118e-06 / Group3: 7.3529e-05 / Group4: 7.3529e-05 / Group5: 7.3529e-05 / \n",
      "  20/ 136  <train> Loss:2.7256  Acc:0.0199  fbScore:0.4466   LR -> Group0: 2.9412e-06 / Group1: 5.8824e-06 / Group2: 8.8235e-06 / Group3: 1.4706e-04 / Group4: 1.4706e-04 / Group5: 1.4706e-04 / \n",
      "  30/ 136  <train> Loss:2.7627  Acc:0.0203  fbScore:0.4588   LR -> Group0: 4.4118e-06 / Group1: 8.8235e-06 / Group2: 1.3235e-05 / Group3: 2.2059e-04 / Group4: 2.2059e-04 / Group5: 2.2059e-04 / \n",
      "  40/ 136  <train> Loss:2.7400  Acc:0.0201  fbScore:0.4496   LR -> Group0: 5.8824e-06 / Group1: 1.1765e-05 / Group2: 1.7647e-05 / Group3: 2.9412e-04 / Group4: 2.9412e-04 / Group5: 2.9412e-04 / \n",
      "  50/ 136  <train> Loss:2.8606  Acc:0.0216  fbScore:0.4598   LR -> Group0: 7.3529e-06 / Group1: 1.4706e-05 / Group2: 2.2059e-05 / Group3: 3.6765e-04 / Group4: 3.6765e-04 / Group5: 3.6765e-04 / \n",
      "  60/ 136  <train> Loss:2.8644  Acc:0.0221  fbScore:0.4711   LR -> Group0: 8.8235e-06 / Group1: 1.7647e-05 / Group2: 2.6471e-05 / Group3: 4.4118e-04 / Group4: 4.4118e-04 / Group5: 4.4118e-04 / \n",
      "  70/ 136  <train> Loss:2.8043  Acc:0.0218  fbScore:0.4669   LR -> Group0: 9.9673e-06 / Group1: 1.9935e-05 / Group2: 2.9902e-05 / Group3: 4.9837e-04 / Group4: 4.9837e-04 / Group5: 4.9837e-04 / \n",
      "  80/ 136  <train> Loss:2.7357  Acc:0.0214  fbScore:0.4645   LR -> Group0: 9.8039e-06 / Group1: 1.9608e-05 / Group2: 2.9412e-05 / Group3: 4.9020e-04 / Group4: 4.9020e-04 / Group5: 4.9020e-04 / \n",
      "  90/ 136  <train> Loss:2.7306  Acc:0.0224  fbScore:0.4753   LR -> Group0: 9.6405e-06 / Group1: 1.9281e-05 / Group2: 2.8922e-05 / Group3: 4.8203e-04 / Group4: 4.8203e-04 / Group5: 4.8203e-04 / \n",
      " 100/ 136  <train> Loss:2.6624  Acc:0.0223  fbScore:0.4795   LR -> Group0: 9.4771e-06 / Group1: 1.8954e-05 / Group2: 2.8431e-05 / Group3: 4.7386e-04 / Group4: 4.7386e-04 / Group5: 4.7386e-04 / \n",
      " 110/ 136  <train> Loss:2.5826  Acc:0.0224  fbScore:0.4803   LR -> Group0: 9.3137e-06 / Group1: 1.8627e-05 / Group2: 2.7941e-05 / Group3: 4.6569e-04 / Group4: 4.6569e-04 / Group5: 4.6569e-04 / \n",
      " 120/ 136  <train> Loss:2.4779  Acc:0.0285  fbScore:0.4775   LR -> Group0: 9.1503e-06 / Group1: 1.8301e-05 / Group2: 2.7451e-05 / Group3: 4.5752e-04 / Group4: 4.5752e-04 / Group5: 4.5752e-04 / \n",
      " 130/ 136  <train> Loss:2.4195  Acc:0.0748  fbScore:0.4974   LR -> Group0: 8.9869e-06 / Group1: 1.7974e-05 / Group2: 2.6961e-05 / Group3: 4.4935e-04 / Group4: 4.4935e-04 / Group5: 4.4935e-04 / \n",
      "<train> Loss:2.3792  Acc:0.1037  fbScore:0.5122\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "32c578ff43bf432a81d9e09c40bde7da"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:1.1149  Acc:0.7662  fbScore:0.8057\n",
      "Checkpoints have been updated to the epoch 1 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   2/  5】   LR -> Group0: 8.8889e-06 / Group1: 1.7778e-05 / Group2: 2.6667e-05 / Group3: 4.4444e-04 / Group4: 4.4444e-04 / Group5: 4.4444e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb327844827740ba8bc7492e8bb6b48f"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:1.2412  Acc:0.6820  fbScore:0.6692   LR -> Group0: 8.7255e-06 / Group1: 1.7451e-05 / Group2: 2.6176e-05 / Group3: 4.3627e-04 / Group4: 4.3627e-04 / Group5: 4.3627e-04 / \n",
      "  20/ 136  <train> Loss:1.2298  Acc:0.7855  fbScore:0.7139   LR -> Group0: 8.5621e-06 / Group1: 1.7124e-05 / Group2: 2.5686e-05 / Group3: 4.2810e-04 / Group4: 4.2810e-04 / Group5: 4.2810e-04 / \n",
      "  30/ 136  <train> Loss:1.0990  Acc:0.8141  fbScore:0.7147   LR -> Group0: 8.3987e-06 / Group1: 1.6797e-05 / Group2: 2.5196e-05 / Group3: 4.1993e-04 / Group4: 4.1993e-04 / Group5: 4.1993e-04 / \n",
      "  40/ 136  <train> Loss:0.9541  Acc:0.8369  fbScore:0.7173   LR -> Group0: 8.2353e-06 / Group1: 1.6471e-05 / Group2: 2.4706e-05 / Group3: 4.1176e-04 / Group4: 4.1176e-04 / Group5: 4.1176e-04 / \n",
      "  50/ 136  <train> Loss:0.9313  Acc:0.8545  fbScore:0.7454   LR -> Group0: 8.0719e-06 / Group1: 1.6144e-05 / Group2: 2.4216e-05 / Group3: 4.0359e-04 / Group4: 4.0359e-04 / Group5: 4.0359e-04 / \n",
      "  60/ 136  <train> Loss:0.9037  Acc:0.8556  fbScore:0.7589   LR -> Group0: 7.9085e-06 / Group1: 1.5817e-05 / Group2: 2.3725e-05 / Group3: 3.9542e-04 / Group4: 3.9542e-04 / Group5: 3.9542e-04 / \n",
      "  70/ 136  <train> Loss:0.8524  Acc:0.8569  fbScore:0.7774   LR -> Group0: 7.7451e-06 / Group1: 1.5490e-05 / Group2: 2.3235e-05 / Group3: 3.8725e-04 / Group4: 3.8725e-04 / Group5: 3.8725e-04 / \n",
      "  80/ 136  <train> Loss:0.8976  Acc:0.8580  fbScore:0.7804   LR -> Group0: 7.5817e-06 / Group1: 1.5163e-05 / Group2: 2.2745e-05 / Group3: 3.7908e-04 / Group4: 3.7908e-04 / Group5: 3.7908e-04 / \n",
      "  90/ 136  <train> Loss:0.8949  Acc:0.8507  fbScore:0.7861   LR -> Group0: 7.4183e-06 / Group1: 1.4837e-05 / Group2: 2.2255e-05 / Group3: 3.7092e-04 / Group4: 3.7092e-04 / Group5: 3.7092e-04 / \n",
      " 100/ 136  <train> Loss:0.8633  Acc:0.8465  fbScore:0.7914   LR -> Group0: 7.2549e-06 / Group1: 1.4510e-05 / Group2: 2.1765e-05 / Group3: 3.6275e-04 / Group4: 3.6275e-04 / Group5: 3.6275e-04 / \n",
      " 110/ 136  <train> Loss:0.8349  Acc:0.8539  fbScore:0.8038   LR -> Group0: 7.0915e-06 / Group1: 1.4183e-05 / Group2: 2.1275e-05 / Group3: 3.5458e-04 / Group4: 3.5458e-04 / Group5: 3.5458e-04 / \n",
      " 120/ 136  <train> Loss:0.8141  Acc:0.8566  fbScore:0.8095   LR -> Group0: 6.9281e-06 / Group1: 1.3856e-05 / Group2: 2.0784e-05 / Group3: 3.4641e-04 / Group4: 3.4641e-04 / Group5: 3.4641e-04 / \n",
      " 130/ 136  <train> Loss:0.7955  Acc:0.8572  fbScore:0.8106   LR -> Group0: 6.7647e-06 / Group1: 1.3529e-05 / Group2: 2.0294e-05 / Group3: 3.3824e-04 / Group4: 3.3824e-04 / Group5: 3.3824e-04 / \n",
      "<train> Loss:0.7831  Acc:0.8575  fbScore:0.8136\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "48236a761951431a9fe0120095474def"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.5469  Acc:0.8779  fbScore:0.8775\n",
      "Checkpoints have been updated to the epoch 2 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   3/  5】   LR -> Group0: 6.6667e-06 / Group1: 1.3333e-05 / Group2: 2.0000e-05 / Group3: 3.3333e-04 / Group4: 3.3333e-04 / Group5: 3.3333e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e96f7160a670494e913d1000a2bf8530"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:0.3660  Acc:0.9203  fbScore:0.9359   LR -> Group0: 6.5033e-06 / Group1: 1.3007e-05 / Group2: 1.9510e-05 / Group3: 3.2516e-04 / Group4: 3.2516e-04 / Group5: 3.2516e-04 / \n",
      "  20/ 136  <train> Loss:0.5520  Acc:0.9273  fbScore:0.9180   LR -> Group0: 6.3399e-06 / Group1: 1.2680e-05 / Group2: 1.9020e-05 / Group3: 3.1699e-04 / Group4: 3.1699e-04 / Group5: 3.1699e-04 / \n",
      "  30/ 136  <train> Loss:0.4623  Acc:0.9344  fbScore:0.8989   LR -> Group0: 6.1765e-06 / Group1: 1.2353e-05 / Group2: 1.8529e-05 / Group3: 3.0882e-04 / Group4: 3.0882e-04 / Group5: 3.0882e-04 / \n",
      "  40/ 136  <train> Loss:0.4398  Acc:0.9270  fbScore:0.8966   LR -> Group0: 6.0131e-06 / Group1: 1.2026e-05 / Group2: 1.8039e-05 / Group3: 3.0065e-04 / Group4: 3.0065e-04 / Group5: 3.0065e-04 / \n",
      "  50/ 136  <train> Loss:0.4953  Acc:0.9320  fbScore:0.9047   LR -> Group0: 5.8497e-06 / Group1: 1.1699e-05 / Group2: 1.7549e-05 / Group3: 2.9248e-04 / Group4: 2.9248e-04 / Group5: 2.9248e-04 / \n",
      "  60/ 136  <train> Loss:0.5463  Acc:0.9220  fbScore:0.8974   LR -> Group0: 5.6863e-06 / Group1: 1.1373e-05 / Group2: 1.7059e-05 / Group3: 2.8431e-04 / Group4: 2.8431e-04 / Group5: 2.8431e-04 / \n",
      "  70/ 136  <train> Loss:0.5609  Acc:0.9062  fbScore:0.8696   LR -> Group0: 5.5229e-06 / Group1: 1.1046e-05 / Group2: 1.6569e-05 / Group3: 2.7614e-04 / Group4: 2.7614e-04 / Group5: 2.7614e-04 / \n",
      "  80/ 136  <train> Loss:0.5411  Acc:0.9039  fbScore:0.8505   LR -> Group0: 5.3595e-06 / Group1: 1.0719e-05 / Group2: 1.6078e-05 / Group3: 2.6797e-04 / Group4: 2.6797e-04 / Group5: 2.6797e-04 / \n",
      "  90/ 136  <train> Loss:0.5695  Acc:0.9057  fbScore:0.8417   LR -> Group0: 5.1961e-06 / Group1: 1.0392e-05 / Group2: 1.5588e-05 / Group3: 2.5980e-04 / Group4: 2.5980e-04 / Group5: 2.5980e-04 / \n",
      " 100/ 136  <train> Loss:0.5570  Acc:0.9013  fbScore:0.8363   LR -> Group0: 5.0327e-06 / Group1: 1.0065e-05 / Group2: 1.5098e-05 / Group3: 2.5163e-04 / Group4: 2.5163e-04 / Group5: 2.5163e-04 / \n",
      " 110/ 136  <train> Loss:0.5549  Acc:0.8969  fbScore:0.8424   LR -> Group0: 4.8693e-06 / Group1: 9.7386e-06 / Group2: 1.4608e-05 / Group3: 2.4346e-04 / Group4: 2.4346e-04 / Group5: 2.4346e-04 / \n",
      " 120/ 136  <train> Loss:0.5427  Acc:0.8951  fbScore:0.8378   LR -> Group0: 4.7059e-06 / Group1: 9.4118e-06 / Group2: 1.4118e-05 / Group3: 2.3529e-04 / Group4: 2.3529e-04 / Group5: 2.3529e-04 / \n",
      " 130/ 136  <train> Loss:0.5562  Acc:0.8983  fbScore:0.8280   LR -> Group0: 4.5425e-06 / Group1: 9.0850e-06 / Group2: 1.3627e-05 / Group3: 2.2712e-04 / Group4: 2.2712e-04 / Group5: 2.2712e-04 / \n",
      "<train> Loss:0.5468  Acc:0.8996  fbScore:0.8268\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba6373f5438a499cb43ce53c7ca77535"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.6122  Acc:0.9127  fbScore:0.8943\n",
      "Checkpoints have been updated to the epoch 3 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   4/  5】   LR -> Group0: 4.4444e-06 / Group1: 8.8889e-06 / Group2: 1.3333e-05 / Group3: 2.2222e-04 / Group4: 2.2222e-04 / Group5: 2.2222e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "560d810898d743f69468d6fcdc6e977f"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:0.3581  Acc:0.9070  fbScore:0.9064   LR -> Group0: 4.2810e-06 / Group1: 8.5621e-06 / Group2: 1.2843e-05 / Group3: 2.1405e-04 / Group4: 2.1405e-04 / Group5: 2.1405e-04 / \n",
      "  20/ 136  <train> Loss:0.3479  Acc:0.9176  fbScore:0.9285   LR -> Group0: 4.1176e-06 / Group1: 8.2353e-06 / Group2: 1.2353e-05 / Group3: 2.0588e-04 / Group4: 2.0588e-04 / Group5: 2.0588e-04 / \n",
      "  30/ 136  <train> Loss:0.4823  Acc:0.9234  fbScore:0.9222   LR -> Group0: 3.9542e-06 / Group1: 7.9085e-06 / Group2: 1.1863e-05 / Group3: 1.9771e-04 / Group4: 1.9771e-04 / Group5: 1.9771e-04 / \n",
      "  40/ 136  <train> Loss:0.4838  Acc:0.9213  fbScore:0.9201   LR -> Group0: 3.7908e-06 / Group1: 7.5817e-06 / Group2: 1.1373e-05 / Group3: 1.8954e-04 / Group4: 1.8954e-04 / Group5: 1.8954e-04 / \n",
      "  50/ 136  <train> Loss:0.4666  Acc:0.9120  fbScore:0.8918   LR -> Group0: 3.6275e-06 / Group1: 7.2549e-06 / Group2: 1.0882e-05 / Group3: 1.8137e-04 / Group4: 1.8137e-04 / Group5: 1.8137e-04 / \n",
      "  60/ 136  <train> Loss:0.4561  Acc:0.9091  fbScore:0.8919   LR -> Group0: 3.4641e-06 / Group1: 6.9281e-06 / Group2: 1.0392e-05 / Group3: 1.7320e-04 / Group4: 1.7320e-04 / Group5: 1.7320e-04 / \n",
      "  70/ 136  <train> Loss:0.4292  Acc:0.9118  fbScore:0.8715   LR -> Group0: 3.3007e-06 / Group1: 6.6013e-06 / Group2: 9.9020e-06 / Group3: 1.6503e-04 / Group4: 1.6503e-04 / Group5: 1.6503e-04 / \n",
      "  80/ 136  <train> Loss:0.4730  Acc:0.9150  fbScore:0.8718   LR -> Group0: 3.1373e-06 / Group1: 6.2745e-06 / Group2: 9.4118e-06 / Group3: 1.5686e-04 / Group4: 1.5686e-04 / Group5: 1.5686e-04 / \n",
      "  90/ 136  <train> Loss:0.4496  Acc:0.9175  fbScore:0.8789   LR -> Group0: 2.9739e-06 / Group1: 5.9477e-06 / Group2: 8.9216e-06 / Group3: 1.4869e-04 / Group4: 1.4869e-04 / Group5: 1.4869e-04 / \n",
      " 100/ 136  <train> Loss:0.4267  Acc:0.9221  fbScore:0.8872   LR -> Group0: 2.8105e-06 / Group1: 5.6209e-06 / Group2: 8.4314e-06 / Group3: 1.4052e-04 / Group4: 1.4052e-04 / Group5: 1.4052e-04 / \n",
      " 110/ 136  <train> Loss:0.4081  Acc:0.9252  fbScore:0.8830   LR -> Group0: 2.6471e-06 / Group1: 5.2941e-06 / Group2: 7.9412e-06 / Group3: 1.3235e-04 / Group4: 1.3235e-04 / Group5: 1.3235e-04 / \n",
      " 120/ 136  <train> Loss:0.4082  Acc:0.9270  fbScore:0.8805   LR -> Group0: 2.4837e-06 / Group1: 4.9673e-06 / Group2: 7.4510e-06 / Group3: 1.2418e-04 / Group4: 1.2418e-04 / Group5: 1.2418e-04 / \n",
      " 130/ 136  <train> Loss:0.3965  Acc:0.9278  fbScore:0.8840   LR -> Group0: 2.3203e-06 / Group1: 4.6405e-06 / Group2: 6.9608e-06 / Group3: 1.1601e-04 / Group4: 1.1601e-04 / Group5: 1.1601e-04 / \n",
      "<train> Loss:0.3951  Acc:0.9271  fbScore:0.8863\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4afbf65cf4714004937cf5b413980035"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.6362  Acc:0.9265  fbScore:0.8871\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   5/  5】   LR -> Group0: 2.2222e-06 / Group1: 4.4444e-06 / Group2: 6.6667e-06 / Group3: 1.1111e-04 / Group4: 1.1111e-04 / Group5: 1.1111e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f5d8737680d46698d364b6b82fe5fdd"
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 136  <train> Loss:0.4972  Acc:0.9320  fbScore:0.8705   LR -> Group0: 2.0588e-06 / Group1: 4.1176e-06 / Group2: 6.1765e-06 / Group3: 1.0294e-04 / Group4: 1.0294e-04 / Group5: 1.0294e-04 / \n",
      "  20/ 136  <train> Loss:0.7013  Acc:0.9316  fbScore:0.8879   LR -> Group0: 1.8954e-06 / Group1: 3.7908e-06 / Group2: 5.6863e-06 / Group3: 9.4771e-05 / Group4: 9.4771e-05 / Group5: 9.4771e-05 / \n",
      "  30/ 136  <train> Loss:0.5874  Acc:0.9224  fbScore:0.8606   LR -> Group0: 1.7320e-06 / Group1: 3.4641e-06 / Group2: 5.1961e-06 / Group3: 8.6601e-05 / Group4: 8.6601e-05 / Group5: 8.6601e-05 / \n",
      "  40/ 136  <train> Loss:0.5116  Acc:0.9227  fbScore:0.8560   LR -> Group0: 1.5686e-06 / Group1: 3.1373e-06 / Group2: 4.7059e-06 / Group3: 7.8431e-05 / Group4: 7.8431e-05 / Group5: 7.8431e-05 / \n",
      "  50/ 136  <train> Loss:0.4760  Acc:0.9237  fbScore:0.8320   LR -> Group0: 1.4052e-06 / Group1: 2.8105e-06 / Group2: 4.2157e-06 / Group3: 7.0261e-05 / Group4: 7.0261e-05 / Group5: 7.0261e-05 / \n",
      "  60/ 136  <train> Loss:0.4429  Acc:0.9255  fbScore:0.8499   LR -> Group0: 1.2418e-06 / Group1: 2.4837e-06 / Group2: 3.7255e-06 / Group3: 6.2092e-05 / Group4: 6.2092e-05 / Group5: 6.2092e-05 / \n",
      "  70/ 136  <train> Loss:0.4158  Acc:0.9278  fbScore:0.8613   LR -> Group0: 1.0784e-06 / Group1: 2.1569e-06 / Group2: 3.2353e-06 / Group3: 5.3922e-05 / Group4: 5.3922e-05 / Group5: 5.3922e-05 / \n",
      "  80/ 136  <train> Loss:0.3925  Acc:0.9307  fbScore:0.8730   LR -> Group0: 9.1503e-07 / Group1: 1.8301e-06 / Group2: 2.7451e-06 / Group3: 4.5752e-05 / Group4: 4.5752e-05 / Group5: 4.5752e-05 / \n",
      "  90/ 136  <train> Loss:0.3770  Acc:0.9318  fbScore:0.8787   LR -> Group0: 7.5163e-07 / Group1: 1.5033e-06 / Group2: 2.2549e-06 / Group3: 3.7582e-05 / Group4: 3.7582e-05 / Group5: 3.7582e-05 / \n",
      " 100/ 136  <train> Loss:0.3640  Acc:0.9341  fbScore:0.8868   LR -> Group0: 5.8824e-07 / Group1: 1.1765e-06 / Group2: 1.7647e-06 / Group3: 2.9412e-05 / Group4: 2.9412e-05 / Group5: 2.9412e-05 / \n",
      " 110/ 136  <train> Loss:0.3523  Acc:0.9359  fbScore:0.8931   LR -> Group0: 4.2484e-07 / Group1: 8.4967e-07 / Group2: 1.2745e-06 / Group3: 2.1242e-05 / Group4: 2.1242e-05 / Group5: 2.1242e-05 / \n",
      " 120/ 136  <train> Loss:0.3379  Acc:0.9378  fbScore:0.8901   LR -> Group0: 2.6144e-07 / Group1: 5.2288e-07 / Group2: 7.8431e-07 / Group3: 1.3072e-05 / Group4: 1.3072e-05 / Group5: 1.3072e-05 / \n",
      " 130/ 136  <train> Loss:0.3275  Acc:0.9391  fbScore:0.8951   LR -> Group0: 9.8039e-08 / Group1: 1.9608e-07 / Group2: 2.9412e-07 / Group3: 4.9020e-06 / Group4: 4.9020e-06 / Group5: 4.9020e-06 / \n",
      "<train> Loss:0.3242  Acc:0.9393  fbScore:0.8911\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e08ce31287614701af57327133ab6374"
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.8244  Acc:0.9438  fbScore:0.8782\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Evaluate Test Dataset\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60a71435263b4f15901a93887dbfc818"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss:0.6357  Acc:0.9145  fbScore:0.8889\n",
      "fb_score : 0.8957654723127035\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "logs.keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['fit_history', 'test_preds_labels', 'test_fb_score'])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "logs['test_fb_score'][1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9067357512953368"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "for i in range(hps.cv_n):\n",
    "    fb_score = logs['test_fb_score'][i]\n",
    "    print(fb_score)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9028831562974203\n",
      "0.9067357512953368\n",
      "0.884621200665356\n",
      "0.892047172664046\n",
      "0.8957654723127035\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "test_pred_df = pd.DataFrame(columns=[f\"cv{i}\" for i in range(hps.cv_n)] + ['cv_ensemble', 'label'])\n",
    "test_pred_df['label'] = logs['test_preds_labels'][0]['labels']\n",
    "for i in range(hps.cv_n):\n",
    "    test_pred_df[f\"cv{i}\"] = logs['test_preds_labels'][i]['preds']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_pred_df['cv_ensemble'] = test_pred_df.loc[:, 'cv0':'cv4'].mean(axis=1).map(lambda x: 1 if x >= 0.5 else 0)\n",
    "\n",
    "\n",
    "display(test_pred_df)\n",
    "display(test_pred_df.describe())"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv0</th>\n",
       "      <th>cv1</th>\n",
       "      <th>cv2</th>\n",
       "      <th>cv3</th>\n",
       "      <th>cv4</th>\n",
       "      <th>cv_ensemble</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5429 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cv0  cv1  cv2  cv3  cv4  cv_ensemble  label\n",
       "0     0.0  0.0  0.0  0.0  0.0            0    0.0\n",
       "1     0.0  0.0  0.0  0.0  0.0            0    0.0\n",
       "2     0.0  0.0  0.0  0.0  0.0            0    0.0\n",
       "3     0.0  0.0  0.0  0.0  0.0            0    0.0\n",
       "4     0.0  0.0  0.0  0.0  0.0            0    0.0\n",
       "...   ...  ...  ...  ...  ...          ...    ...\n",
       "5424  0.0  0.0  0.0  0.0  0.0            0    0.0\n",
       "5425  0.0  0.0  0.0  0.0  1.0            0    0.0\n",
       "5426  0.0  0.0  0.0  0.0  0.0            0    0.0\n",
       "5427  0.0  0.0  0.0  0.0  0.0            0    0.0\n",
       "5428  0.0  0.0  0.0  0.0  0.0            0    0.0\n",
       "\n",
       "[5429 rows x 7 columns]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv0</th>\n",
       "      <th>cv1</th>\n",
       "      <th>cv2</th>\n",
       "      <th>cv3</th>\n",
       "      <th>cv4</th>\n",
       "      <th>cv_ensemble</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5429.000000</td>\n",
       "      <td>5429.000000</td>\n",
       "      <td>5429.000000</td>\n",
       "      <td>5429.000000</td>\n",
       "      <td>5429.000000</td>\n",
       "      <td>5429.000000</td>\n",
       "      <td>5429.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.076626</td>\n",
       "      <td>0.071468</td>\n",
       "      <td>0.080862</td>\n",
       "      <td>0.081046</td>\n",
       "      <td>0.106834</td>\n",
       "      <td>0.076441</td>\n",
       "      <td>0.023209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.266021</td>\n",
       "      <td>0.257629</td>\n",
       "      <td>0.272648</td>\n",
       "      <td>0.272931</td>\n",
       "      <td>0.308930</td>\n",
       "      <td>0.265727</td>\n",
       "      <td>0.150580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cv0          cv1          cv2          cv3          cv4  \\\n",
       "count  5429.000000  5429.000000  5429.000000  5429.000000  5429.000000   \n",
       "mean      0.076626     0.071468     0.080862     0.081046     0.106834   \n",
       "std       0.266021     0.257629     0.272648     0.272931     0.308930   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "       cv_ensemble        label  \n",
       "count  5429.000000  5429.000000  \n",
       "mean      0.076441     0.023209  \n",
       "std       0.265727     0.150580  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     0.000000  \n",
       "50%       0.000000     0.000000  \n",
       "75%       0.000000     0.000000  \n",
       "max       1.000000     1.000000  "
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "cv_ensemble_fb_score = fbeta_score(y_true=test_pred_df['label'], y_pred=test_pred_df['cv_ensemble'], beta=7.0)\n",
    "print(f\"CV_Ensemble_Fb_score : {cv_ensemble_fb_score}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CV_Ensemble_Fb_score : 0.9030201851570798\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('srws': conda)"
  },
  "interpreter": {
   "hash": "7f2d3241de56b0fa9ccb32ec1dbd92e097a59df5b8abdff3a1f1414152af23a6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}