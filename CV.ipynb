{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import transformers\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import datetime as dt\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0,1,6,7'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "model_name_dict = {\n",
    "    \"PubMedBERT\": \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\",\n",
    "    \"biomed_roberta_base\": \"allenai/biomed_roberta_base\",\n",
    "    \"Bio_ClinicalBERT\":\"emilyalsentzer/Bio_ClinicalBERT\",\n",
    "}\n",
    "\n",
    "class Hparams:\n",
    "    def __init__(self):\n",
    "        self.random_seed = 0 # BAD:2021\n",
    "        self.data_dir = './data'\n",
    "        self.output_dir = './outputs'\n",
    "        self.batch_size = 128\n",
    "        self.token_max_length = 512\n",
    "        self.model_name = model_name_dict['PubMedBERT']\n",
    "        self.num_epochs = 5\n",
    "        self.class_1_weight = 150\n",
    "        self.initial_lr = 2e-5  # 2e-5\n",
    "        self.model_type = 'lstm_ex'  # cnn, lstm, lstm_ex\n",
    "        self.upsample_pos_n = 1\n",
    "        self.use_col = 'title_abstract'  # title, abstract, title_abstract\n",
    "        self.train_argument = True\n",
    "        self.test_size = 0.0  # 0.2\n",
    "        self.cv_n = 5\n",
    "    \n",
    "\n",
    "hps = Hparams()\n",
    "\n",
    "\n",
    "def seed_torch(seed:int):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(hps.random_seed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DataFrame"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "orig_df = pd.read_csv(os.path.join(hps.data_dir, 'train.csv'), index_col=0)\n",
    "submit_df = pd.read_csv(os.path.join(hps.data_dir, 'test.csv'), index_col=0)\n",
    "sample_submit_df = pd.read_csv(os.path.join(hps.data_dir, 'sample_submit.csv'), index_col=0, header=None, names=['judgement'])\n",
    "\n",
    "# 修正\n",
    "orig_df.loc[2488, 'judgement'] = 0\n",
    "orig_df.loc[7708, 'judgement'] = 0\n",
    "\n",
    "# 補完\n",
    "orig_df['abstract'].fillna('', inplace=True)\n",
    "orig_df['title_abstract'] = orig_df.title + orig_df.abstract\n",
    "\n",
    "submit_df['abstract'].fillna('', inplace=True)\n",
    "submit_df['title_abstract'] = submit_df.title + submit_df.abstract\n",
    "submit_df['judgement'] = -1\n",
    "submit_df.reset_index(inplace=True, drop=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross Validations SetUp"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "if hps.test_size > 0.0:\n",
    "    train_df, test_df = train_test_split(orig_df, test_size=hps.test_size, random_state=hps.random_seed, shuffle=True, stratify=orig_df.judgement)\n",
    "else:\n",
    "    train_df = orig_df.copy()\n",
    "    test_df = orig_df.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def get_cv_number(df, cv_n):\n",
    "\n",
    "    df['cv_id'] = 0\n",
    "\n",
    "    neg_idx = df.loc[df.judgement==0].index.tolist()\n",
    "    pos_idx = df.loc[df.judgement==1].index.tolist()\n",
    "\n",
    "    neg_idx = [list(a) for a in list(np.array_split(random.sample(neg_idx, len(neg_idx)), cv_n))]\n",
    "    pos_idx = [list(a) for a in list(np.array_split(random.sample(pos_idx, len(pos_idx)), cv_n))]\n",
    "\n",
    "    for i in range(cv_n):\n",
    "        n_id = neg_idx[i]\n",
    "        p_id = pos_idx[i]\n",
    "        df.loc[n_id, 'cv_id'] = i\n",
    "        df.loc[p_id, 'cv_id'] = i\n",
    "\n",
    "    df = df.sort_index()\n",
    "\n",
    "    for i in range(cv_n):\n",
    "        tmp_df = df.loc[df.cv_id==i]\n",
    "        print('cv_id:', i, '->  pos:', len(tmp_df.loc[tmp_df.judgement==1]), ' / neg:', len(tmp_df.loc[tmp_df.judgement==0]), ' / all:', len(tmp_df))\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = get_cv_number(train_df, cv_n=hps.cv_n)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cv_id: 0 ->  pos: 126  / neg: 5303  / all: 5429\n",
      "cv_id: 1 ->  pos: 126  / neg: 5303  / all: 5429\n",
      "cv_id: 2 ->  pos: 126  / neg: 5303  / all: 5429\n",
      "cv_id: 3 ->  pos: 126  / neg: 5303  / all: 5429\n",
      "cv_id: 4 ->  pos: 126  / neg: 5303  / all: 5429\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hugging Face"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "base_tokenizer = transformers.AutoTokenizer.from_pretrained(hps.model_name)\n",
    "\n",
    "bert_config = transformers.AutoConfig.from_pretrained(hps.model_name)\n",
    "bert_config.output_hidden_states = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DataSet / DataLoader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, use_col='title_abstract', token_max_length=512, argument=False, upsample_pos_n=1):\n",
    "\n",
    "        if upsample_pos_n > 1:\n",
    "            df_pos = df.loc[df.judgement==1]\n",
    "            df_pos = pd.concat([df_pos for i in range(int(upsample_pos_n))], axis=0).reset_index(drop=True)\n",
    "            df_neg = df.loc[df.judgement==0]\n",
    "            self.df = pd.concat([df_pos, df_neg], axis=0).reset_index(drop=True)\n",
    "        else:\n",
    "            self.df = df\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.argument = argument\n",
    "        self.use_col = use_col\n",
    "\n",
    "    def text_argument(self, text, drop_min_seq=3, seq_sort=True):\n",
    "        seq_list = text.split('. ')\n",
    "        seq_len = len(seq_list)\n",
    "        if seq_len >= drop_min_seq:\n",
    "            orig_idx_list = list(range(0, seq_len))\n",
    "            idx_list = random.sample(orig_idx_list, random.randint(round(seq_len * 0.7), seq_len))\n",
    "            if seq_sort:\n",
    "                idx_list = sorted(idx_list)\n",
    "            insert_idx_list = random.sample(orig_idx_list, random.randint(0, seq_len//3))\n",
    "            for x in insert_idx_list:\n",
    "                idx = random.randint(0, len(idx_list))\n",
    "                idx_list.insert(idx, x)\n",
    "            seq_list = [seq_list[i] for i in idx_list]\n",
    "        text = '. '.join(seq_list)\n",
    "        return text\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        text = self.df.loc[idx, self.use_col]\n",
    "\n",
    "        if self.argument:\n",
    "            text = self.text_argument(text, drop_min_seq=3, seq_sort=True)\n",
    "\n",
    "        token = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            padding = 'max_length', max_length = hps.token_max_length, truncation = True,\n",
    "            return_attention_mask=True, return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        sample = dict(\n",
    "            input_ids=token['input_ids'][0],\n",
    "            attention_mask=token['attention_mask'][0]\n",
    "        )\n",
    "        \n",
    "        label = torch.tensor(self.df.loc[idx, 'judgement'], dtype=torch.float32)\n",
    "        return sample, label\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class BertLstmModel(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.bert = transformers.AutoModel.from_pretrained(hps.model_name, config=bert_config)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.regressor = nn.Linear(hidden_size*2, 1)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        self.lstm.flatten_parameters()\n",
    "        out, _ = self.lstm(outputs['last_hidden_state'], None)\n",
    "        out = self.leakyrelu(out)\n",
    "        sequence_output = out[:, -1, :]\n",
    "        output = self.dropout(sequence_output)\n",
    "        logits = torch.flatten(self.regressor(output))\n",
    "        return logits"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "class BertLstmExModel(nn.Module):\n",
    "    def __init__(self, hidden_size, config, use_hidden_n=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = transformers.AutoModel.from_pretrained(hps.model_name, config=bert_config)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.use_hidden_n = use_hidden_n\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.conv1d = nn.Conv1d(in_channels=self.use_hidden_n, out_channels=1, kernel_size=3, padding='same')\n",
    "        self.regressor = nn.Linear(self.hidden_size*2, 1)\n",
    "        \n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_states_list = [outputs['hidden_states'][-1*i] for i in range(1, self.use_hidden_n+1)]\n",
    "        self.lstm.flatten_parameters()\n",
    "        out_list = [\n",
    "            self.dropout(\n",
    "                self.leakyrelu(\n",
    "                    self.lstm(hidden_state, None)[0]\n",
    "                )[:, -1, :]\n",
    "            ).view(-1, 1, self.hidden_size*2)  # (batch, use_hidden_n, hidden_size*2)\n",
    "        for hidden_state in hidden_states_list]\n",
    "\n",
    "        out = torch.cat(out_list, dim=1)\n",
    "\n",
    "        out = self.dropout(self.leakyrelu(self.conv1d(out)))\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        logits = torch.flatten(self.regressor(out))\n",
    "        return logits"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Checkpoint"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "class ModelCheckpoint:\n",
    "    def __init__(self, save_dir:str, save_name:str, cv_id:int):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        self.cv_id = cv_id\n",
    "        self.save_dir = save_dir\n",
    "        self.save_name = save_name\n",
    "        self.best_loss = self.best_acc = self.best_fbeta_score = 0.0\n",
    "\n",
    "    def get_checkpoint_name(self):\n",
    "        checkpoint_name = f\"{self.save_name.replace('/', '_')}_cv{self.cv_id}.pth\"\n",
    "        checkpoint_name = os.path.join(self.save_dir, checkpoint_name)\n",
    "        return checkpoint_name\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        torch.save(model.state_dict(), self.get_checkpoint_name())\n",
    "\n",
    "    def load_checkpoint(self, model=None, manual_name=None):\n",
    "        if manual_name is None:\n",
    "            checkpoint_name = self.get_checkpoint_name()\n",
    "        else:\n",
    "            checkpoint_name = manual_name\n",
    "        print(checkpoint_name)\n",
    "        model.load_state_dict(torch.load(checkpoint_name))\n",
    "        return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fit"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def fit(dataloaders, model, optimizer, num_epochs, device, batch_size, lr_scheduler, cv_id):\n",
    "\n",
    "    seed_torch(hps.random_seed)\n",
    "\n",
    "    history = {\n",
    "        'train':{'loss':[], 'acc':[], 'fbscore':[]},\n",
    "        'val':{'loss':[], 'acc':[], 'fbscore':[]},\n",
    "        'lr':[],\n",
    "    }\n",
    "\n",
    "    checkpoint = ModelCheckpoint(save_dir='cross_validation_weights', save_name='bert_text_classification', cv_id=cv_id)\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    print(f\"Using device : {device}\")\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"【Epoch {epoch+1: 3}/{num_epochs: 3}】   LR -> \", end='')\n",
    "        for i, params in enumerate(optimizer.param_groups):\n",
    "            print(f\"Group{i}: {params['lr']:.4e}\", end=' / ')\n",
    "        print('')\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            running_fbeta_score = 0.0\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            for i, (inputs, labels) in enumerate(tqdm(dataloaders[phase])):\n",
    "                input_ids = inputs['input_ids']\n",
    "                attention_mask = inputs['attention_mask']\n",
    "                input_ids = input_ids.to(device)\n",
    "                attention_mask = attention_mask.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    logits_outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    pos_weight = torch.tensor([hps.class_1_weight for i in range(input_ids.size(0))]).to(device)\n",
    "                    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "                    loss = criterion(logits_outputs, labels)\n",
    "\n",
    "                    outputs = torch.sigmoid(logits_outputs)\n",
    "                    preds = torch.where(outputs >= 0.5, 1, 0)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        lr_scheduler.step()\n",
    "\n",
    "                running_loss += loss.item() * input_ids.size(0)\n",
    "                running_corrects += torch.sum(preds == labels)\n",
    "                running_fbeta_score += fbeta_score(labels.to('cpu').detach().numpy(), preds.to('cpu').detach().numpy(), beta=7.0, zero_division=0) * input_ids.size(0)    \n",
    "\n",
    "                if phase == 'train':\n",
    "                    if i % 10 == 9:\n",
    "                        total_num = float((i * batch_size) + input_ids.size(0))\n",
    "                        print(f\"{i+1: 4}/{len(dataloaders[phase]): 4}  <{phase}> Loss:{(running_loss/total_num):.4f}  Acc:{(running_corrects/total_num):.4f}  fbScore:{(running_fbeta_score/total_num):.4f}   LR -> \", end='')\n",
    "                        for i, params in enumerate(optimizer.param_groups):\n",
    "                            print(f\"Group{i}: {params['lr']:.4e}\", end=' / ')\n",
    "                            if isinstance(optimizer.param_groups[0]['lr'], float):\n",
    "                                history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "                            else:\n",
    "                                history['lr'].append(optimizer.param_groups[0]['lr'].item())\n",
    "                        print('')\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n",
    "            epoch_fbscore = running_fbeta_score / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            print(f\"<{phase}> Loss:{epoch_loss:.4f}  Acc:{epoch_acc:.4f}  fbScore:{epoch_fbscore:.4f}\")\n",
    "\n",
    "            history[phase]['loss'].append(epoch_loss)\n",
    "            history[phase]['acc'].append(epoch_acc.item())\n",
    "            history[phase]['fbscore'].append(epoch_fbscore)\n",
    "\n",
    "\n",
    "            if phase == 'val' and epoch_fbscore > checkpoint.best_fbeta_score:\n",
    "                print(f\"Checkpoints have been updated to the epoch {epoch+1} weights.\")\n",
    "                checkpoint.best_loss = epoch_loss\n",
    "                checkpoint.best_acc = epoch_acc\n",
    "                checkpoint.best_fbeta_score = epoch_fbscore\n",
    "                checkpoint.best_epoch = epoch+1\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print('-' * 150)\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    checkpoint.save_checkpoint(model)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return model, history"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def inference(model, dataloader, device, evaluate=True):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    running_fbeta_score = 0.0\n",
    "\n",
    "    preds_labels_dict = dict(preds = np.empty(0), labels = np.empty(0))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(tqdm(dataloader)):\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits_outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            if evaluate:\n",
    "                pos_weight = torch.tensor([hps.class_1_weight for i in range(input_ids.size(0))]).to(device)\n",
    "                criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "                loss = criterion(logits_outputs, labels)\n",
    "\n",
    "            outputs = torch.sigmoid(logits_outputs)\n",
    "            preds = torch.where(outputs >= 0.5, 1, 0)\n",
    "            \n",
    "            if evaluate:\n",
    "                running_loss += loss.item() * input_ids.size(0)\n",
    "                running_corrects += torch.sum(preds == labels)\n",
    "                running_fbeta_score += fbeta_score(labels.to('cpu').detach().numpy(), preds.to('cpu').detach().numpy(), beta=7.0, zero_division=0) * input_ids.size(0)\n",
    "\n",
    "            preds_labels_dict['preds']  = np.hstack([preds_labels_dict['preds'], preds.to('cpu').detach().numpy().copy()])\n",
    "            preds_labels_dict['labels']  = np.hstack([preds_labels_dict['labels'], labels.to('cpu').detach().numpy().copy()])\n",
    "    \n",
    "    if evaluate:\n",
    "        loss = running_loss / len(dataloader.dataset)\n",
    "        acc = running_corrects / len(dataloader.dataset)\n",
    "        fbscore = running_fbeta_score / len(dataloader.dataset)\n",
    "        print(f\"Loss:{loss:.4f}  Acc:{acc:.4f}  fbScore:{fbscore:.4f}\")\n",
    "    return preds_labels_dict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CrossValidation Loop"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def model_setup(model, dataloaders):\n",
    "\n",
    "    optimizer = optim.AdamW(\n",
    "        params=[\n",
    "            {'params': model.bert.embeddings.parameters(), 'lr': 1e-5},\n",
    "            {'params': model.bert.encoder.parameters(), 'lr': 2e-5},\n",
    "            {'params': model.bert.pooler.parameters(), 'lr': 3e-5},\n",
    "            {'params': model.lstm.parameters(), 'lr': 5e-4},\n",
    "            {'params': model.conv1d.parameters(), 'lr': 5e-4},\n",
    "            {'params': model.regressor.parameters(), 'lr': 5e-4}\n",
    "        ]\n",
    "    )\n",
    "    num_warmup_steps = round(hps.num_epochs * len(dataloaders['train']) * 0.1)\n",
    "    num_training_steps = round(hps.num_epochs * len(dataloaders['train']))\n",
    "    print(f\"InitLR:{hps.initial_lr} / num_warmup_steps:{num_warmup_steps} / num_training_steps:{num_training_steps}\")\n",
    "    lr_scheduler = transformers.get_linear_schedule_with_warmup(optimizer=optimizer, num_warmup_steps=num_warmup_steps, \n",
    "                                                                num_training_steps=num_training_steps, last_epoch=-1)\n",
    "\n",
    "    return (optimizer, lr_scheduler)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def cross_validation(cv_n, orig_df, test_df):\n",
    "\n",
    "    logs = {\n",
    "        'fit_history':[],\n",
    "        'test_preds_labels':[],\n",
    "        'test_fb_score':[],\n",
    "    }\n",
    "\n",
    "    for i in range(cv_n):\n",
    "        print('\\033[32m' + f\"Cross-validation loop : {i+1}/{cv_n}\" + '\\033[0m')\n",
    "\n",
    "        # DataFrame\n",
    "        train_df = orig_df.loc[orig_df.cv_id != i].copy().reset_index(drop=True)\n",
    "        valid_df = orig_df.loc[orig_df.cv_id == i].copy().reset_index(drop=True)\n",
    "        test_df = test_df.reset_index(drop=True)\n",
    "        print(f\"Train  ->  label_1:{train_df.judgement.sum()} / all:{train_df.judgement.count()}   ({train_df.judgement.sum() / train_df.judgement.count() * 100:.3f}%)\")\n",
    "        print(f\"Valid  ->  label_1:{valid_df.judgement.sum()} / all:{valid_df.judgement.count()}   ({valid_df.judgement.sum() / valid_df.judgement.count() * 100:.3f}%)\")\n",
    "\n",
    "        # Dataset / Dataloader\n",
    "        phase_param = {\n",
    "            \"df\":{'train': train_df, 'val': valid_df, 'test': test_df, 'submit': submit_df},\n",
    "            \"argument\":{'train': hps.train_argument, 'val': False, 'test': False, 'submit': False},\n",
    "            \"batch_size\":{'train':hps.batch_size, 'val':hps.batch_size*4, 'test':hps.batch_size*4, 'submit': hps.batch_size*4},\n",
    "            \"shuffle\":{'train': True, 'val': False, 'test': False, 'submit': False},\n",
    "            \"upsample_pos_n\":{'train': hps.upsample_pos_n, 'val': 1, 'test': 1, 'submit': 1},\n",
    "        }\n",
    "        datasets = {phase:TextClassificationDataset(df=phase_param['df'][phase], tokenizer=base_tokenizer, use_col=hps.use_col,\\\n",
    "                                                    token_max_length=hps.token_max_length, argument=phase_param['argument'][phase],\\\n",
    "                                                    upsample_pos_n=phase_param['upsample_pos_n'][phase]) for phase in ['train', 'val', 'test', 'submit']}\n",
    "        dataloaders = {phase: DataLoader(datasets[phase], batch_size=phase_param['batch_size'][phase], \\\n",
    "                                        shuffle=phase_param['shuffle'][phase]) for phase in ['train', 'val', 'test', 'submit']}\n",
    "        \n",
    "        # Model / Optimizer\n",
    "        if hps.model_type == 'lstm':\n",
    "            print(f\"Choosed BertLstmModel\")\n",
    "            model = BertLstmModel(hidden_size=bert_config.hidden_size)\n",
    "        elif hps.model_type == 'lstm_ex':\n",
    "            print(f\"Choosed BertLstmExModel\")\n",
    "            model = BertLstmExModel(hidden_size=bert_config.hidden_size, config=bert_config, use_hidden_n=4)\n",
    "\n",
    "        optimizer, lr_scheduler = model_setup(model, dataloaders)\n",
    "        model = model.to(device)\n",
    "        device_num = torch.cuda.device_count()\n",
    "        if device_num > 1:\n",
    "            print(f\"Use {device_num} GPUs\")\n",
    "            model = nn.DataParallel(model)\n",
    "\n",
    "        # Training / Validation\n",
    "        model, fit_history = fit(dataloaders=dataloaders, model=model, optimizer=optimizer, num_epochs=hps.num_epochs, \n",
    "                             device=device, batch_size=hps.batch_size, lr_scheduler=lr_scheduler, cv_id=i)\n",
    "\n",
    "        # Evaluate\n",
    "        print(f\"Evaluate Test Dataset\")\n",
    "        test_preds_labels_dict = inference(model, dataloader=dataloaders['test'], device=device)\n",
    "        test_fb_score = fbeta_score(y_true=test_preds_labels_dict['labels'], y_pred=test_preds_labels_dict['preds'], beta=7.0)\n",
    "        print(f\"fb_score : {test_fb_score}\")   \n",
    "\n",
    "        logs['fit_history'].append(fit_history)\n",
    "        logs['test_preds_labels'].append(test_preds_labels_dict)\n",
    "        logs['test_fb_score'].append(test_fb_score)\n",
    "\n",
    "        del model, datasets, dataloaders\n",
    "        torch.cuda.empty_cache()\n",
    "        print()\n",
    "\n",
    "    return logs\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "logs = cross_validation(cv_n=hps.cv_n, orig_df=train_df, test_df=test_df)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[32mCross-validation loop : 1/5\u001b[0m\n",
      "Train  ->  label_1:504 / all:21716   (2.321%)\n",
      "Valid  ->  label_1:126 / all:5429   (2.321%)\n",
      "Choosed BertLstmExModel\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "InitLR:2e-05 / num_warmup_steps:85 / num_training_steps:850\n",
      "Use 4 GPUs\n",
      "Using device : cuda\n",
      "【Epoch   1/  5】   LR -> Group0: 0.0000e+00 / Group1: 0.0000e+00 / Group2: 0.0000e+00 / Group3: 0.0000e+00 / Group4: 0.0000e+00 / Group5: 0.0000e+00 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aff705e5ca3543deaa5084efbd8bfd7c"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:2.5485  Acc:0.0563  fbScore:0.4570   LR -> Group0: 1.1765e-06 / Group1: 2.3529e-06 / Group2: 3.5294e-06 / Group3: 5.8824e-05 / Group4: 5.8824e-05 / Group5: 5.8824e-05 / \n",
      "  20/ 170  <train> Loss:2.6329  Acc:0.0410  fbScore:0.5095   LR -> Group0: 2.3529e-06 / Group1: 4.7059e-06 / Group2: 7.0588e-06 / Group3: 1.1765e-04 / Group4: 1.1765e-04 / Group5: 1.1765e-04 / \n",
      "  30/ 170  <train> Loss:2.5131  Acc:0.0346  fbScore:0.5044   LR -> Group0: 3.5294e-06 / Group1: 7.0588e-06 / Group2: 1.0588e-05 / Group3: 1.7647e-04 / Group4: 1.7647e-04 / Group5: 1.7647e-04 / \n",
      "  40/ 170  <train> Loss:2.5331  Acc:0.0340  fbScore:0.5242   LR -> Group0: 4.7059e-06 / Group1: 9.4118e-06 / Group2: 1.4118e-05 / Group3: 2.3529e-04 / Group4: 2.3529e-04 / Group5: 2.3529e-04 / \n",
      "  50/ 170  <train> Loss:2.4598  Acc:0.0316  fbScore:0.5166   LR -> Group0: 5.8824e-06 / Group1: 1.1765e-05 / Group2: 1.7647e-05 / Group3: 2.9412e-04 / Group4: 2.9412e-04 / Group5: 2.9412e-04 / \n",
      "  60/ 170  <train> Loss:2.4030  Acc:0.0302  fbScore:0.5140   LR -> Group0: 7.0588e-06 / Group1: 1.4118e-05 / Group2: 2.1176e-05 / Group3: 3.5294e-04 / Group4: 3.5294e-04 / Group5: 3.5294e-04 / \n",
      "  70/ 170  <train> Loss:2.3184  Acc:0.0448  fbScore:0.5144   LR -> Group0: 8.2353e-06 / Group1: 1.6471e-05 / Group2: 2.4706e-05 / Group3: 4.1176e-04 / Group4: 4.1176e-04 / Group5: 4.1176e-04 / \n",
      "  80/ 170  <train> Loss:2.2354  Acc:0.0975  fbScore:0.5368   LR -> Group0: 9.4118e-06 / Group1: 1.8824e-05 / Group2: 2.8235e-05 / Group3: 4.7059e-04 / Group4: 4.7059e-04 / Group5: 4.7059e-04 / \n",
      "  90/ 170  <train> Loss:2.1569  Acc:0.1604  fbScore:0.5497   LR -> Group0: 9.9346e-06 / Group1: 1.9869e-05 / Group2: 2.9804e-05 / Group3: 4.9673e-04 / Group4: 4.9673e-04 / Group5: 4.9673e-04 / \n",
      " 100/ 170  <train> Loss:2.0778  Acc:0.2002  fbScore:0.5633   LR -> Group0: 9.8039e-06 / Group1: 1.9608e-05 / Group2: 2.9412e-05 / Group3: 4.9020e-04 / Group4: 4.9020e-04 / Group5: 4.9020e-04 / \n",
      " 110/ 170  <train> Loss:2.0278  Acc:0.2478  fbScore:0.5789   LR -> Group0: 9.6732e-06 / Group1: 1.9346e-05 / Group2: 2.9020e-05 / Group3: 4.8366e-04 / Group4: 4.8366e-04 / Group5: 4.8366e-04 / \n",
      " 120/ 170  <train> Loss:1.9466  Acc:0.2797  fbScore:0.5850   LR -> Group0: 9.5425e-06 / Group1: 1.9085e-05 / Group2: 2.8627e-05 / Group3: 4.7712e-04 / Group4: 4.7712e-04 / Group5: 4.7712e-04 / \n",
      " 130/ 170  <train> Loss:1.8842  Acc:0.3237  fbScore:0.5872   LR -> Group0: 9.4118e-06 / Group1: 1.8824e-05 / Group2: 2.8235e-05 / Group3: 4.7059e-04 / Group4: 4.7059e-04 / Group5: 4.7059e-04 / \n",
      " 140/ 170  <train> Loss:1.8142  Acc:0.3566  fbScore:0.6044   LR -> Group0: 9.2810e-06 / Group1: 1.8562e-05 / Group2: 2.7843e-05 / Group3: 4.6405e-04 / Group4: 4.6405e-04 / Group5: 4.6405e-04 / \n",
      " 150/ 170  <train> Loss:1.7486  Acc:0.3873  fbScore:0.6119   LR -> Group0: 9.1503e-06 / Group1: 1.8301e-05 / Group2: 2.7451e-05 / Group3: 4.5752e-04 / Group4: 4.5752e-04 / Group5: 4.5752e-04 / \n",
      " 160/ 170  <train> Loss:1.6871  Acc:0.4122  fbScore:0.6200   LR -> Group0: 9.0196e-06 / Group1: 1.8039e-05 / Group2: 2.7059e-05 / Group3: 4.5098e-04 / Group4: 4.5098e-04 / Group5: 4.5098e-04 / \n",
      " 170/ 170  <train> Loss:1.6729  Acc:0.4377  fbScore:0.6265   LR -> Group0: 8.8889e-06 / Group1: 1.7778e-05 / Group2: 2.6667e-05 / Group3: 4.4444e-04 / Group4: 4.4444e-04 / Group5: 4.4444e-04 / \n",
      "<train> Loss:1.6729  Acc:0.4377  fbScore:0.6265\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ef7818230fd14f53a463492a1261101a"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.9037  Acc:0.7220  fbScore:0.7972\n",
      "Checkpoints have been updated to the epoch 1 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   2/  5】   LR -> Group0: 8.8889e-06 / Group1: 1.7778e-05 / Group2: 2.6667e-05 / Group3: 4.4444e-04 / Group4: 4.4444e-04 / Group5: 4.4444e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0db47695125f457cb35a40153d0a168f"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:0.8034  Acc:0.7359  fbScore:0.7949   LR -> Group0: 8.7582e-06 / Group1: 1.7516e-05 / Group2: 2.6275e-05 / Group3: 4.3791e-04 / Group4: 4.3791e-04 / Group5: 4.3791e-04 / \n",
      "  20/ 170  <train> Loss:0.8134  Acc:0.8074  fbScore:0.7451   LR -> Group0: 8.6275e-06 / Group1: 1.7255e-05 / Group2: 2.5882e-05 / Group3: 4.3137e-04 / Group4: 4.3137e-04 / Group5: 4.3137e-04 / \n",
      "  30/ 170  <train> Loss:0.7570  Acc:0.8146  fbScore:0.7515   LR -> Group0: 8.4967e-06 / Group1: 1.6993e-05 / Group2: 2.5490e-05 / Group3: 4.2484e-04 / Group4: 4.2484e-04 / Group5: 4.2484e-04 / \n",
      "  40/ 170  <train> Loss:0.7185  Acc:0.8309  fbScore:0.7891   LR -> Group0: 8.3660e-06 / Group1: 1.6732e-05 / Group2: 2.5098e-05 / Group3: 4.1830e-04 / Group4: 4.1830e-04 / Group5: 4.1830e-04 / \n",
      "  50/ 170  <train> Loss:0.6941  Acc:0.8473  fbScore:0.8056   LR -> Group0: 8.2353e-06 / Group1: 1.6471e-05 / Group2: 2.4706e-05 / Group3: 4.1176e-04 / Group4: 4.1176e-04 / Group5: 4.1176e-04 / \n",
      "  60/ 170  <train> Loss:0.6782  Acc:0.8621  fbScore:0.8052   LR -> Group0: 8.1046e-06 / Group1: 1.6209e-05 / Group2: 2.4314e-05 / Group3: 4.0523e-04 / Group4: 4.0523e-04 / Group5: 4.0523e-04 / \n",
      "  70/ 170  <train> Loss:0.6727  Acc:0.8693  fbScore:0.8171   LR -> Group0: 7.9739e-06 / Group1: 1.5948e-05 / Group2: 2.3922e-05 / Group3: 3.9869e-04 / Group4: 3.9869e-04 / Group5: 3.9869e-04 / \n",
      "  80/ 170  <train> Loss:0.6389  Acc:0.8752  fbScore:0.8305   LR -> Group0: 7.8431e-06 / Group1: 1.5686e-05 / Group2: 2.3529e-05 / Group3: 3.9216e-04 / Group4: 3.9216e-04 / Group5: 3.9216e-04 / \n",
      "  90/ 170  <train> Loss:0.6300  Acc:0.8776  fbScore:0.8143   LR -> Group0: 7.7124e-06 / Group1: 1.5425e-05 / Group2: 2.3137e-05 / Group3: 3.8562e-04 / Group4: 3.8562e-04 / Group5: 3.8562e-04 / \n",
      " 100/ 170  <train> Loss:0.6166  Acc:0.8809  fbScore:0.8238   LR -> Group0: 7.5817e-06 / Group1: 1.5163e-05 / Group2: 2.2745e-05 / Group3: 3.7908e-04 / Group4: 3.7908e-04 / Group5: 3.7908e-04 / \n",
      " 110/ 170  <train> Loss:0.6138  Acc:0.8824  fbScore:0.8251   LR -> Group0: 7.4510e-06 / Group1: 1.4902e-05 / Group2: 2.2353e-05 / Group3: 3.7255e-04 / Group4: 3.7255e-04 / Group5: 3.7255e-04 / \n",
      " 120/ 170  <train> Loss:0.6064  Acc:0.8792  fbScore:0.8232   LR -> Group0: 7.3203e-06 / Group1: 1.4641e-05 / Group2: 2.1961e-05 / Group3: 3.6601e-04 / Group4: 3.6601e-04 / Group5: 3.6601e-04 / \n",
      " 130/ 170  <train> Loss:0.5840  Acc:0.8842  fbScore:0.8335   LR -> Group0: 7.1895e-06 / Group1: 1.4379e-05 / Group2: 2.1569e-05 / Group3: 3.5948e-04 / Group4: 3.5948e-04 / Group5: 3.5948e-04 / \n",
      " 140/ 170  <train> Loss:0.6488  Acc:0.8853  fbScore:0.8283   LR -> Group0: 7.0588e-06 / Group1: 1.4118e-05 / Group2: 2.1176e-05 / Group3: 3.5294e-04 / Group4: 3.5294e-04 / Group5: 3.5294e-04 / \n",
      " 150/ 170  <train> Loss:0.6664  Acc:0.8794  fbScore:0.8228   LR -> Group0: 6.9281e-06 / Group1: 1.3856e-05 / Group2: 2.0784e-05 / Group3: 3.4641e-04 / Group4: 3.4641e-04 / Group5: 3.4641e-04 / \n",
      " 160/ 170  <train> Loss:0.6736  Acc:0.8808  fbScore:0.8190   LR -> Group0: 6.7974e-06 / Group1: 1.3595e-05 / Group2: 2.0392e-05 / Group3: 3.3987e-04 / Group4: 3.3987e-04 / Group5: 3.3987e-04 / \n",
      " 170/ 170  <train> Loss:0.6691  Acc:0.8786  fbScore:0.8193   LR -> Group0: 6.6667e-06 / Group1: 1.3333e-05 / Group2: 2.0000e-05 / Group3: 3.3333e-04 / Group4: 3.3333e-04 / Group5: 3.3333e-04 / \n",
      "<train> Loss:0.6691  Acc:0.8786  fbScore:0.8193\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "28687d854c604a0b8f71e0e4acbaabaf"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.6527  Acc:0.8589  fbScore:0.8611\n",
      "Checkpoints have been updated to the epoch 2 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   3/  5】   LR -> Group0: 6.6667e-06 / Group1: 1.3333e-05 / Group2: 2.0000e-05 / Group3: 3.3333e-04 / Group4: 3.3333e-04 / Group5: 3.3333e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67138509455e42e5b0e142ca2f7dae16"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:0.4471  Acc:0.8938  fbScore:0.7744   LR -> Group0: 6.5359e-06 / Group1: 1.3072e-05 / Group2: 1.9608e-05 / Group3: 3.2680e-04 / Group4: 3.2680e-04 / Group5: 3.2680e-04 / \n",
      "  20/ 170  <train> Loss:0.4330  Acc:0.9070  fbScore:0.8088   LR -> Group0: 6.4052e-06 / Group1: 1.2810e-05 / Group2: 1.9216e-05 / Group3: 3.2026e-04 / Group4: 3.2026e-04 / Group5: 3.2026e-04 / \n",
      "  30/ 170  <train> Loss:0.4260  Acc:0.9063  fbScore:0.8100   LR -> Group0: 6.2745e-06 / Group1: 1.2549e-05 / Group2: 1.8824e-05 / Group3: 3.1373e-04 / Group4: 3.1373e-04 / Group5: 3.1373e-04 / \n",
      "  40/ 170  <train> Loss:0.3881  Acc:0.9133  fbScore:0.8432   LR -> Group0: 6.1438e-06 / Group1: 1.2288e-05 / Group2: 1.8431e-05 / Group3: 3.0719e-04 / Group4: 3.0719e-04 / Group5: 3.0719e-04 / \n",
      "  50/ 170  <train> Loss:0.3899  Acc:0.9161  fbScore:0.8416   LR -> Group0: 6.0131e-06 / Group1: 1.2026e-05 / Group2: 1.8039e-05 / Group3: 3.0065e-04 / Group4: 3.0065e-04 / Group5: 3.0065e-04 / \n",
      "  60/ 170  <train> Loss:0.4464  Acc:0.9063  fbScore:0.8313   LR -> Group0: 5.8824e-06 / Group1: 1.1765e-05 / Group2: 1.7647e-05 / Group3: 2.9412e-04 / Group4: 2.9412e-04 / Group5: 2.9412e-04 / \n",
      "  70/ 170  <train> Loss:0.4352  Acc:0.9050  fbScore:0.8457   LR -> Group0: 5.7516e-06 / Group1: 1.1503e-05 / Group2: 1.7255e-05 / Group3: 2.8758e-04 / Group4: 2.8758e-04 / Group5: 2.8758e-04 / \n",
      "  80/ 170  <train> Loss:0.4422  Acc:0.9085  fbScore:0.8449   LR -> Group0: 5.6209e-06 / Group1: 1.1242e-05 / Group2: 1.6863e-05 / Group3: 2.8105e-04 / Group4: 2.8105e-04 / Group5: 2.8105e-04 / \n",
      "  90/ 170  <train> Loss:0.4461  Acc:0.9030  fbScore:0.8379   LR -> Group0: 5.4902e-06 / Group1: 1.0980e-05 / Group2: 1.6471e-05 / Group3: 2.7451e-04 / Group4: 2.7451e-04 / Group5: 2.7451e-04 / \n",
      " 100/ 170  <train> Loss:0.4469  Acc:0.8991  fbScore:0.8411   LR -> Group0: 5.3595e-06 / Group1: 1.0719e-05 / Group2: 1.6078e-05 / Group3: 2.6797e-04 / Group4: 2.6797e-04 / Group5: 2.6797e-04 / \n",
      " 110/ 170  <train> Loss:0.4296  Acc:0.9028  fbScore:0.8499   LR -> Group0: 5.2288e-06 / Group1: 1.0458e-05 / Group2: 1.5686e-05 / Group3: 2.6144e-04 / Group4: 2.6144e-04 / Group5: 2.6144e-04 / \n",
      " 120/ 170  <train> Loss:0.4326  Acc:0.9057  fbScore:0.8569   LR -> Group0: 5.0980e-06 / Group1: 1.0196e-05 / Group2: 1.5294e-05 / Group3: 2.5490e-04 / Group4: 2.5490e-04 / Group5: 2.5490e-04 / \n",
      " 130/ 170  <train> Loss:0.4256  Acc:0.9053  fbScore:0.8545   LR -> Group0: 4.9673e-06 / Group1: 9.9346e-06 / Group2: 1.4902e-05 / Group3: 2.4837e-04 / Group4: 2.4837e-04 / Group5: 2.4837e-04 / \n",
      " 140/ 170  <train> Loss:0.4175  Acc:0.9060  fbScore:0.8567   LR -> Group0: 4.8366e-06 / Group1: 9.6732e-06 / Group2: 1.4510e-05 / Group3: 2.4183e-04 / Group4: 2.4183e-04 / Group5: 2.4183e-04 / \n",
      " 150/ 170  <train> Loss:0.4381  Acc:0.9073  fbScore:0.8570   LR -> Group0: 4.7059e-06 / Group1: 9.4118e-06 / Group2: 1.4118e-05 / Group3: 2.3529e-04 / Group4: 2.3529e-04 / Group5: 2.3529e-04 / \n",
      " 160/ 170  <train> Loss:0.4471  Acc:0.9048  fbScore:0.8562   LR -> Group0: 4.5752e-06 / Group1: 9.1503e-06 / Group2: 1.3725e-05 / Group3: 2.2876e-04 / Group4: 2.2876e-04 / Group5: 2.2876e-04 / \n",
      " 170/ 170  <train> Loss:0.4468  Acc:0.9018  fbScore:0.8512   LR -> Group0: 4.4444e-06 / Group1: 8.8889e-06 / Group2: 1.3333e-05 / Group3: 2.2222e-04 / Group4: 2.2222e-04 / Group5: 2.2222e-04 / \n",
      "<train> Loss:0.4468  Acc:0.9018  fbScore:0.8512\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4cb05591ddfe482a9da6e00e7ae525da"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.7365  Acc:0.8876  fbScore:0.8670\n",
      "Checkpoints have been updated to the epoch 3 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   4/  5】   LR -> Group0: 4.4444e-06 / Group1: 8.8889e-06 / Group2: 1.3333e-05 / Group3: 2.2222e-04 / Group4: 2.2222e-04 / Group5: 2.2222e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ca1939c169e4389bec1950c5b38edf9"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:0.3223  Acc:0.9148  fbScore:0.8839   LR -> Group0: 4.3137e-06 / Group1: 8.6275e-06 / Group2: 1.2941e-05 / Group3: 2.1569e-04 / Group4: 2.1569e-04 / Group5: 2.1569e-04 / \n",
      "  20/ 170  <train> Loss:0.2851  Acc:0.9332  fbScore:0.8723   LR -> Group0: 4.1830e-06 / Group1: 8.3660e-06 / Group2: 1.2549e-05 / Group3: 2.0915e-04 / Group4: 2.0915e-04 / Group5: 2.0915e-04 / \n",
      "  30/ 170  <train> Loss:0.2617  Acc:0.9393  fbScore:0.9031   LR -> Group0: 4.0523e-06 / Group1: 8.1046e-06 / Group2: 1.2157e-05 / Group3: 2.0261e-04 / Group4: 2.0261e-04 / Group5: 2.0261e-04 / \n",
      "  40/ 170  <train> Loss:0.2461  Acc:0.9434  fbScore:0.8903   LR -> Group0: 3.9216e-06 / Group1: 7.8431e-06 / Group2: 1.1765e-05 / Group3: 1.9608e-04 / Group4: 1.9608e-04 / Group5: 1.9608e-04 / \n",
      "  50/ 170  <train> Loss:0.2383  Acc:0.9461  fbScore:0.9038   LR -> Group0: 3.7908e-06 / Group1: 7.5817e-06 / Group2: 1.1373e-05 / Group3: 1.8954e-04 / Group4: 1.8954e-04 / Group5: 1.8954e-04 / \n",
      "  60/ 170  <train> Loss:0.2409  Acc:0.9458  fbScore:0.9083   LR -> Group0: 3.6601e-06 / Group1: 7.3203e-06 / Group2: 1.0980e-05 / Group3: 1.8301e-04 / Group4: 1.8301e-04 / Group5: 1.8301e-04 / \n",
      "  70/ 170  <train> Loss:0.2664  Acc:0.9452  fbScore:0.8817   LR -> Group0: 3.5294e-06 / Group1: 7.0588e-06 / Group2: 1.0588e-05 / Group3: 1.7647e-04 / Group4: 1.7647e-04 / Group5: 1.7647e-04 / \n",
      "  80/ 170  <train> Loss:0.2698  Acc:0.9431  fbScore:0.8873   LR -> Group0: 3.3987e-06 / Group1: 6.7974e-06 / Group2: 1.0196e-05 / Group3: 1.6993e-04 / Group4: 1.6993e-04 / Group5: 1.6993e-04 / \n",
      "  90/ 170  <train> Loss:0.2725  Acc:0.9415  fbScore:0.8931   LR -> Group0: 3.2680e-06 / Group1: 6.5359e-06 / Group2: 9.8039e-06 / Group3: 1.6340e-04 / Group4: 1.6340e-04 / Group5: 1.6340e-04 / \n",
      " 100/ 170  <train> Loss:0.2770  Acc:0.9416  fbScore:0.8947   LR -> Group0: 3.1373e-06 / Group1: 6.2745e-06 / Group2: 9.4118e-06 / Group3: 1.5686e-04 / Group4: 1.5686e-04 / Group5: 1.5686e-04 / \n",
      " 110/ 170  <train> Loss:0.2763  Acc:0.9416  fbScore:0.8981   LR -> Group0: 3.0065e-06 / Group1: 6.0131e-06 / Group2: 9.0196e-06 / Group3: 1.5033e-04 / Group4: 1.5033e-04 / Group5: 1.5033e-04 / \n",
      " 120/ 170  <train> Loss:0.2872  Acc:0.9404  fbScore:0.8993   LR -> Group0: 2.8758e-06 / Group1: 5.7516e-06 / Group2: 8.6275e-06 / Group3: 1.4379e-04 / Group4: 1.4379e-04 / Group5: 1.4379e-04 / \n",
      " 130/ 170  <train> Loss:0.2829  Acc:0.9400  fbScore:0.8949   LR -> Group0: 2.7451e-06 / Group1: 5.4902e-06 / Group2: 8.2353e-06 / Group3: 1.3725e-04 / Group4: 1.3725e-04 / Group5: 1.3725e-04 / \n",
      " 140/ 170  <train> Loss:0.2803  Acc:0.9397  fbScore:0.8981   LR -> Group0: 2.6144e-06 / Group1: 5.2288e-06 / Group2: 7.8431e-06 / Group3: 1.3072e-04 / Group4: 1.3072e-04 / Group5: 1.3072e-04 / \n",
      " 150/ 170  <train> Loss:0.2834  Acc:0.9404  fbScore:0.8932   LR -> Group0: 2.4837e-06 / Group1: 4.9673e-06 / Group2: 7.4510e-06 / Group3: 1.2418e-04 / Group4: 1.2418e-04 / Group5: 1.2418e-04 / \n",
      " 160/ 170  <train> Loss:0.2823  Acc:0.9404  fbScore:0.8958   LR -> Group0: 2.3529e-06 / Group1: 4.7059e-06 / Group2: 7.0588e-06 / Group3: 1.1765e-04 / Group4: 1.1765e-04 / Group5: 1.1765e-04 / \n",
      " 170/ 170  <train> Loss:0.2806  Acc:0.9405  fbScore:0.8886   LR -> Group0: 2.2222e-06 / Group1: 4.4444e-06 / Group2: 6.6667e-06 / Group3: 1.1111e-04 / Group4: 1.1111e-04 / Group5: 1.1111e-04 / \n",
      "<train> Loss:0.2806  Acc:0.9405  fbScore:0.8886\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6bc6a8b6fc5c4d5ab797035946306bb6"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.8264  Acc:0.9379  fbScore:0.8893\n",
      "Checkpoints have been updated to the epoch 4 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   5/  5】   LR -> Group0: 2.2222e-06 / Group1: 4.4444e-06 / Group2: 6.6667e-06 / Group3: 1.1111e-04 / Group4: 1.1111e-04 / Group5: 1.1111e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a8800269b0fd4d22a14f37f7cb653866"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:0.3128  Acc:0.9328  fbScore:0.9442   LR -> Group0: 2.0915e-06 / Group1: 4.1830e-06 / Group2: 6.2745e-06 / Group3: 1.0458e-04 / Group4: 1.0458e-04 / Group5: 1.0458e-04 / \n",
      "  20/ 170  <train> Loss:0.2988  Acc:0.9348  fbScore:0.9204   LR -> Group0: 1.9608e-06 / Group1: 3.9216e-06 / Group2: 5.8824e-06 / Group3: 9.8039e-05 / Group4: 9.8039e-05 / Group5: 9.8039e-05 / \n",
      "  30/ 170  <train> Loss:0.2806  Acc:0.9388  fbScore:0.9321   LR -> Group0: 1.8301e-06 / Group1: 3.6601e-06 / Group2: 5.4902e-06 / Group3: 9.1503e-05 / Group4: 9.1503e-05 / Group5: 9.1503e-05 / \n",
      "  40/ 170  <train> Loss:0.2550  Acc:0.9438  fbScore:0.9356   LR -> Group0: 1.6993e-06 / Group1: 3.3987e-06 / Group2: 5.0980e-06 / Group3: 8.4967e-05 / Group4: 8.4967e-05 / Group5: 8.4967e-05 / \n",
      "  50/ 170  <train> Loss:0.2542  Acc:0.9464  fbScore:0.9417   LR -> Group0: 1.5686e-06 / Group1: 3.1373e-06 / Group2: 4.7059e-06 / Group3: 7.8431e-05 / Group4: 7.8431e-05 / Group5: 7.8431e-05 / \n",
      "  60/ 170  <train> Loss:0.2469  Acc:0.9464  fbScore:0.9444   LR -> Group0: 1.4379e-06 / Group1: 2.8758e-06 / Group2: 4.3137e-06 / Group3: 7.1895e-05 / Group4: 7.1895e-05 / Group5: 7.1895e-05 / \n",
      "  70/ 170  <train> Loss:0.2589  Acc:0.9465  fbScore:0.9419   LR -> Group0: 1.3072e-06 / Group1: 2.6144e-06 / Group2: 3.9216e-06 / Group3: 6.5359e-05 / Group4: 6.5359e-05 / Group5: 6.5359e-05 / \n",
      "  80/ 170  <train> Loss:0.2584  Acc:0.9451  fbScore:0.9274   LR -> Group0: 1.1765e-06 / Group1: 2.3529e-06 / Group2: 3.5294e-06 / Group3: 5.8824e-05 / Group4: 5.8824e-05 / Group5: 5.8824e-05 / \n",
      "  90/ 170  <train> Loss:0.2567  Acc:0.9433  fbScore:0.9275   LR -> Group0: 1.0458e-06 / Group1: 2.0915e-06 / Group2: 3.1373e-06 / Group3: 5.2288e-05 / Group4: 5.2288e-05 / Group5: 5.2288e-05 / \n",
      " 100/ 170  <train> Loss:0.2546  Acc:0.9427  fbScore:0.9304   LR -> Group0: 9.1503e-07 / Group1: 1.8301e-06 / Group2: 2.7451e-06 / Group3: 4.5752e-05 / Group4: 4.5752e-05 / Group5: 4.5752e-05 / \n",
      " 110/ 170  <train> Loss:0.2503  Acc:0.9430  fbScore:0.9067   LR -> Group0: 7.8431e-07 / Group1: 1.5686e-06 / Group2: 2.3529e-06 / Group3: 3.9216e-05 / Group4: 3.9216e-05 / Group5: 3.9216e-05 / \n",
      " 120/ 170  <train> Loss:0.2517  Acc:0.9442  fbScore:0.9089   LR -> Group0: 6.5359e-07 / Group1: 1.3072e-06 / Group2: 1.9608e-06 / Group3: 3.2680e-05 / Group4: 3.2680e-05 / Group5: 3.2680e-05 / \n",
      " 130/ 170  <train> Loss:0.2471  Acc:0.9444  fbScore:0.8973   LR -> Group0: 5.2288e-07 / Group1: 1.0458e-06 / Group2: 1.5686e-06 / Group3: 2.6144e-05 / Group4: 2.6144e-05 / Group5: 2.6144e-05 / \n",
      " 140/ 170  <train> Loss:0.2434  Acc:0.9448  fbScore:0.8868   LR -> Group0: 3.9216e-07 / Group1: 7.8431e-07 / Group2: 1.1765e-06 / Group3: 1.9608e-05 / Group4: 1.9608e-05 / Group5: 1.9608e-05 / \n",
      " 150/ 170  <train> Loss:0.2393  Acc:0.9453  fbScore:0.8850   LR -> Group0: 2.6144e-07 / Group1: 5.2288e-07 / Group2: 7.8431e-07 / Group3: 1.3072e-05 / Group4: 1.3072e-05 / Group5: 1.3072e-05 / \n",
      " 160/ 170  <train> Loss:0.2376  Acc:0.9462  fbScore:0.8835   LR -> Group0: 1.3072e-07 / Group1: 2.6144e-07 / Group2: 3.9216e-07 / Group3: 6.5359e-06 / Group4: 6.5359e-06 / Group5: 6.5359e-06 / \n",
      " 170/ 170  <train> Loss:0.2350  Acc:0.9469  fbScore:0.8818   LR -> Group0: 0.0000e+00 / Group1: 0.0000e+00 / Group2: 0.0000e+00 / Group3: 0.0000e+00 / Group4: 0.0000e+00 / Group5: 0.0000e+00 / \n",
      "<train> Loss:0.2350  Acc:0.9469  fbScore:0.8818\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2693a0f2e84b403bb31e45f4f7fb04c9"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:1.2436  Acc:0.9547  fbScore:0.8606\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Evaluate Test Dataset\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e3f29070838425b9470c521966a7547"
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss:0.3533  Acc:0.9391  fbScore:0.9295\n",
      "fb_score : 0.9385562530178659\n",
      "\n",
      "\u001b[32mCross-validation loop : 2/5\u001b[0m\n",
      "Train  ->  label_1:504 / all:21716   (2.321%)\n",
      "Valid  ->  label_1:126 / all:5429   (2.321%)\n",
      "Choosed BertLstmExModel\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "InitLR:2e-05 / num_warmup_steps:85 / num_training_steps:850\n",
      "Use 4 GPUs\n",
      "Using device : cuda\n",
      "【Epoch   1/  5】   LR -> Group0: 0.0000e+00 / Group1: 0.0000e+00 / Group2: 0.0000e+00 / Group3: 0.0000e+00 / Group4: 0.0000e+00 / Group5: 0.0000e+00 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2de247a40c1847cbb9e221253f080a08"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:3.9551  Acc:0.0320  fbScore:0.6000   LR -> Group0: 1.1765e-06 / Group1: 2.3529e-06 / Group2: 3.5294e-06 / Group3: 5.8824e-05 / Group4: 5.8824e-05 / Group5: 5.8824e-05 / \n",
      "  20/ 170  <train> Loss:3.7548  Acc:0.0301  fbScore:0.5629   LR -> Group0: 2.3529e-06 / Group1: 4.7059e-06 / Group2: 7.0588e-06 / Group3: 1.1765e-04 / Group4: 1.1765e-04 / Group5: 1.1765e-04 / \n",
      "  30/ 170  <train> Loss:3.4486  Acc:0.0271  fbScore:0.5409   LR -> Group0: 3.5294e-06 / Group1: 7.0588e-06 / Group2: 1.0588e-05 / Group3: 1.7647e-04 / Group4: 1.7647e-04 / Group5: 1.7647e-04 / \n",
      "  40/ 170  <train> Loss:3.3881  Acc:0.0266  fbScore:0.5391   LR -> Group0: 4.7059e-06 / Group1: 9.4118e-06 / Group2: 1.4118e-05 / Group3: 2.3529e-04 / Group4: 2.3529e-04 / Group5: 2.3529e-04 / \n",
      "  50/ 170  <train> Loss:3.2418  Acc:0.0253  fbScore:0.5183   LR -> Group0: 5.8824e-06 / Group1: 1.1765e-05 / Group2: 1.7647e-05 / Group3: 2.9412e-04 / Group4: 2.9412e-04 / Group5: 2.9412e-04 / \n",
      "  60/ 170  <train> Loss:3.2260  Acc:0.0259  fbScore:0.5247   LR -> Group0: 7.0588e-06 / Group1: 1.4118e-05 / Group2: 2.1176e-05 / Group3: 3.5294e-04 / Group4: 3.5294e-04 / Group5: 3.5294e-04 / \n",
      "  70/ 170  <train> Loss:3.0984  Acc:0.0250  fbScore:0.5128   LR -> Group0: 8.2353e-06 / Group1: 1.6471e-05 / Group2: 2.4706e-05 / Group3: 4.1176e-04 / Group4: 4.1176e-04 / Group5: 4.1176e-04 / \n",
      "  80/ 170  <train> Loss:3.0178  Acc:0.0246  fbScore:0.5065   LR -> Group0: 9.4118e-06 / Group1: 1.8824e-05 / Group2: 2.8235e-05 / Group3: 4.7059e-04 / Group4: 4.7059e-04 / Group5: 4.7059e-04 / \n",
      "  90/ 170  <train> Loss:2.9783  Acc:0.0249  fbScore:0.5116   LR -> Group0: 9.9346e-06 / Group1: 1.9869e-05 / Group2: 2.9804e-05 / Group3: 4.9673e-04 / Group4: 4.9673e-04 / Group5: 4.9673e-04 / \n",
      " 100/ 170  <train> Loss:2.8945  Acc:0.0245  fbScore:0.5061   LR -> Group0: 9.8039e-06 / Group1: 1.9608e-05 / Group2: 2.9412e-05 / Group3: 4.9020e-04 / Group4: 4.9020e-04 / Group5: 4.9020e-04 / \n",
      " 110/ 170  <train> Loss:2.7977  Acc:0.0241  fbScore:0.5023   LR -> Group0: 9.6732e-06 / Group1: 1.9346e-05 / Group2: 2.9020e-05 / Group3: 4.8366e-04 / Group4: 4.8366e-04 / Group5: 4.8366e-04 / \n",
      " 120/ 170  <train> Loss:2.6984  Acc:0.0257  fbScore:0.5038   LR -> Group0: 9.5425e-06 / Group1: 1.9085e-05 / Group2: 2.8627e-05 / Group3: 4.7712e-04 / Group4: 4.7712e-04 / Group5: 4.7712e-04 / \n",
      " 130/ 170  <train> Loss:2.5901  Acc:0.0552  fbScore:0.5015   LR -> Group0: 9.4118e-06 / Group1: 1.8824e-05 / Group2: 2.8235e-05 / Group3: 4.7059e-04 / Group4: 4.7059e-04 / Group5: 4.7059e-04 / \n",
      " 140/ 170  <train> Loss:2.4910  Acc:0.1052  fbScore:0.5168   LR -> Group0: 9.2810e-06 / Group1: 1.8562e-05 / Group2: 2.7843e-05 / Group3: 4.6405e-04 / Group4: 4.6405e-04 / Group5: 4.6405e-04 / \n",
      " 150/ 170  <train> Loss:2.3882  Acc:0.1544  fbScore:0.5298   LR -> Group0: 9.1503e-06 / Group1: 1.8301e-05 / Group2: 2.7451e-05 / Group3: 4.5752e-04 / Group4: 4.5752e-04 / Group5: 4.5752e-04 / \n",
      " 160/ 170  <train> Loss:2.3088  Acc:0.1996  fbScore:0.5471   LR -> Group0: 9.0196e-06 / Group1: 1.8039e-05 / Group2: 2.7059e-05 / Group3: 4.5098e-04 / Group4: 4.5098e-04 / Group5: 4.5098e-04 / \n",
      " 170/ 170  <train> Loss:2.2303  Acc:0.2380  fbScore:0.5634   LR -> Group0: 8.8889e-06 / Group1: 1.7778e-05 / Group2: 2.6667e-05 / Group3: 4.4444e-04 / Group4: 4.4444e-04 / Group5: 4.4444e-04 / \n",
      "<train> Loss:2.2303  Acc:0.2380  fbScore:0.5634\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ceb76336e4dc4a8680aebd06dfcdbbbf"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.6420  Acc:0.8847  fbScore:0.8884\n",
      "Checkpoints have been updated to the epoch 1 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   2/  5】   LR -> Group0: 8.8889e-06 / Group1: 1.7778e-05 / Group2: 2.6667e-05 / Group3: 4.4444e-04 / Group4: 4.4444e-04 / Group5: 4.4444e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d9c80daae5845d9abf5fcf09b7e9931"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:1.0381  Acc:0.9070  fbScore:0.6925   LR -> Group0: 8.7582e-06 / Group1: 1.7516e-05 / Group2: 2.6275e-05 / Group3: 4.3791e-04 / Group4: 4.3791e-04 / Group5: 4.3791e-04 / \n",
      "  20/ 170  <train> Loss:1.0028  Acc:0.8438  fbScore:0.7547   LR -> Group0: 8.6275e-06 / Group1: 1.7255e-05 / Group2: 2.5882e-05 / Group3: 4.3137e-04 / Group4: 4.3137e-04 / Group5: 4.3137e-04 / \n",
      "  30/ 170  <train> Loss:1.0466  Acc:0.8500  fbScore:0.7727   LR -> Group0: 8.4967e-06 / Group1: 1.6993e-05 / Group2: 2.5490e-05 / Group3: 4.2484e-04 / Group4: 4.2484e-04 / Group5: 4.2484e-04 / \n",
      "  40/ 170  <train> Loss:0.9932  Acc:0.8568  fbScore:0.7957   LR -> Group0: 8.3660e-06 / Group1: 1.6732e-05 / Group2: 2.5098e-05 / Group3: 4.1830e-04 / Group4: 4.1830e-04 / Group5: 4.1830e-04 / \n",
      "  50/ 170  <train> Loss:0.9600  Acc:0.8644  fbScore:0.7858   LR -> Group0: 8.2353e-06 / Group1: 1.6471e-05 / Group2: 2.4706e-05 / Group3: 4.1176e-04 / Group4: 4.1176e-04 / Group5: 4.1176e-04 / \n",
      "  60/ 170  <train> Loss:0.9515  Acc:0.8777  fbScore:0.7993   LR -> Group0: 8.1046e-06 / Group1: 1.6209e-05 / Group2: 2.4314e-05 / Group3: 4.0523e-04 / Group4: 4.0523e-04 / Group5: 4.0523e-04 / \n",
      "  70/ 170  <train> Loss:0.9457  Acc:0.8720  fbScore:0.7828   LR -> Group0: 7.9739e-06 / Group1: 1.5948e-05 / Group2: 2.3922e-05 / Group3: 3.9869e-04 / Group4: 3.9869e-04 / Group5: 3.9869e-04 / \n",
      "  80/ 170  <train> Loss:0.8841  Acc:0.8774  fbScore:0.7893   LR -> Group0: 7.8431e-06 / Group1: 1.5686e-05 / Group2: 2.3529e-05 / Group3: 3.9216e-04 / Group4: 3.9216e-04 / Group5: 3.9216e-04 / \n",
      "  90/ 170  <train> Loss:0.8542  Acc:0.8839  fbScore:0.8008   LR -> Group0: 7.7124e-06 / Group1: 1.5425e-05 / Group2: 2.3137e-05 / Group3: 3.8562e-04 / Group4: 3.8562e-04 / Group5: 3.8562e-04 / \n",
      " 100/ 170  <train> Loss:0.8489  Acc:0.8787  fbScore:0.8037   LR -> Group0: 7.5817e-06 / Group1: 1.5163e-05 / Group2: 2.2745e-05 / Group3: 3.7908e-04 / Group4: 3.7908e-04 / Group5: 3.7908e-04 / \n",
      " 110/ 170  <train> Loss:0.8348  Acc:0.8733  fbScore:0.7980   LR -> Group0: 7.4510e-06 / Group1: 1.4902e-05 / Group2: 2.2353e-05 / Group3: 3.7255e-04 / Group4: 3.7255e-04 / Group5: 3.7255e-04 / \n",
      " 120/ 170  <train> Loss:0.8057  Acc:0.8764  fbScore:0.7987   LR -> Group0: 7.3203e-06 / Group1: 1.4641e-05 / Group2: 2.1961e-05 / Group3: 3.6601e-04 / Group4: 3.6601e-04 / Group5: 3.6601e-04 / \n",
      " 130/ 170  <train> Loss:0.8310  Acc:0.8752  fbScore:0.7995   LR -> Group0: 7.1895e-06 / Group1: 1.4379e-05 / Group2: 2.1569e-05 / Group3: 3.5948e-04 / Group4: 3.5948e-04 / Group5: 3.5948e-04 / \n",
      " 140/ 170  <train> Loss:0.8581  Acc:0.8582  fbScore:0.7873   LR -> Group0: 7.0588e-06 / Group1: 1.4118e-05 / Group2: 2.1176e-05 / Group3: 3.5294e-04 / Group4: 3.5294e-04 / Group5: 3.5294e-04 / \n",
      " 150/ 170  <train> Loss:0.8479  Acc:0.8559  fbScore:0.7893   LR -> Group0: 6.9281e-06 / Group1: 1.3856e-05 / Group2: 2.0784e-05 / Group3: 3.4641e-04 / Group4: 3.4641e-04 / Group5: 3.4641e-04 / \n",
      " 160/ 170  <train> Loss:0.8189  Acc:0.8591  fbScore:0.7968   LR -> Group0: 6.7974e-06 / Group1: 1.3595e-05 / Group2: 2.0392e-05 / Group3: 3.3987e-04 / Group4: 3.3987e-04 / Group5: 3.3987e-04 / \n",
      " 170/ 170  <train> Loss:0.7923  Acc:0.8625  fbScore:0.7988   LR -> Group0: 6.6667e-06 / Group1: 1.3333e-05 / Group2: 2.0000e-05 / Group3: 3.3333e-04 / Group4: 3.3333e-04 / Group5: 3.3333e-04 / \n",
      "<train> Loss:0.7923  Acc:0.8625  fbScore:0.7988\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9cfb182265ce4b378838b5dedf59d7e2"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.4465  Acc:0.9057  fbScore:0.8988\n",
      "Checkpoints have been updated to the epoch 2 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   3/  5】   LR -> Group0: 6.6667e-06 / Group1: 1.3333e-05 / Group2: 2.0000e-05 / Group3: 3.3333e-04 / Group4: 3.3333e-04 / Group5: 3.3333e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "863c651f3d94439eaa11e8c118e3aa24"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:0.2647  Acc:0.9336  fbScore:0.8353   LR -> Group0: 6.5359e-06 / Group1: 1.3072e-05 / Group2: 1.9608e-05 / Group3: 3.2680e-04 / Group4: 3.2680e-04 / Group5: 3.2680e-04 / \n",
      "  20/ 170  <train> Loss:0.3435  Acc:0.9500  fbScore:0.8885   LR -> Group0: 6.4052e-06 / Group1: 1.2810e-05 / Group2: 1.9216e-05 / Group3: 3.2026e-04 / Group4: 3.2026e-04 / Group5: 3.2026e-04 / \n",
      "  30/ 170  <train> Loss:0.4621  Acc:0.9289  fbScore:0.8710   LR -> Group0: 6.2745e-06 / Group1: 1.2549e-05 / Group2: 1.8824e-05 / Group3: 3.1373e-04 / Group4: 3.1373e-04 / Group5: 3.1373e-04 / \n",
      "  40/ 170  <train> Loss:0.5225  Acc:0.8939  fbScore:0.8516   LR -> Group0: 6.1438e-06 / Group1: 1.2288e-05 / Group2: 1.8431e-05 / Group3: 3.0719e-04 / Group4: 3.0719e-04 / Group5: 3.0719e-04 / \n",
      "  50/ 170  <train> Loss:0.4878  Acc:0.8973  fbScore:0.8294   LR -> Group0: 6.0131e-06 / Group1: 1.2026e-05 / Group2: 1.8039e-05 / Group3: 3.0065e-04 / Group4: 3.0065e-04 / Group5: 3.0065e-04 / \n",
      "  60/ 170  <train> Loss:0.4662  Acc:0.9052  fbScore:0.8331   LR -> Group0: 5.8824e-06 / Group1: 1.1765e-05 / Group2: 1.7647e-05 / Group3: 2.9412e-04 / Group4: 2.9412e-04 / Group5: 2.9412e-04 / \n",
      "  70/ 170  <train> Loss:0.5037  Acc:0.8956  fbScore:0.8353   LR -> Group0: 5.7516e-06 / Group1: 1.1503e-05 / Group2: 1.7255e-05 / Group3: 2.8758e-04 / Group4: 2.8758e-04 / Group5: 2.8758e-04 / \n",
      "  80/ 170  <train> Loss:0.5221  Acc:0.8818  fbScore:0.8290   LR -> Group0: 5.6209e-06 / Group1: 1.1242e-05 / Group2: 1.6863e-05 / Group3: 2.8105e-04 / Group4: 2.8105e-04 / Group5: 2.8105e-04 / \n",
      "  90/ 170  <train> Loss:0.5139  Acc:0.8864  fbScore:0.8397   LR -> Group0: 5.4902e-06 / Group1: 1.0980e-05 / Group2: 1.6471e-05 / Group3: 2.7451e-04 / Group4: 2.7451e-04 / Group5: 2.7451e-04 / \n",
      " 100/ 170  <train> Loss:0.5115  Acc:0.8867  fbScore:0.8198   LR -> Group0: 5.3595e-06 / Group1: 1.0719e-05 / Group2: 1.6078e-05 / Group3: 2.6797e-04 / Group4: 2.6797e-04 / Group5: 2.6797e-04 / \n",
      " 110/ 170  <train> Loss:0.5248  Acc:0.8876  fbScore:0.8159   LR -> Group0: 5.2288e-06 / Group1: 1.0458e-05 / Group2: 1.5686e-05 / Group3: 2.6144e-04 / Group4: 2.6144e-04 / Group5: 2.6144e-04 / \n",
      " 120/ 170  <train> Loss:0.5077  Acc:0.8890  fbScore:0.8235   LR -> Group0: 5.0980e-06 / Group1: 1.0196e-05 / Group2: 1.5294e-05 / Group3: 2.5490e-04 / Group4: 2.5490e-04 / Group5: 2.5490e-04 / \n",
      " 130/ 170  <train> Loss:0.5021  Acc:0.8913  fbScore:0.8298   LR -> Group0: 4.9673e-06 / Group1: 9.9346e-06 / Group2: 1.4902e-05 / Group3: 2.4837e-04 / Group4: 2.4837e-04 / Group5: 2.4837e-04 / \n",
      " 140/ 170  <train> Loss:0.4929  Acc:0.8924  fbScore:0.8356   LR -> Group0: 4.8366e-06 / Group1: 9.6732e-06 / Group2: 1.4510e-05 / Group3: 2.4183e-04 / Group4: 2.4183e-04 / Group5: 2.4183e-04 / \n",
      " 150/ 170  <train> Loss:0.4814  Acc:0.8943  fbScore:0.8359   LR -> Group0: 4.7059e-06 / Group1: 9.4118e-06 / Group2: 1.4118e-05 / Group3: 2.3529e-04 / Group4: 2.3529e-04 / Group5: 2.3529e-04 / \n",
      " 160/ 170  <train> Loss:0.4694  Acc:0.8957  fbScore:0.8420   LR -> Group0: 4.5752e-06 / Group1: 9.1503e-06 / Group2: 1.3725e-05 / Group3: 2.2876e-04 / Group4: 2.2876e-04 / Group5: 2.2876e-04 / \n",
      " 170/ 170  <train> Loss:0.4554  Acc:0.8982  fbScore:0.8468   LR -> Group0: 4.4444e-06 / Group1: 8.8889e-06 / Group2: 1.3333e-05 / Group3: 2.2222e-04 / Group4: 2.2222e-04 / Group5: 2.2222e-04 / \n",
      "<train> Loss:0.4554  Acc:0.8982  fbScore:0.8468\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "17c3c3c2431e4190b980613ccbb78653"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.6760  Acc:0.9552  fbScore:0.9037\n",
      "Checkpoints have been updated to the epoch 3 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   4/  5】   LR -> Group0: 4.4444e-06 / Group1: 8.8889e-06 / Group2: 1.3333e-05 / Group3: 2.2222e-04 / Group4: 2.2222e-04 / Group5: 2.2222e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da840f537b8c498597b2547dadb68261"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:0.2696  Acc:0.9570  fbScore:0.8622   LR -> Group0: 4.3137e-06 / Group1: 8.6275e-06 / Group2: 1.2941e-05 / Group3: 2.1569e-04 / Group4: 2.1569e-04 / Group5: 2.1569e-04 / \n",
      "  20/ 170  <train> Loss:0.2300  Acc:0.9594  fbScore:0.9137   LR -> Group0: 4.1830e-06 / Group1: 8.3660e-06 / Group2: 1.2549e-05 / Group3: 2.0915e-04 / Group4: 2.0915e-04 / Group5: 2.0915e-04 / \n",
      "  30/ 170  <train> Loss:0.3789  Acc:0.9516  fbScore:0.8239   LR -> Group0: 4.0523e-06 / Group1: 8.1046e-06 / Group2: 1.2157e-05 / Group3: 2.0261e-04 / Group4: 2.0261e-04 / Group5: 2.0261e-04 / \n",
      "  40/ 170  <train> Loss:0.3401  Acc:0.9508  fbScore:0.8312   LR -> Group0: 3.9216e-06 / Group1: 7.8431e-06 / Group2: 1.1765e-05 / Group3: 1.9608e-04 / Group4: 1.9608e-04 / Group5: 1.9608e-04 / \n",
      "  50/ 170  <train> Loss:0.3202  Acc:0.9512  fbScore:0.8539   LR -> Group0: 3.7908e-06 / Group1: 7.5817e-06 / Group2: 1.1373e-05 / Group3: 1.8954e-04 / Group4: 1.8954e-04 / Group5: 1.8954e-04 / \n",
      "  60/ 170  <train> Loss:0.3353  Acc:0.9493  fbScore:0.8501   LR -> Group0: 3.6601e-06 / Group1: 7.3203e-06 / Group2: 1.0980e-05 / Group3: 1.8301e-04 / Group4: 1.8301e-04 / Group5: 1.8301e-04 / \n",
      "  70/ 170  <train> Loss:0.3233  Acc:0.9472  fbScore:0.8606   LR -> Group0: 3.5294e-06 / Group1: 7.0588e-06 / Group2: 1.0588e-05 / Group3: 1.7647e-04 / Group4: 1.7647e-04 / Group5: 1.7647e-04 / \n",
      "  80/ 170  <train> Loss:0.3672  Acc:0.9467  fbScore:0.8454   LR -> Group0: 3.3987e-06 / Group1: 6.7974e-06 / Group2: 1.0196e-05 / Group3: 1.6993e-04 / Group4: 1.6993e-04 / Group5: 1.6993e-04 / \n",
      "  90/ 170  <train> Loss:0.3583  Acc:0.9464  fbScore:0.8588   LR -> Group0: 3.2680e-06 / Group1: 6.5359e-06 / Group2: 9.8039e-06 / Group3: 1.6340e-04 / Group4: 1.6340e-04 / Group5: 1.6340e-04 / \n",
      " 100/ 170  <train> Loss:0.3731  Acc:0.9467  fbScore:0.8522   LR -> Group0: 3.1373e-06 / Group1: 6.2745e-06 / Group2: 9.4118e-06 / Group3: 1.5686e-04 / Group4: 1.5686e-04 / Group5: 1.5686e-04 / \n",
      " 110/ 170  <train> Loss:0.3640  Acc:0.9452  fbScore:0.8574   LR -> Group0: 3.0065e-06 / Group1: 6.0131e-06 / Group2: 9.0196e-06 / Group3: 1.5033e-04 / Group4: 1.5033e-04 / Group5: 1.5033e-04 / \n",
      " 120/ 170  <train> Loss:0.3551  Acc:0.9443  fbScore:0.8564   LR -> Group0: 2.8758e-06 / Group1: 5.7516e-06 / Group2: 8.6275e-06 / Group3: 1.4379e-04 / Group4: 1.4379e-04 / Group5: 1.4379e-04 / \n",
      " 130/ 170  <train> Loss:0.3451  Acc:0.9439  fbScore:0.8622   LR -> Group0: 2.7451e-06 / Group1: 5.4902e-06 / Group2: 8.2353e-06 / Group3: 1.3725e-04 / Group4: 1.3725e-04 / Group5: 1.3725e-04 / \n",
      " 140/ 170  <train> Loss:0.3395  Acc:0.9435  fbScore:0.8685   LR -> Group0: 2.6144e-06 / Group1: 5.2288e-06 / Group2: 7.8431e-06 / Group3: 1.3072e-04 / Group4: 1.3072e-04 / Group5: 1.3072e-04 / \n",
      " 150/ 170  <train> Loss:0.3328  Acc:0.9434  fbScore:0.8742   LR -> Group0: 2.4837e-06 / Group1: 4.9673e-06 / Group2: 7.4510e-06 / Group3: 1.2418e-04 / Group4: 1.2418e-04 / Group5: 1.2418e-04 / \n",
      " 160/ 170  <train> Loss:0.3242  Acc:0.9439  fbScore:0.8717   LR -> Group0: 2.3529e-06 / Group1: 4.7059e-06 / Group2: 7.0588e-06 / Group3: 1.1765e-04 / Group4: 1.1765e-04 / Group5: 1.1765e-04 / \n",
      " 170/ 170  <train> Loss:0.3386  Acc:0.9437  fbScore:0.8748   LR -> Group0: 2.2222e-06 / Group1: 4.4444e-06 / Group2: 6.6667e-06 / Group3: 1.1111e-04 / Group4: 1.1111e-04 / Group5: 1.1111e-04 / \n",
      "<train> Loss:0.3386  Acc:0.9437  fbScore:0.8748\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "57aad08016864860a442ff9d527db030"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.7037  Acc:0.9449  fbScore:0.9022\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   5/  5】   LR -> Group0: 2.2222e-06 / Group1: 4.4444e-06 / Group2: 6.6667e-06 / Group3: 1.1111e-04 / Group4: 1.1111e-04 / Group5: 1.1111e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05a8722c6eab495c9e00e74db8f573e4"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:0.3569  Acc:0.9406  fbScore:0.7379   LR -> Group0: 2.0915e-06 / Group1: 4.1830e-06 / Group2: 6.2745e-06 / Group3: 1.0458e-04 / Group4: 1.0458e-04 / Group5: 1.0458e-04 / \n",
      "  20/ 170  <train> Loss:0.2916  Acc:0.9426  fbScore:0.8337   LR -> Group0: 1.9608e-06 / Group1: 3.9216e-06 / Group2: 5.8824e-06 / Group3: 9.8039e-05 / Group4: 9.8039e-05 / Group5: 9.8039e-05 / \n",
      "  30/ 170  <train> Loss:0.2793  Acc:0.9430  fbScore:0.8751   LR -> Group0: 1.8301e-06 / Group1: 3.6601e-06 / Group2: 5.4902e-06 / Group3: 9.1503e-05 / Group4: 9.1503e-05 / Group5: 9.1503e-05 / \n",
      "  40/ 170  <train> Loss:0.2724  Acc:0.9418  fbScore:0.8920   LR -> Group0: 1.6993e-06 / Group1: 3.3987e-06 / Group2: 5.0980e-06 / Group3: 8.4967e-05 / Group4: 8.4967e-05 / Group5: 8.4967e-05 / \n",
      "  50/ 170  <train> Loss:0.2619  Acc:0.9422  fbScore:0.8840   LR -> Group0: 1.5686e-06 / Group1: 3.1373e-06 / Group2: 4.7059e-06 / Group3: 7.8431e-05 / Group4: 7.8431e-05 / Group5: 7.8431e-05 / \n",
      "  60/ 170  <train> Loss:0.2564  Acc:0.9444  fbScore:0.8969   LR -> Group0: 1.4379e-06 / Group1: 2.8758e-06 / Group2: 4.3137e-06 / Group3: 7.1895e-05 / Group4: 7.1895e-05 / Group5: 7.1895e-05 / \n",
      "  70/ 170  <train> Loss:0.2452  Acc:0.9470  fbScore:0.9051   LR -> Group0: 1.3072e-06 / Group1: 2.6144e-06 / Group2: 3.9216e-06 / Group3: 6.5359e-05 / Group4: 6.5359e-05 / Group5: 6.5359e-05 / \n",
      "  80/ 170  <train> Loss:0.2348  Acc:0.9493  fbScore:0.9127   LR -> Group0: 1.1765e-06 / Group1: 2.3529e-06 / Group2: 3.5294e-06 / Group3: 5.8824e-05 / Group4: 5.8824e-05 / Group5: 5.8824e-05 / \n",
      "  90/ 170  <train> Loss:0.2335  Acc:0.9500  fbScore:0.9187   LR -> Group0: 1.0458e-06 / Group1: 2.0915e-06 / Group2: 3.1373e-06 / Group3: 5.2288e-05 / Group4: 5.2288e-05 / Group5: 5.2288e-05 / \n",
      " 100/ 170  <train> Loss:0.2316  Acc:0.9505  fbScore:0.9232   LR -> Group0: 9.1503e-07 / Group1: 1.8301e-06 / Group2: 2.7451e-06 / Group3: 4.5752e-05 / Group4: 4.5752e-05 / Group5: 4.5752e-05 / \n",
      " 110/ 170  <train> Loss:0.2272  Acc:0.9510  fbScore:0.9174   LR -> Group0: 7.8431e-07 / Group1: 1.5686e-06 / Group2: 2.3529e-06 / Group3: 3.9216e-05 / Group4: 3.9216e-05 / Group5: 3.9216e-05 / \n",
      " 120/ 170  <train> Loss:0.2243  Acc:0.9516  fbScore:0.9198   LR -> Group0: 6.5359e-07 / Group1: 1.3072e-06 / Group2: 1.9608e-06 / Group3: 3.2680e-05 / Group4: 3.2680e-05 / Group5: 3.2680e-05 / \n",
      " 130/ 170  <train> Loss:0.2221  Acc:0.9519  fbScore:0.9140   LR -> Group0: 5.2288e-07 / Group1: 1.0458e-06 / Group2: 1.5686e-06 / Group3: 2.6144e-05 / Group4: 2.6144e-05 / Group5: 2.6144e-05 / \n",
      " 140/ 170  <train> Loss:0.2205  Acc:0.9519  fbScore:0.8893   LR -> Group0: 3.9216e-07 / Group1: 7.8431e-07 / Group2: 1.1765e-06 / Group3: 1.9608e-05 / Group4: 1.9608e-05 / Group5: 1.9608e-05 / \n",
      " 150/ 170  <train> Loss:0.2181  Acc:0.9526  fbScore:0.8818   LR -> Group0: 2.6144e-07 / Group1: 5.2288e-07 / Group2: 7.8431e-07 / Group3: 1.3072e-05 / Group4: 1.3072e-05 / Group5: 1.3072e-05 / \n",
      " 160/ 170  <train> Loss:0.2158  Acc:0.9529  fbScore:0.8805   LR -> Group0: 1.3072e-07 / Group1: 2.6144e-07 / Group2: 3.9216e-07 / Group3: 6.5359e-06 / Group4: 6.5359e-06 / Group5: 6.5359e-06 / \n",
      " 170/ 170  <train> Loss:0.2143  Acc:0.9531  fbScore:0.8846   LR -> Group0: 0.0000e+00 / Group1: 0.0000e+00 / Group2: 0.0000e+00 / Group3: 0.0000e+00 / Group4: 0.0000e+00 / Group5: 0.0000e+00 / \n",
      "<train> Loss:0.2143  Acc:0.9531  fbScore:0.8846\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1978c3d27d948fa8b6a4044307acc24"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.6828  Acc:0.9556  fbScore:0.9066\n",
      "Checkpoints have been updated to the epoch 5 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Evaluate Test Dataset\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46a09a28e57242759997d9a91b471014"
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss:0.2851  Acc:0.9585  fbScore:0.9447\n",
      "fb_score : 0.9507161039040696\n",
      "\n",
      "\u001b[32mCross-validation loop : 3/5\u001b[0m\n",
      "Train  ->  label_1:504 / all:21716   (2.321%)\n",
      "Valid  ->  label_1:126 / all:5429   (2.321%)\n",
      "Choosed BertLstmExModel\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "InitLR:2e-05 / num_warmup_steps:85 / num_training_steps:850\n",
      "Use 4 GPUs\n",
      "Using device : cuda\n",
      "【Epoch   1/  5】   LR -> Group0: 0.0000e+00 / Group1: 0.0000e+00 / Group2: 0.0000e+00 / Group3: 0.0000e+00 / Group4: 0.0000e+00 / Group5: 0.0000e+00 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9301d0615c9435089a9159c5527f4bb"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:3.3194  Acc:0.0258  fbScore:0.5281   LR -> Group0: 1.1765e-06 / Group1: 2.3529e-06 / Group2: 3.5294e-06 / Group3: 5.8824e-05 / Group4: 5.8824e-05 / Group5: 5.8824e-05 / \n",
      "  20/ 170  <train> Loss:3.1994  Acc:0.0246  fbScore:0.5227   LR -> Group0: 2.3529e-06 / Group1: 4.7059e-06 / Group2: 7.0588e-06 / Group3: 1.1765e-04 / Group4: 1.1765e-04 / Group5: 1.1765e-04 / \n",
      "  30/ 170  <train> Loss:3.1828  Acc:0.0245  fbScore:0.5306   LR -> Group0: 3.5294e-06 / Group1: 7.0588e-06 / Group2: 1.0588e-05 / Group3: 1.7647e-04 / Group4: 1.7647e-04 / Group5: 1.7647e-04 / \n",
      "  40/ 170  <train> Loss:3.0156  Acc:0.0229  fbScore:0.4965   LR -> Group0: 4.7059e-06 / Group1: 9.4118e-06 / Group2: 1.4118e-05 / Group3: 2.3529e-04 / Group4: 2.3529e-04 / Group5: 2.3529e-04 / \n",
      "  50/ 170  <train> Loss:2.9582  Acc:0.0223  fbScore:0.4917   LR -> Group0: 5.8824e-06 / Group1: 1.1765e-05 / Group2: 1.7647e-05 / Group3: 2.9412e-04 / Group4: 2.9412e-04 / Group5: 2.9412e-04 / \n",
      "  60/ 170  <train> Loss:2.9663  Acc:0.0228  fbScore:0.4974   LR -> Group0: 7.0588e-06 / Group1: 1.4118e-05 / Group2: 2.1176e-05 / Group3: 3.5294e-04 / Group4: 3.5294e-04 / Group5: 3.5294e-04 / \n",
      "  70/ 170  <train> Loss:2.9129  Acc:0.0231  fbScore:0.4992   LR -> Group0: 8.2353e-06 / Group1: 1.6471e-05 / Group2: 2.4706e-05 / Group3: 4.1176e-04 / Group4: 4.1176e-04 / Group5: 4.1176e-04 / \n",
      "  80/ 170  <train> Loss:2.8372  Acc:0.0229  fbScore:0.4977   LR -> Group0: 9.4118e-06 / Group1: 1.8824e-05 / Group2: 2.8235e-05 / Group3: 4.7059e-04 / Group4: 4.7059e-04 / Group5: 4.7059e-04 / \n",
      "  90/ 170  <train> Loss:2.7731  Acc:0.0227  fbScore:0.4959   LR -> Group0: 9.9346e-06 / Group1: 1.9869e-05 / Group2: 2.9804e-05 / Group3: 4.9673e-04 / Group4: 4.9673e-04 / Group5: 4.9673e-04 / \n",
      " 100/ 170  <train> Loss:2.7273  Acc:0.0227  fbScore:0.4972   LR -> Group0: 9.8039e-06 / Group1: 1.9608e-05 / Group2: 2.9412e-05 / Group3: 4.9020e-04 / Group4: 4.9020e-04 / Group5: 4.9020e-04 / \n",
      " 110/ 170  <train> Loss:2.7001  Acc:0.0246  fbScore:0.5010   LR -> Group0: 9.6732e-06 / Group1: 1.9346e-05 / Group2: 2.9020e-05 / Group3: 4.8366e-04 / Group4: 4.8366e-04 / Group5: 4.8366e-04 / \n",
      " 120/ 170  <train> Loss:2.6397  Acc:0.0549  fbScore:0.5034   LR -> Group0: 9.5425e-06 / Group1: 1.9085e-05 / Group2: 2.8627e-05 / Group3: 4.7712e-04 / Group4: 4.7712e-04 / Group5: 4.7712e-04 / \n",
      " 130/ 170  <train> Loss:2.5631  Acc:0.1034  fbScore:0.5078   LR -> Group0: 9.4118e-06 / Group1: 1.8824e-05 / Group2: 2.8235e-05 / Group3: 4.7059e-04 / Group4: 4.7059e-04 / Group5: 4.7059e-04 / \n",
      " 140/ 170  <train> Loss:2.5207  Acc:0.1305  fbScore:0.5180   LR -> Group0: 9.2810e-06 / Group1: 1.8562e-05 / Group2: 2.7843e-05 / Group3: 4.6405e-04 / Group4: 4.6405e-04 / Group5: 4.6405e-04 / \n",
      " 150/ 170  <train> Loss:2.4626  Acc:0.1679  fbScore:0.5305   LR -> Group0: 9.1503e-06 / Group1: 1.8301e-05 / Group2: 2.7451e-05 / Group3: 4.5752e-04 / Group4: 4.5752e-04 / Group5: 4.5752e-04 / \n",
      " 160/ 170  <train> Loss:2.3776  Acc:0.2034  fbScore:0.5391   LR -> Group0: 9.0196e-06 / Group1: 1.8039e-05 / Group2: 2.7059e-05 / Group3: 4.5098e-04 / Group4: 4.5098e-04 / Group5: 4.5098e-04 / \n",
      " 170/ 170  <train> Loss:2.3165  Acc:0.2420  fbScore:0.5516   LR -> Group0: 8.8889e-06 / Group1: 1.7778e-05 / Group2: 2.6667e-05 / Group3: 4.4444e-04 / Group4: 4.4444e-04 / Group5: 4.4444e-04 / \n",
      "<train> Loss:2.3165  Acc:0.2420  fbScore:0.5516\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "addf34d84a074ae39f0f3c9c23500554"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.9835  Acc:0.7908  fbScore:0.8336\n",
      "Checkpoints have been updated to the epoch 1 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   2/  5】   LR -> Group0: 8.8889e-06 / Group1: 1.7778e-05 / Group2: 2.6667e-05 / Group3: 4.4444e-04 / Group4: 4.4444e-04 / Group5: 4.4444e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7485b67d847543afb2c92d7edadd39d5"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:1.1646  Acc:0.6484  fbScore:0.7822   LR -> Group0: 8.7582e-06 / Group1: 1.7516e-05 / Group2: 2.6275e-05 / Group3: 4.3791e-04 / Group4: 4.3791e-04 / Group5: 4.3791e-04 / \n",
      "  20/ 170  <train> Loss:1.0100  Acc:0.7578  fbScore:0.7355   LR -> Group0: 8.6275e-06 / Group1: 1.7255e-05 / Group2: 2.5882e-05 / Group3: 4.3137e-04 / Group4: 4.3137e-04 / Group5: 4.3137e-04 / \n",
      "  30/ 170  <train> Loss:0.9446  Acc:0.7865  fbScore:0.7707   LR -> Group0: 8.4967e-06 / Group1: 1.6993e-05 / Group2: 2.5490e-05 / Group3: 4.2484e-04 / Group4: 4.2484e-04 / Group5: 4.2484e-04 / \n",
      "  40/ 170  <train> Loss:0.8938  Acc:0.7869  fbScore:0.7791   LR -> Group0: 8.3660e-06 / Group1: 1.6732e-05 / Group2: 2.5098e-05 / Group3: 4.1830e-04 / Group4: 4.1830e-04 / Group5: 4.1830e-04 / \n",
      "  50/ 170  <train> Loss:0.8911  Acc:0.8020  fbScore:0.7895   LR -> Group0: 8.2353e-06 / Group1: 1.6471e-05 / Group2: 2.4706e-05 / Group3: 4.1176e-04 / Group4: 4.1176e-04 / Group5: 4.1176e-04 / \n",
      "  60/ 170  <train> Loss:0.8154  Acc:0.8178  fbScore:0.8048   LR -> Group0: 8.1046e-06 / Group1: 1.6209e-05 / Group2: 2.4314e-05 / Group3: 4.0523e-04 / Group4: 4.0523e-04 / Group5: 4.0523e-04 / \n",
      "  70/ 170  <train> Loss:0.9685  Acc:0.8190  fbScore:0.7978   LR -> Group0: 7.9739e-06 / Group1: 1.5948e-05 / Group2: 2.3922e-05 / Group3: 3.9869e-04 / Group4: 3.9869e-04 / Group5: 3.9869e-04 / \n",
      "  80/ 170  <train> Loss:0.9371  Acc:0.8206  fbScore:0.7909   LR -> Group0: 7.8431e-06 / Group1: 1.5686e-05 / Group2: 2.3529e-05 / Group3: 3.9216e-04 / Group4: 3.9216e-04 / Group5: 3.9216e-04 / \n",
      "  90/ 170  <train> Loss:0.9592  Acc:0.8191  fbScore:0.7864   LR -> Group0: 7.7124e-06 / Group1: 1.5425e-05 / Group2: 2.3137e-05 / Group3: 3.8562e-04 / Group4: 3.8562e-04 / Group5: 3.8562e-04 / \n",
      " 100/ 170  <train> Loss:0.9399  Acc:0.8153  fbScore:0.7923   LR -> Group0: 7.5817e-06 / Group1: 1.5163e-05 / Group2: 2.2745e-05 / Group3: 3.7908e-04 / Group4: 3.7908e-04 / Group5: 3.7908e-04 / \n",
      " 110/ 170  <train> Loss:0.8928  Acc:0.8224  fbScore:0.7863   LR -> Group0: 7.4510e-06 / Group1: 1.4902e-05 / Group2: 2.2353e-05 / Group3: 3.7255e-04 / Group4: 3.7255e-04 / Group5: 3.7255e-04 / \n",
      " 120/ 170  <train> Loss:0.8808  Acc:0.8266  fbScore:0.7884   LR -> Group0: 7.3203e-06 / Group1: 1.4641e-05 / Group2: 2.1961e-05 / Group3: 3.6601e-04 / Group4: 3.6601e-04 / Group5: 3.6601e-04 / \n",
      " 130/ 170  <train> Loss:0.8782  Acc:0.8263  fbScore:0.7888   LR -> Group0: 7.1895e-06 / Group1: 1.4379e-05 / Group2: 2.1569e-05 / Group3: 3.5948e-04 / Group4: 3.5948e-04 / Group5: 3.5948e-04 / \n",
      " 140/ 170  <train> Loss:0.8567  Acc:0.8259  fbScore:0.7930   LR -> Group0: 7.0588e-06 / Group1: 1.4118e-05 / Group2: 2.1176e-05 / Group3: 3.5294e-04 / Group4: 3.5294e-04 / Group5: 3.5294e-04 / \n",
      " 150/ 170  <train> Loss:0.8417  Acc:0.8295  fbScore:0.7858   LR -> Group0: 6.9281e-06 / Group1: 1.3856e-05 / Group2: 2.0784e-05 / Group3: 3.4641e-04 / Group4: 3.4641e-04 / Group5: 3.4641e-04 / \n",
      " 160/ 170  <train> Loss:0.8668  Acc:0.8327  fbScore:0.7880   LR -> Group0: 6.7974e-06 / Group1: 1.3595e-05 / Group2: 2.0392e-05 / Group3: 3.3987e-04 / Group4: 3.3987e-04 / Group5: 3.3987e-04 / \n",
      " 170/ 170  <train> Loss:0.8571  Acc:0.8273  fbScore:0.7825   LR -> Group0: 6.6667e-06 / Group1: 1.3333e-05 / Group2: 2.0000e-05 / Group3: 3.3333e-04 / Group4: 3.3333e-04 / Group5: 3.3333e-04 / \n",
      "<train> Loss:0.8571  Acc:0.8273  fbScore:0.7825\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12ff0d95bf7841068c03b72c12b48f34"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.7101  Acc:0.7425  fbScore:0.8106\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   3/  5】   LR -> Group0: 6.6667e-06 / Group1: 1.3333e-05 / Group2: 2.0000e-05 / Group3: 3.3333e-04 / Group4: 3.3333e-04 / Group5: 3.3333e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "928ca5f38e9e48f7ad7538dd71f8796b"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:0.8906  Acc:0.8016  fbScore:0.7551   LR -> Group0: 6.5359e-06 / Group1: 1.3072e-05 / Group2: 1.9608e-05 / Group3: 3.2680e-04 / Group4: 3.2680e-04 / Group5: 3.2680e-04 / \n",
      "  20/ 170  <train> Loss:0.7295  Acc:0.8285  fbScore:0.8173   LR -> Group0: 6.4052e-06 / Group1: 1.2810e-05 / Group2: 1.9216e-05 / Group3: 3.2026e-04 / Group4: 3.2026e-04 / Group5: 3.2026e-04 / \n",
      "  30/ 170  <train> Loss:0.6717  Acc:0.8448  fbScore:0.8481   LR -> Group0: 6.2745e-06 / Group1: 1.2549e-05 / Group2: 1.8824e-05 / Group3: 3.1373e-04 / Group4: 3.1373e-04 / Group5: 3.1373e-04 / \n",
      "  40/ 170  <train> Loss:0.6372  Acc:0.8537  fbScore:0.8567   LR -> Group0: 6.1438e-06 / Group1: 1.2288e-05 / Group2: 1.8431e-05 / Group3: 3.0719e-04 / Group4: 3.0719e-04 / Group5: 3.0719e-04 / \n",
      "  50/ 170  <train> Loss:0.6070  Acc:0.8584  fbScore:0.8649   LR -> Group0: 6.0131e-06 / Group1: 1.2026e-05 / Group2: 1.8039e-05 / Group3: 3.0065e-04 / Group4: 3.0065e-04 / Group5: 3.0065e-04 / \n",
      "  60/ 170  <train> Loss:0.5823  Acc:0.8626  fbScore:0.8687   LR -> Group0: 5.8824e-06 / Group1: 1.1765e-05 / Group2: 1.7647e-05 / Group3: 2.9412e-04 / Group4: 2.9412e-04 / Group5: 2.9412e-04 / \n",
      "  70/ 170  <train> Loss:0.5625  Acc:0.8704  fbScore:0.8715   LR -> Group0: 5.7516e-06 / Group1: 1.1503e-05 / Group2: 1.7255e-05 / Group3: 2.8758e-04 / Group4: 2.8758e-04 / Group5: 2.8758e-04 / \n",
      "  80/ 170  <train> Loss:0.5418  Acc:0.8748  fbScore:0.8650   LR -> Group0: 5.6209e-06 / Group1: 1.1242e-05 / Group2: 1.6863e-05 / Group3: 2.8105e-04 / Group4: 2.8105e-04 / Group5: 2.8105e-04 / \n",
      "  90/ 170  <train> Loss:0.5370  Acc:0.8804  fbScore:0.8476   LR -> Group0: 5.4902e-06 / Group1: 1.0980e-05 / Group2: 1.6471e-05 / Group3: 2.7451e-04 / Group4: 2.7451e-04 / Group5: 2.7451e-04 / \n",
      " 100/ 170  <train> Loss:0.5250  Acc:0.8815  fbScore:0.8519   LR -> Group0: 5.3595e-06 / Group1: 1.0719e-05 / Group2: 1.6078e-05 / Group3: 2.6797e-04 / Group4: 2.6797e-04 / Group5: 2.6797e-04 / \n",
      " 110/ 170  <train> Loss:0.5119  Acc:0.8807  fbScore:0.8513   LR -> Group0: 5.2288e-06 / Group1: 1.0458e-05 / Group2: 1.5686e-05 / Group3: 2.6144e-04 / Group4: 2.6144e-04 / Group5: 2.6144e-04 / \n",
      " 120/ 170  <train> Loss:0.4947  Acc:0.8824  fbScore:0.8541   LR -> Group0: 5.0980e-06 / Group1: 1.0196e-05 / Group2: 1.5294e-05 / Group3: 2.5490e-04 / Group4: 2.5490e-04 / Group5: 2.5490e-04 / \n",
      " 130/ 170  <train> Loss:0.4988  Acc:0.8849  fbScore:0.8574   LR -> Group0: 4.9673e-06 / Group1: 9.9346e-06 / Group2: 1.4902e-05 / Group3: 2.4837e-04 / Group4: 2.4837e-04 / Group5: 2.4837e-04 / \n",
      " 140/ 170  <train> Loss:0.4854  Acc:0.8868  fbScore:0.8604   LR -> Group0: 4.8366e-06 / Group1: 9.6732e-06 / Group2: 1.4510e-05 / Group3: 2.4183e-04 / Group4: 2.4183e-04 / Group5: 2.4183e-04 / \n",
      " 150/ 170  <train> Loss:0.4750  Acc:0.8883  fbScore:0.8630   LR -> Group0: 4.7059e-06 / Group1: 9.4118e-06 / Group2: 1.4118e-05 / Group3: 2.3529e-04 / Group4: 2.3529e-04 / Group5: 2.3529e-04 / \n",
      " 160/ 170  <train> Loss:0.4632  Acc:0.8913  fbScore:0.8558   LR -> Group0: 4.5752e-06 / Group1: 9.1503e-06 / Group2: 1.3725e-05 / Group3: 2.2876e-04 / Group4: 2.2876e-04 / Group5: 2.2876e-04 / \n",
      " 170/ 170  <train> Loss:0.4525  Acc:0.8939  fbScore:0.8546   LR -> Group0: 4.4444e-06 / Group1: 8.8889e-06 / Group2: 1.3333e-05 / Group3: 2.2222e-04 / Group4: 2.2222e-04 / Group5: 2.2222e-04 / \n",
      "<train> Loss:0.4525  Acc:0.8939  fbScore:0.8546\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91256a6b79e947a697b8b5fa3e134950"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.5763  Acc:0.9429  fbScore:0.9187\n",
      "Checkpoints have been updated to the epoch 3 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   4/  5】   LR -> Group0: 4.4444e-06 / Group1: 8.8889e-06 / Group2: 1.3333e-05 / Group3: 2.2222e-04 / Group4: 2.2222e-04 / Group5: 2.2222e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1fe710404a314a058b55f8c2101ecd4d"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:0.5105  Acc:0.9242  fbScore:0.8248   LR -> Group0: 4.3137e-06 / Group1: 8.6275e-06 / Group2: 1.2941e-05 / Group3: 2.1569e-04 / Group4: 2.1569e-04 / Group5: 2.1569e-04 / \n",
      "  20/ 170  <train> Loss:0.4505  Acc:0.9012  fbScore:0.8563   LR -> Group0: 4.1830e-06 / Group1: 8.3660e-06 / Group2: 1.2549e-05 / Group3: 2.0915e-04 / Group4: 2.0915e-04 / Group5: 2.0915e-04 / \n",
      "  30/ 170  <train> Loss:0.4133  Acc:0.8982  fbScore:0.8408   LR -> Group0: 4.0523e-06 / Group1: 8.1046e-06 / Group2: 1.2157e-05 / Group3: 2.0261e-04 / Group4: 2.0261e-04 / Group5: 2.0261e-04 / \n",
      "  40/ 170  <train> Loss:0.4194  Acc:0.8996  fbScore:0.8530   LR -> Group0: 3.9216e-06 / Group1: 7.8431e-06 / Group2: 1.1765e-05 / Group3: 1.9608e-04 / Group4: 1.9608e-04 / Group5: 1.9608e-04 / \n",
      "  50/ 170  <train> Loss:0.3884  Acc:0.9044  fbScore:0.8663   LR -> Group0: 3.7908e-06 / Group1: 7.5817e-06 / Group2: 1.1373e-05 / Group3: 1.8954e-04 / Group4: 1.8954e-04 / Group5: 1.8954e-04 / \n",
      "  60/ 170  <train> Loss:0.3685  Acc:0.9078  fbScore:0.8751   LR -> Group0: 3.6601e-06 / Group1: 7.3203e-06 / Group2: 1.0980e-05 / Group3: 1.8301e-04 / Group4: 1.8301e-04 / Group5: 1.8301e-04 / \n",
      "  70/ 170  <train> Loss:0.3704  Acc:0.9112  fbScore:0.8849   LR -> Group0: 3.5294e-06 / Group1: 7.0588e-06 / Group2: 1.0588e-05 / Group3: 1.7647e-04 / Group4: 1.7647e-04 / Group5: 1.7647e-04 / \n",
      "  80/ 170  <train> Loss:0.3679  Acc:0.9133  fbScore:0.8785   LR -> Group0: 3.3987e-06 / Group1: 6.7974e-06 / Group2: 1.0196e-05 / Group3: 1.6993e-04 / Group4: 1.6993e-04 / Group5: 1.6993e-04 / \n",
      "  90/ 170  <train> Loss:0.3590  Acc:0.9143  fbScore:0.8846   LR -> Group0: 3.2680e-06 / Group1: 6.5359e-06 / Group2: 9.8039e-06 / Group3: 1.6340e-04 / Group4: 1.6340e-04 / Group5: 1.6340e-04 / \n",
      " 100/ 170  <train> Loss:0.3455  Acc:0.9161  fbScore:0.8867   LR -> Group0: 3.1373e-06 / Group1: 6.2745e-06 / Group2: 9.4118e-06 / Group3: 1.5686e-04 / Group4: 1.5686e-04 / Group5: 1.5686e-04 / \n",
      " 110/ 170  <train> Loss:0.3367  Acc:0.9183  fbScore:0.8906   LR -> Group0: 3.0065e-06 / Group1: 6.0131e-06 / Group2: 9.0196e-06 / Group3: 1.5033e-04 / Group4: 1.5033e-04 / Group5: 1.5033e-04 / \n",
      " 120/ 170  <train> Loss:0.3514  Acc:0.9195  fbScore:0.8827   LR -> Group0: 2.8758e-06 / Group1: 5.7516e-06 / Group2: 8.6275e-06 / Group3: 1.4379e-04 / Group4: 1.4379e-04 / Group5: 1.4379e-04 / \n",
      " 130/ 170  <train> Loss:0.3665  Acc:0.9166  fbScore:0.8802   LR -> Group0: 2.7451e-06 / Group1: 5.4902e-06 / Group2: 8.2353e-06 / Group3: 1.3725e-04 / Group4: 1.3725e-04 / Group5: 1.3725e-04 / \n",
      " 140/ 170  <train> Loss:0.3675  Acc:0.9145  fbScore:0.8823   LR -> Group0: 2.6144e-06 / Group1: 5.2288e-06 / Group2: 7.8431e-06 / Group3: 1.3072e-04 / Group4: 1.3072e-04 / Group5: 1.3072e-04 / \n",
      " 150/ 170  <train> Loss:0.3641  Acc:0.9134  fbScore:0.8777   LR -> Group0: 2.4837e-06 / Group1: 4.9673e-06 / Group2: 7.4510e-06 / Group3: 1.2418e-04 / Group4: 1.2418e-04 / Group5: 1.2418e-04 / \n",
      " 160/ 170  <train> Loss:0.3754  Acc:0.9134  fbScore:0.8737   LR -> Group0: 2.3529e-06 / Group1: 4.7059e-06 / Group2: 7.0588e-06 / Group3: 1.1765e-04 / Group4: 1.1765e-04 / Group5: 1.1765e-04 / \n",
      " 170/ 170  <train> Loss:0.3702  Acc:0.9132  fbScore:0.8595   LR -> Group0: 2.2222e-06 / Group1: 4.4444e-06 / Group2: 6.6667e-06 / Group3: 1.1111e-04 / Group4: 1.1111e-04 / Group5: 1.1111e-04 / \n",
      "<train> Loss:0.3702  Acc:0.9132  fbScore:0.8595\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6b46c0e54b54fa9a9b03cb674dd7c9d"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.4177  Acc:0.9190  fbScore:0.9182\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   5/  5】   LR -> Group0: 2.2222e-06 / Group1: 4.4444e-06 / Group2: 6.6667e-06 / Group3: 1.1111e-04 / Group4: 1.1111e-04 / Group5: 1.1111e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fed42fb691f14c52b8f9af9473fd2dda"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:0.3077  Acc:0.9141  fbScore:0.8333   LR -> Group0: 2.0915e-06 / Group1: 4.1830e-06 / Group2: 6.2745e-06 / Group3: 1.0458e-04 / Group4: 1.0458e-04 / Group5: 1.0458e-04 / \n",
      "  20/ 170  <train> Loss:0.3213  Acc:0.9191  fbScore:0.7936   LR -> Group0: 1.9608e-06 / Group1: 3.9216e-06 / Group2: 5.8824e-06 / Group3: 9.8039e-05 / Group4: 9.8039e-05 / Group5: 9.8039e-05 / \n",
      "  30/ 170  <train> Loss:0.4812  Acc:0.9190  fbScore:0.8313   LR -> Group0: 1.8301e-06 / Group1: 3.6601e-06 / Group2: 5.4902e-06 / Group3: 9.1503e-05 / Group4: 9.1503e-05 / Group5: 9.1503e-05 / \n",
      "  40/ 170  <train> Loss:0.4357  Acc:0.9170  fbScore:0.8346   LR -> Group0: 1.6993e-06 / Group1: 3.3987e-06 / Group2: 5.0980e-06 / Group3: 8.4967e-05 / Group4: 8.4967e-05 / Group5: 8.4967e-05 / \n",
      "  50/ 170  <train> Loss:0.3919  Acc:0.9220  fbScore:0.8534   LR -> Group0: 1.5686e-06 / Group1: 3.1373e-06 / Group2: 4.7059e-06 / Group3: 7.8431e-05 / Group4: 7.8431e-05 / Group5: 7.8431e-05 / \n",
      "  60/ 170  <train> Loss:0.3741  Acc:0.9230  fbScore:0.8678   LR -> Group0: 1.4379e-06 / Group1: 2.8758e-06 / Group2: 4.3137e-06 / Group3: 7.1895e-05 / Group4: 7.1895e-05 / Group5: 7.1895e-05 / \n",
      "  70/ 170  <train> Loss:0.3644  Acc:0.9256  fbScore:0.8620   LR -> Group0: 1.3072e-06 / Group1: 2.6144e-06 / Group2: 3.9216e-06 / Group3: 6.5359e-05 / Group4: 6.5359e-05 / Group5: 6.5359e-05 / \n",
      "  80/ 170  <train> Loss:0.3593  Acc:0.9264  fbScore:0.8696   LR -> Group0: 1.1765e-06 / Group1: 2.3529e-06 / Group2: 3.5294e-06 / Group3: 5.8824e-05 / Group4: 5.8824e-05 / Group5: 5.8824e-05 / \n",
      "  90/ 170  <train> Loss:0.3432  Acc:0.9283  fbScore:0.8563   LR -> Group0: 1.0458e-06 / Group1: 2.0915e-06 / Group2: 3.1373e-06 / Group3: 5.2288e-05 / Group4: 5.2288e-05 / Group5: 5.2288e-05 / \n",
      " 100/ 170  <train> Loss:0.3335  Acc:0.9295  fbScore:0.8639   LR -> Group0: 9.1503e-07 / Group1: 1.8301e-06 / Group2: 2.7451e-06 / Group3: 4.5752e-05 / Group4: 4.5752e-05 / Group5: 4.5752e-05 / \n",
      " 110/ 170  <train> Loss:0.3243  Acc:0.9300  fbScore:0.8605   LR -> Group0: 7.8431e-07 / Group1: 1.5686e-06 / Group2: 2.3529e-06 / Group3: 3.9216e-05 / Group4: 3.9216e-05 / Group5: 3.9216e-05 / \n",
      " 120/ 170  <train> Loss:0.3185  Acc:0.9318  fbScore:0.8678   LR -> Group0: 6.5359e-07 / Group1: 1.3072e-06 / Group2: 1.9608e-06 / Group3: 3.2680e-05 / Group4: 3.2680e-05 / Group5: 3.2680e-05 / \n",
      " 130/ 170  <train> Loss:0.3164  Acc:0.9322  fbScore:0.8718   LR -> Group0: 5.2288e-07 / Group1: 1.0458e-06 / Group2: 1.5686e-06 / Group3: 2.6144e-05 / Group4: 2.6144e-05 / Group5: 2.6144e-05 / \n",
      " 140/ 170  <train> Loss:0.3098  Acc:0.9320  fbScore:0.8767   LR -> Group0: 3.9216e-07 / Group1: 7.8431e-07 / Group2: 1.1765e-06 / Group3: 1.9608e-05 / Group4: 1.9608e-05 / Group5: 1.9608e-05 / \n",
      " 150/ 170  <train> Loss:0.3026  Acc:0.9330  fbScore:0.8747   LR -> Group0: 2.6144e-07 / Group1: 5.2288e-07 / Group2: 7.8431e-07 / Group3: 1.3072e-05 / Group4: 1.3072e-05 / Group5: 1.3072e-05 / \n",
      " 160/ 170  <train> Loss:0.2975  Acc:0.9331  fbScore:0.8730   LR -> Group0: 1.3072e-07 / Group1: 2.6144e-07 / Group2: 3.9216e-07 / Group3: 6.5359e-06 / Group4: 6.5359e-06 / Group5: 6.5359e-06 / \n",
      " 170/ 170  <train> Loss:0.2922  Acc:0.9341  fbScore:0.8776   LR -> Group0: 0.0000e+00 / Group1: 0.0000e+00 / Group2: 0.0000e+00 / Group3: 0.0000e+00 / Group4: 0.0000e+00 / Group5: 0.0000e+00 / \n",
      "<train> Loss:0.2922  Acc:0.9341  fbScore:0.8776\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82a74136708242ee9734467719fb4e6b"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.4997  Acc:0.9425  fbScore:0.9128\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Evaluate Test Dataset\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "248364f7dede4afd90c1b4f44673ad10"
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss:0.3516  Acc:0.9451  fbScore:0.9327\n",
      "fb_score : 0.9416795560003639\n",
      "\n",
      "\u001b[32mCross-validation loop : 4/5\u001b[0m\n",
      "Train  ->  label_1:504 / all:21716   (2.321%)\n",
      "Valid  ->  label_1:126 / all:5429   (2.321%)\n",
      "Choosed BertLstmExModel\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "InitLR:2e-05 / num_warmup_steps:85 / num_training_steps:850\n",
      "Use 4 GPUs\n",
      "Using device : cuda\n",
      "【Epoch   1/  5】   LR -> Group0: 0.0000e+00 / Group1: 0.0000e+00 / Group2: 0.0000e+00 / Group3: 0.0000e+00 / Group4: 0.0000e+00 / Group5: 0.0000e+00 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd3928149dda40cebb72db34a664d2ce"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:3.0050  Acc:0.0227  fbScore:0.4951   LR -> Group0: 1.1765e-06 / Group1: 2.3529e-06 / Group2: 3.5294e-06 / Group3: 5.8824e-05 / Group4: 5.8824e-05 / Group5: 5.8824e-05 / \n",
      "  20/ 170  <train> Loss:2.9244  Acc:0.0219  fbScore:0.4805   LR -> Group0: 2.3529e-06 / Group1: 4.7059e-06 / Group2: 7.0588e-06 / Group3: 1.1765e-04 / Group4: 1.1765e-04 / Group5: 1.1765e-04 / \n",
      "  30/ 170  <train> Loss:3.0544  Acc:0.0232  fbScore:0.5049   LR -> Group0: 3.5294e-06 / Group1: 7.0588e-06 / Group2: 1.0588e-05 / Group3: 1.7647e-04 / Group4: 1.7647e-04 / Group5: 1.7647e-04 / \n",
      "  40/ 170  <train> Loss:2.9985  Acc:0.0227  fbScore:0.4978   LR -> Group0: 4.7059e-06 / Group1: 9.4118e-06 / Group2: 1.4118e-05 / Group3: 2.3529e-04 / Group4: 2.3529e-04 / Group5: 2.3529e-04 / \n",
      "  50/ 170  <train> Loss:2.9760  Acc:0.0225  fbScore:0.5002   LR -> Group0: 5.8824e-06 / Group1: 1.1765e-05 / Group2: 1.7647e-05 / Group3: 2.9412e-04 / Group4: 2.9412e-04 / Group5: 2.9412e-04 / \n",
      "  60/ 170  <train> Loss:2.9311  Acc:0.0223  fbScore:0.4978   LR -> Group0: 7.0588e-06 / Group1: 1.4118e-05 / Group2: 2.1176e-05 / Group3: 3.5294e-04 / Group4: 3.5294e-04 / Group5: 3.5294e-04 / \n",
      "  70/ 170  <train> Loss:2.9287  Acc:0.0228  fbScore:0.5065   LR -> Group0: 8.2353e-06 / Group1: 1.6471e-05 / Group2: 2.4706e-05 / Group3: 4.1176e-04 / Group4: 4.1176e-04 / Group5: 4.1176e-04 / \n",
      "  80/ 170  <train> Loss:2.8851  Acc:0.0226  fbScore:0.5001   LR -> Group0: 9.4118e-06 / Group1: 1.8824e-05 / Group2: 2.8235e-05 / Group3: 4.7059e-04 / Group4: 4.7059e-04 / Group5: 4.7059e-04 / \n",
      "  90/ 170  <train> Loss:2.8821  Acc:0.0233  fbScore:0.5096   LR -> Group0: 9.9346e-06 / Group1: 1.9869e-05 / Group2: 2.9804e-05 / Group3: 4.9673e-04 / Group4: 4.9673e-04 / Group5: 4.9673e-04 / \n",
      " 100/ 170  <train> Loss:2.8303  Acc:0.0230  fbScore:0.5055   LR -> Group0: 9.8039e-06 / Group1: 1.9608e-05 / Group2: 2.9412e-05 / Group3: 4.9020e-04 / Group4: 4.9020e-04 / Group5: 4.9020e-04 / \n",
      " 110/ 170  <train> Loss:2.7862  Acc:0.0231  fbScore:0.5017   LR -> Group0: 9.6732e-06 / Group1: 1.9346e-05 / Group2: 2.9020e-05 / Group3: 4.8366e-04 / Group4: 4.8366e-04 / Group5: 4.8366e-04 / \n",
      " 120/ 170  <train> Loss:2.7292  Acc:0.0232  fbScore:0.5015   LR -> Group0: 9.5425e-06 / Group1: 1.9085e-05 / Group2: 2.8627e-05 / Group3: 4.7712e-04 / Group4: 4.7712e-04 / Group5: 4.7712e-04 / \n",
      " 130/ 170  <train> Loss:2.6670  Acc:0.0290  fbScore:0.4979   LR -> Group0: 9.4118e-06 / Group1: 1.8824e-05 / Group2: 2.8235e-05 / Group3: 4.7059e-04 / Group4: 4.7059e-04 / Group5: 4.7059e-04 / \n",
      " 140/ 170  <train> Loss:2.5953  Acc:0.0665  fbScore:0.5061   LR -> Group0: 9.2810e-06 / Group1: 1.8562e-05 / Group2: 2.7843e-05 / Group3: 4.6405e-04 / Group4: 4.6405e-04 / Group5: 4.6405e-04 / \n",
      " 150/ 170  <train> Loss:2.4868  Acc:0.1139  fbScore:0.5197   LR -> Group0: 9.1503e-06 / Group1: 1.8301e-05 / Group2: 2.7451e-05 / Group3: 4.5752e-04 / Group4: 4.5752e-04 / Group5: 4.5752e-04 / \n",
      " 160/ 170  <train> Loss:2.4330  Acc:0.1524  fbScore:0.5286   LR -> Group0: 9.0196e-06 / Group1: 1.8039e-05 / Group2: 2.7059e-05 / Group3: 4.5098e-04 / Group4: 4.5098e-04 / Group5: 4.5098e-04 / \n",
      " 170/ 170  <train> Loss:2.3635  Acc:0.1773  fbScore:0.5383   LR -> Group0: 8.8889e-06 / Group1: 1.7778e-05 / Group2: 2.6667e-05 / Group3: 4.4444e-04 / Group4: 4.4444e-04 / Group5: 4.4444e-04 / \n",
      "<train> Loss:2.3635  Acc:0.1773  fbScore:0.5383\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b1999d3e4d3e41ea9c97114675669253"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:1.5045  Acc:0.7508  fbScore:0.7094\n",
      "Checkpoints have been updated to the epoch 1 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   2/  5】   LR -> Group0: 8.8889e-06 / Group1: 1.7778e-05 / Group2: 2.6667e-05 / Group3: 4.4444e-04 / Group4: 4.4444e-04 / Group5: 4.4444e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "10ba60290de641e5b402dfd7ffd687d3"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:1.6849  Acc:0.6398  fbScore:0.5181   LR -> Group0: 8.7582e-06 / Group1: 1.7516e-05 / Group2: 2.6275e-05 / Group3: 4.3791e-04 / Group4: 4.3791e-04 / Group5: 4.3791e-04 / \n",
      "  20/ 170  <train> Loss:1.4675  Acc:0.6566  fbScore:0.5973   LR -> Group0: 8.6275e-06 / Group1: 1.7255e-05 / Group2: 2.5882e-05 / Group3: 4.3137e-04 / Group4: 4.3137e-04 / Group5: 4.3137e-04 / \n",
      "  30/ 170  <train> Loss:1.2927  Acc:0.6638  fbScore:0.6498   LR -> Group0: 8.4967e-06 / Group1: 1.6993e-05 / Group2: 2.5490e-05 / Group3: 4.2484e-04 / Group4: 4.2484e-04 / Group5: 4.2484e-04 / \n",
      "  40/ 170  <train> Loss:1.1618  Acc:0.7031  fbScore:0.6722   LR -> Group0: 8.3660e-06 / Group1: 1.6732e-05 / Group2: 2.5098e-05 / Group3: 4.1830e-04 / Group4: 4.1830e-04 / Group5: 4.1830e-04 / \n",
      "  50/ 170  <train> Loss:1.1228  Acc:0.7080  fbScore:0.6703   LR -> Group0: 8.2353e-06 / Group1: 1.6471e-05 / Group2: 2.4706e-05 / Group3: 4.1176e-04 / Group4: 4.1176e-04 / Group5: 4.1176e-04 / \n",
      "  60/ 170  <train> Loss:1.0704  Acc:0.7379  fbScore:0.6893   LR -> Group0: 8.1046e-06 / Group1: 1.6209e-05 / Group2: 2.4314e-05 / Group3: 4.0523e-04 / Group4: 4.0523e-04 / Group5: 4.0523e-04 / \n",
      "  70/ 170  <train> Loss:1.1048  Acc:0.7343  fbScore:0.7012   LR -> Group0: 7.9739e-06 / Group1: 1.5948e-05 / Group2: 2.3922e-05 / Group3: 3.9869e-04 / Group4: 3.9869e-04 / Group5: 3.9869e-04 / \n",
      "  80/ 170  <train> Loss:1.0969  Acc:0.7275  fbScore:0.7153   LR -> Group0: 7.8431e-06 / Group1: 1.5686e-05 / Group2: 2.3529e-05 / Group3: 3.9216e-04 / Group4: 3.9216e-04 / Group5: 3.9216e-04 / \n",
      "  90/ 170  <train> Loss:1.0578  Acc:0.7471  fbScore:0.7224   LR -> Group0: 7.7124e-06 / Group1: 1.5425e-05 / Group2: 2.3137e-05 / Group3: 3.8562e-04 / Group4: 3.8562e-04 / Group5: 3.8562e-04 / \n",
      " 100/ 170  <train> Loss:1.0408  Acc:0.7569  fbScore:0.7324   LR -> Group0: 7.5817e-06 / Group1: 1.5163e-05 / Group2: 2.2745e-05 / Group3: 3.7908e-04 / Group4: 3.7908e-04 / Group5: 3.7908e-04 / \n",
      " 110/ 170  <train> Loss:1.0259  Acc:0.7521  fbScore:0.7242   LR -> Group0: 7.4510e-06 / Group1: 1.4902e-05 / Group2: 2.2353e-05 / Group3: 3.7255e-04 / Group4: 3.7255e-04 / Group5: 3.7255e-04 / \n",
      " 120/ 170  <train> Loss:1.0007  Acc:0.7534  fbScore:0.7281   LR -> Group0: 7.3203e-06 / Group1: 1.4641e-05 / Group2: 2.1961e-05 / Group3: 3.6601e-04 / Group4: 3.6601e-04 / Group5: 3.6601e-04 / \n",
      " 130/ 170  <train> Loss:0.9960  Acc:0.7634  fbScore:0.7303   LR -> Group0: 7.1895e-06 / Group1: 1.4379e-05 / Group2: 2.1569e-05 / Group3: 3.5948e-04 / Group4: 3.5948e-04 / Group5: 3.5948e-04 / \n",
      " 140/ 170  <train> Loss:0.9764  Acc:0.7715  fbScore:0.7305   LR -> Group0: 7.0588e-06 / Group1: 1.4118e-05 / Group2: 2.1176e-05 / Group3: 3.5294e-04 / Group4: 3.5294e-04 / Group5: 3.5294e-04 / \n",
      " 150/ 170  <train> Loss:0.9463  Acc:0.7745  fbScore:0.7381   LR -> Group0: 6.9281e-06 / Group1: 1.3856e-05 / Group2: 2.0784e-05 / Group3: 3.4641e-04 / Group4: 3.4641e-04 / Group5: 3.4641e-04 / \n",
      " 160/ 170  <train> Loss:0.9252  Acc:0.7797  fbScore:0.7466   LR -> Group0: 6.7974e-06 / Group1: 1.3595e-05 / Group2: 2.0392e-05 / Group3: 3.3987e-04 / Group4: 3.3987e-04 / Group5: 3.3987e-04 / \n",
      " 170/ 170  <train> Loss:0.9120  Acc:0.7835  fbScore:0.7554   LR -> Group0: 6.6667e-06 / Group1: 1.3333e-05 / Group2: 2.0000e-05 / Group3: 3.3333e-04 / Group4: 3.3333e-04 / Group5: 3.3333e-04 / \n",
      "<train> Loss:0.9120  Acc:0.7835  fbScore:0.7554\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05ad76a111be465fb5dfb813f2cd2db3"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.6379  Acc:0.8379  fbScore:0.8465\n",
      "Checkpoints have been updated to the epoch 2 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   3/  5】   LR -> Group0: 6.6667e-06 / Group1: 1.3333e-05 / Group2: 2.0000e-05 / Group3: 3.3333e-04 / Group4: 3.3333e-04 / Group5: 3.3333e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60c4301012a745a3866811e7c3e6eb68"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:0.7132  Acc:0.8156  fbScore:0.7738   LR -> Group0: 6.5359e-06 / Group1: 1.3072e-05 / Group2: 1.9608e-05 / Group3: 3.2680e-04 / Group4: 3.2680e-04 / Group5: 3.2680e-04 / \n",
      "  20/ 170  <train> Loss:0.5709  Acc:0.8395  fbScore:0.7789   LR -> Group0: 6.4052e-06 / Group1: 1.2810e-05 / Group2: 1.9216e-05 / Group3: 3.2026e-04 / Group4: 3.2026e-04 / Group5: 3.2026e-04 / \n",
      "  30/ 170  <train> Loss:0.5032  Acc:0.8677  fbScore:0.8300   LR -> Group0: 6.2745e-06 / Group1: 1.2549e-05 / Group2: 1.8824e-05 / Group3: 3.1373e-04 / Group4: 3.1373e-04 / Group5: 3.1373e-04 / \n",
      "  40/ 170  <train> Loss:0.4687  Acc:0.8861  fbScore:0.8588   LR -> Group0: 6.1438e-06 / Group1: 1.2288e-05 / Group2: 1.8431e-05 / Group3: 3.0719e-04 / Group4: 3.0719e-04 / Group5: 3.0719e-04 / \n",
      "  50/ 170  <train> Loss:0.4404  Acc:0.8983  fbScore:0.8674   LR -> Group0: 6.0131e-06 / Group1: 1.2026e-05 / Group2: 1.8039e-05 / Group3: 3.0065e-04 / Group4: 3.0065e-04 / Group5: 3.0065e-04 / \n",
      "  60/ 170  <train> Loss:0.4119  Acc:0.9053  fbScore:0.8504   LR -> Group0: 5.8824e-06 / Group1: 1.1765e-05 / Group2: 1.7647e-05 / Group3: 2.9412e-04 / Group4: 2.9412e-04 / Group5: 2.9412e-04 / \n",
      "  70/ 170  <train> Loss:0.4390  Acc:0.9030  fbScore:0.8517   LR -> Group0: 5.7516e-06 / Group1: 1.1503e-05 / Group2: 1.7255e-05 / Group3: 2.8758e-04 / Group4: 2.8758e-04 / Group5: 2.8758e-04 / \n",
      "  80/ 170  <train> Loss:0.4696  Acc:0.8962  fbScore:0.8345   LR -> Group0: 5.6209e-06 / Group1: 1.1242e-05 / Group2: 1.6863e-05 / Group3: 2.8105e-04 / Group4: 2.8105e-04 / Group5: 2.8105e-04 / \n",
      "  90/ 170  <train> Loss:0.4711  Acc:0.8933  fbScore:0.8414   LR -> Group0: 5.4902e-06 / Group1: 1.0980e-05 / Group2: 1.6471e-05 / Group3: 2.7451e-04 / Group4: 2.7451e-04 / Group5: 2.7451e-04 / \n",
      " 100/ 170  <train> Loss:0.5198  Acc:0.8957  fbScore:0.8384   LR -> Group0: 5.3595e-06 / Group1: 1.0719e-05 / Group2: 1.6078e-05 / Group3: 2.6797e-04 / Group4: 2.6797e-04 / Group5: 2.6797e-04 / \n",
      " 110/ 170  <train> Loss:0.5277  Acc:0.8927  fbScore:0.8323   LR -> Group0: 5.2288e-06 / Group1: 1.0458e-05 / Group2: 1.5686e-05 / Group3: 2.6144e-04 / Group4: 2.6144e-04 / Group5: 2.6144e-04 / \n",
      " 120/ 170  <train> Loss:0.5236  Acc:0.8906  fbScore:0.8318   LR -> Group0: 5.0980e-06 / Group1: 1.0196e-05 / Group2: 1.5294e-05 / Group3: 2.5490e-04 / Group4: 2.5490e-04 / Group5: 2.5490e-04 / \n",
      " 130/ 170  <train> Loss:0.5213  Acc:0.8906  fbScore:0.8375   LR -> Group0: 4.9673e-06 / Group1: 9.9346e-06 / Group2: 1.4902e-05 / Group3: 2.4837e-04 / Group4: 2.4837e-04 / Group5: 2.4837e-04 / \n",
      " 140/ 170  <train> Loss:0.5096  Acc:0.8913  fbScore:0.8365   LR -> Group0: 4.8366e-06 / Group1: 9.6732e-06 / Group2: 1.4510e-05 / Group3: 2.4183e-04 / Group4: 2.4183e-04 / Group5: 2.4183e-04 / \n",
      " 150/ 170  <train> Loss:0.4925  Acc:0.8943  fbScore:0.8302   LR -> Group0: 4.7059e-06 / Group1: 9.4118e-06 / Group2: 1.4118e-05 / Group3: 2.3529e-04 / Group4: 2.3529e-04 / Group5: 2.3529e-04 / \n",
      " 160/ 170  <train> Loss:0.4893  Acc:0.8965  fbScore:0.8284   LR -> Group0: 4.5752e-06 / Group1: 9.1503e-06 / Group2: 1.3725e-05 / Group3: 2.2876e-04 / Group4: 2.2876e-04 / Group5: 2.2876e-04 / \n",
      " 170/ 170  <train> Loss:0.4843  Acc:0.8968  fbScore:0.8338   LR -> Group0: 4.4444e-06 / Group1: 8.8889e-06 / Group2: 1.3333e-05 / Group3: 2.2222e-04 / Group4: 2.2222e-04 / Group5: 2.2222e-04 / \n",
      "<train> Loss:0.4843  Acc:0.8968  fbScore:0.8338\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79ccbd209f814d8083fa7b7d9fe3a383"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.5961  Acc:0.8983  fbScore:0.8799\n",
      "Checkpoints have been updated to the epoch 3 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   4/  5】   LR -> Group0: 4.4444e-06 / Group1: 8.8889e-06 / Group2: 1.3333e-05 / Group3: 2.2222e-04 / Group4: 2.2222e-04 / Group5: 2.2222e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cf045f81ea6140518da6e5f5e310d29e"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:0.4007  Acc:0.8961  fbScore:0.8067   LR -> Group0: 4.3137e-06 / Group1: 8.6275e-06 / Group2: 1.2941e-05 / Group3: 2.1569e-04 / Group4: 2.1569e-04 / Group5: 2.1569e-04 / \n",
      "  20/ 170  <train> Loss:0.3550  Acc:0.9062  fbScore:0.8537   LR -> Group0: 4.1830e-06 / Group1: 8.3660e-06 / Group2: 1.2549e-05 / Group3: 2.0915e-04 / Group4: 2.0915e-04 / Group5: 2.0915e-04 / \n",
      "  30/ 170  <train> Loss:0.3233  Acc:0.9156  fbScore:0.8504   LR -> Group0: 4.0523e-06 / Group1: 8.1046e-06 / Group2: 1.2157e-05 / Group3: 2.0261e-04 / Group4: 2.0261e-04 / Group5: 2.0261e-04 / \n",
      "  40/ 170  <train> Loss:0.3718  Acc:0.9236  fbScore:0.8442   LR -> Group0: 3.9216e-06 / Group1: 7.8431e-06 / Group2: 1.1765e-05 / Group3: 1.9608e-04 / Group4: 1.9608e-04 / Group5: 1.9608e-04 / \n",
      "  50/ 170  <train> Loss:0.3625  Acc:0.9225  fbScore:0.8264   LR -> Group0: 3.7908e-06 / Group1: 7.5817e-06 / Group2: 1.1373e-05 / Group3: 1.8954e-04 / Group4: 1.8954e-04 / Group5: 1.8954e-04 / \n",
      "  60/ 170  <train> Loss:0.3574  Acc:0.9217  fbScore:0.8436   LR -> Group0: 3.6601e-06 / Group1: 7.3203e-06 / Group2: 1.0980e-05 / Group3: 1.8301e-04 / Group4: 1.8301e-04 / Group5: 1.8301e-04 / \n",
      "  70/ 170  <train> Loss:0.4367  Acc:0.9222  fbScore:0.8460   LR -> Group0: 3.5294e-06 / Group1: 7.0588e-06 / Group2: 1.0588e-05 / Group3: 1.7647e-04 / Group4: 1.7647e-04 / Group5: 1.7647e-04 / \n",
      "  80/ 170  <train> Loss:0.4205  Acc:0.9203  fbScore:0.8424   LR -> Group0: 3.3987e-06 / Group1: 6.7974e-06 / Group2: 1.0196e-05 / Group3: 1.6993e-04 / Group4: 1.6993e-04 / Group5: 1.6993e-04 / \n",
      "  90/ 170  <train> Loss:0.4059  Acc:0.9211  fbScore:0.8518   LR -> Group0: 3.2680e-06 / Group1: 6.5359e-06 / Group2: 9.8039e-06 / Group3: 1.6340e-04 / Group4: 1.6340e-04 / Group5: 1.6340e-04 / \n",
      " 100/ 170  <train> Loss:0.3938  Acc:0.9230  fbScore:0.8586   LR -> Group0: 3.1373e-06 / Group1: 6.2745e-06 / Group2: 9.4118e-06 / Group3: 1.5686e-04 / Group4: 1.5686e-04 / Group5: 1.5686e-04 / \n",
      " 110/ 170  <train> Loss:0.3791  Acc:0.9246  fbScore:0.8665   LR -> Group0: 3.0065e-06 / Group1: 6.0131e-06 / Group2: 9.0196e-06 / Group3: 1.5033e-04 / Group4: 1.5033e-04 / Group5: 1.5033e-04 / \n",
      " 120/ 170  <train> Loss:0.3703  Acc:0.9266  fbScore:0.8721   LR -> Group0: 2.8758e-06 / Group1: 5.7516e-06 / Group2: 8.6275e-06 / Group3: 1.4379e-04 / Group4: 1.4379e-04 / Group5: 1.4379e-04 / \n",
      " 130/ 170  <train> Loss:0.3563  Acc:0.9282  fbScore:0.8763   LR -> Group0: 2.7451e-06 / Group1: 5.4902e-06 / Group2: 8.2353e-06 / Group3: 1.3725e-04 / Group4: 1.3725e-04 / Group5: 1.3725e-04 / \n",
      " 140/ 170  <train> Loss:0.3457  Acc:0.9301  fbScore:0.8822   LR -> Group0: 2.6144e-06 / Group1: 5.2288e-06 / Group2: 7.8431e-06 / Group3: 1.3072e-04 / Group4: 1.3072e-04 / Group5: 1.3072e-04 / \n",
      " 150/ 170  <train> Loss:0.4063  Acc:0.9312  fbScore:0.8764   LR -> Group0: 2.4837e-06 / Group1: 4.9673e-06 / Group2: 7.4510e-06 / Group3: 1.2418e-04 / Group4: 1.2418e-04 / Group5: 1.2418e-04 / \n",
      " 160/ 170  <train> Loss:0.4077  Acc:0.9280  fbScore:0.8774   LR -> Group0: 2.3529e-06 / Group1: 4.7059e-06 / Group2: 7.0588e-06 / Group3: 1.1765e-04 / Group4: 1.1765e-04 / Group5: 1.1765e-04 / \n",
      " 170/ 170  <train> Loss:0.4107  Acc:0.9244  fbScore:0.8776   LR -> Group0: 2.2222e-06 / Group1: 4.4444e-06 / Group2: 6.6667e-06 / Group3: 1.1111e-04 / Group4: 1.1111e-04 / Group5: 1.1111e-04 / \n",
      "<train> Loss:0.4107  Acc:0.9244  fbScore:0.8776\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db60eeb3ad6f495680b20cbd371404df"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.5291  Acc:0.8773  fbScore:0.8791\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   5/  5】   LR -> Group0: 2.2222e-06 / Group1: 4.4444e-06 / Group2: 6.6667e-06 / Group3: 1.1111e-04 / Group4: 1.1111e-04 / Group5: 1.1111e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "27374e690a424b878ffa95d679f4c346"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:0.3874  Acc:0.8805  fbScore:0.7676   LR -> Group0: 2.0915e-06 / Group1: 4.1830e-06 / Group2: 6.2745e-06 / Group3: 1.0458e-04 / Group4: 1.0458e-04 / Group5: 1.0458e-04 / \n",
      "  20/ 170  <train> Loss:0.3627  Acc:0.8988  fbScore:0.8446   LR -> Group0: 1.9608e-06 / Group1: 3.9216e-06 / Group2: 5.8824e-06 / Group3: 9.8039e-05 / Group4: 9.8039e-05 / Group5: 9.8039e-05 / \n",
      "  30/ 170  <train> Loss:0.3443  Acc:0.9117  fbScore:0.8772   LR -> Group0: 1.8301e-06 / Group1: 3.6601e-06 / Group2: 5.4902e-06 / Group3: 9.1503e-05 / Group4: 9.1503e-05 / Group5: 9.1503e-05 / \n",
      "  40/ 170  <train> Loss:0.3430  Acc:0.9156  fbScore:0.8696   LR -> Group0: 1.6993e-06 / Group1: 3.3987e-06 / Group2: 5.0980e-06 / Group3: 8.4967e-05 / Group4: 8.4967e-05 / Group5: 8.4967e-05 / \n",
      "  50/ 170  <train> Loss:0.3327  Acc:0.9195  fbScore:0.8668   LR -> Group0: 1.5686e-06 / Group1: 3.1373e-06 / Group2: 4.7059e-06 / Group3: 7.8431e-05 / Group4: 7.8431e-05 / Group5: 7.8431e-05 / \n",
      "  60/ 170  <train> Loss:0.3246  Acc:0.9215  fbScore:0.8775   LR -> Group0: 1.4379e-06 / Group1: 2.8758e-06 / Group2: 4.3137e-06 / Group3: 7.1895e-05 / Group4: 7.1895e-05 / Group5: 7.1895e-05 / \n",
      "  70/ 170  <train> Loss:0.3624  Acc:0.9249  fbScore:0.8818   LR -> Group0: 1.3072e-06 / Group1: 2.6144e-06 / Group2: 3.9216e-06 / Group3: 6.5359e-05 / Group4: 6.5359e-05 / Group5: 6.5359e-05 / \n",
      "  80/ 170  <train> Loss:0.3565  Acc:0.9263  fbScore:0.8782   LR -> Group0: 1.1765e-06 / Group1: 2.3529e-06 / Group2: 3.5294e-06 / Group3: 5.8824e-05 / Group4: 5.8824e-05 / Group5: 5.8824e-05 / \n",
      "  90/ 170  <train> Loss:0.3444  Acc:0.9271  fbScore:0.8840   LR -> Group0: 1.0458e-06 / Group1: 2.0915e-06 / Group2: 3.1373e-06 / Group3: 5.2288e-05 / Group4: 5.2288e-05 / Group5: 5.2288e-05 / \n",
      " 100/ 170  <train> Loss:0.3399  Acc:0.9269  fbScore:0.8884   LR -> Group0: 9.1503e-07 / Group1: 1.8301e-06 / Group2: 2.7451e-06 / Group3: 4.5752e-05 / Group4: 4.5752e-05 / Group5: 4.5752e-05 / \n",
      " 110/ 170  <train> Loss:0.3354  Acc:0.9276  fbScore:0.8897   LR -> Group0: 7.8431e-07 / Group1: 1.5686e-06 / Group2: 2.3529e-06 / Group3: 3.9216e-05 / Group4: 3.9216e-05 / Group5: 3.9216e-05 / \n",
      " 120/ 170  <train> Loss:0.3276  Acc:0.9292  fbScore:0.8851   LR -> Group0: 6.5359e-07 / Group1: 1.3072e-06 / Group2: 1.9608e-06 / Group3: 3.2680e-05 / Group4: 3.2680e-05 / Group5: 3.2680e-05 / \n",
      " 130/ 170  <train> Loss:0.3200  Acc:0.9300  fbScore:0.8892   LR -> Group0: 5.2288e-07 / Group1: 1.0458e-06 / Group2: 1.5686e-06 / Group3: 2.6144e-05 / Group4: 2.6144e-05 / Group5: 2.6144e-05 / \n",
      " 140/ 170  <train> Loss:0.3124  Acc:0.9310  fbScore:0.8914   LR -> Group0: 3.9216e-07 / Group1: 7.8431e-07 / Group2: 1.1765e-06 / Group3: 1.9608e-05 / Group4: 1.9608e-05 / Group5: 1.9608e-05 / \n",
      " 150/ 170  <train> Loss:0.3171  Acc:0.9318  fbScore:0.8750   LR -> Group0: 2.6144e-07 / Group1: 5.2288e-07 / Group2: 7.8431e-07 / Group3: 1.3072e-05 / Group4: 1.3072e-05 / Group5: 1.3072e-05 / \n",
      " 160/ 170  <train> Loss:0.3088  Acc:0.9331  fbScore:0.8787   LR -> Group0: 1.3072e-07 / Group1: 2.6144e-07 / Group2: 3.9216e-07 / Group3: 6.5359e-06 / Group4: 6.5359e-06 / Group5: 6.5359e-06 / \n",
      " 170/ 170  <train> Loss:0.3045  Acc:0.9339  fbScore:0.8825   LR -> Group0: 0.0000e+00 / Group1: 0.0000e+00 / Group2: 0.0000e+00 / Group3: 0.0000e+00 / Group4: 0.0000e+00 / Group5: 0.0000e+00 / \n",
      "<train> Loss:0.3045  Acc:0.9339  fbScore:0.8825\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "97f9d07eb09144abb01e5412dac8122b"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.6244  Acc:0.9418  fbScore:0.9015\n",
      "Checkpoints have been updated to the epoch 5 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Evaluate Test Dataset\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d47deaa8f30495ebf2b074f1ec9f147"
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss:0.3083  Acc:0.9451  fbScore:0.9392\n",
      "fb_score : 0.9460852689671903\n",
      "\n",
      "\u001b[32mCross-validation loop : 5/5\u001b[0m\n",
      "Train  ->  label_1:504 / all:21716   (2.321%)\n",
      "Valid  ->  label_1:126 / all:5429   (2.321%)\n",
      "Choosed BertLstmExModel\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "InitLR:2e-05 / num_warmup_steps:85 / num_training_steps:850\n",
      "Use 4 GPUs\n",
      "Using device : cuda\n",
      "【Epoch   1/  5】   LR -> Group0: 0.0000e+00 / Group1: 0.0000e+00 / Group2: 0.0000e+00 / Group3: 0.0000e+00 / Group4: 0.0000e+00 / Group5: 0.0000e+00 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c5c9a962f7f452183f93e8bf9e0a88e"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:3.1621  Acc:0.0242  fbScore:0.4808   LR -> Group0: 1.1765e-06 / Group1: 2.3529e-06 / Group2: 3.5294e-06 / Group3: 5.8824e-05 / Group4: 5.8824e-05 / Group5: 5.8824e-05 / \n",
      "  20/ 170  <train> Loss:3.3191  Acc:0.0258  fbScore:0.5105   LR -> Group0: 2.3529e-06 / Group1: 4.7059e-06 / Group2: 7.0588e-06 / Group3: 1.1765e-04 / Group4: 1.1765e-04 / Group5: 1.1765e-04 / \n",
      "  30/ 170  <train> Loss:3.4995  Acc:0.0276  fbScore:0.5353   LR -> Group0: 3.5294e-06 / Group1: 7.0588e-06 / Group2: 1.0588e-05 / Group3: 1.7647e-04 / Group4: 1.7647e-04 / Group5: 1.7647e-04 / \n",
      "  40/ 170  <train> Loss:3.4671  Acc:0.0273  fbScore:0.5358   LR -> Group0: 4.7059e-06 / Group1: 9.4118e-06 / Group2: 1.4118e-05 / Group3: 2.3529e-04 / Group4: 2.3529e-04 / Group5: 2.3529e-04 / \n",
      "  50/ 170  <train> Loss:3.2801  Acc:0.0256  fbScore:0.5146   LR -> Group0: 5.8824e-06 / Group1: 1.1765e-05 / Group2: 1.7647e-05 / Group3: 2.9412e-04 / Group4: 2.9412e-04 / Group5: 2.9412e-04 / \n",
      "  60/ 170  <train> Loss:3.1432  Acc:0.0246  fbScore:0.5050   LR -> Group0: 7.0588e-06 / Group1: 1.4118e-05 / Group2: 2.1176e-05 / Group3: 3.5294e-04 / Group4: 3.5294e-04 / Group5: 3.5294e-04 / \n",
      "  70/ 170  <train> Loss:3.1375  Acc:0.0249  fbScore:0.5044   LR -> Group0: 8.2353e-06 / Group1: 1.6471e-05 / Group2: 2.4706e-05 / Group3: 4.1176e-04 / Group4: 4.1176e-04 / Group5: 4.1176e-04 / \n",
      "  80/ 170  <train> Loss:3.0917  Acc:0.0247  fbScore:0.5067   LR -> Group0: 9.4118e-06 / Group1: 1.8824e-05 / Group2: 2.8235e-05 / Group3: 4.7059e-04 / Group4: 4.7059e-04 / Group5: 4.7059e-04 / \n",
      "  90/ 170  <train> Loss:2.9979  Acc:0.0240  fbScore:0.5003   LR -> Group0: 9.9346e-06 / Group1: 1.9869e-05 / Group2: 2.9804e-05 / Group3: 4.9673e-04 / Group4: 4.9673e-04 / Group5: 4.9673e-04 / \n",
      " 100/ 170  <train> Loss:2.9242  Acc:0.0237  fbScore:0.4941   LR -> Group0: 9.8039e-06 / Group1: 1.9608e-05 / Group2: 2.9412e-05 / Group3: 4.9020e-04 / Group4: 4.9020e-04 / Group5: 4.9020e-04 / \n",
      " 110/ 170  <train> Loss:2.8395  Acc:0.0232  fbScore:0.4868   LR -> Group0: 9.6732e-06 / Group1: 1.9346e-05 / Group2: 2.9020e-05 / Group3: 4.8366e-04 / Group4: 4.8366e-04 / Group5: 4.8366e-04 / \n",
      " 120/ 170  <train> Loss:2.7627  Acc:0.0229  fbScore:0.4827   LR -> Group0: 9.5425e-06 / Group1: 1.9085e-05 / Group2: 2.8627e-05 / Group3: 4.7712e-04 / Group4: 4.7712e-04 / Group5: 4.7712e-04 / \n",
      " 130/ 170  <train> Loss:2.7049  Acc:0.0242  fbScore:0.4906   LR -> Group0: 9.4118e-06 / Group1: 1.8824e-05 / Group2: 2.8235e-05 / Group3: 4.7059e-04 / Group4: 4.7059e-04 / Group5: 4.7059e-04 / \n",
      " 140/ 170  <train> Loss:2.6113  Acc:0.0316  fbScore:0.4839   LR -> Group0: 9.2810e-06 / Group1: 1.8562e-05 / Group2: 2.7843e-05 / Group3: 4.6405e-04 / Group4: 4.6405e-04 / Group5: 4.6405e-04 / \n",
      " 150/ 170  <train> Loss:2.5315  Acc:0.0573  fbScore:0.4973   LR -> Group0: 9.1503e-06 / Group1: 1.8301e-05 / Group2: 2.7451e-05 / Group3: 4.5752e-04 / Group4: 4.5752e-04 / Group5: 4.5752e-04 / \n",
      " 160/ 170  <train> Loss:2.4864  Acc:0.1087  fbScore:0.5042   LR -> Group0: 9.0196e-06 / Group1: 1.8039e-05 / Group2: 2.7059e-05 / Group3: 4.5098e-04 / Group4: 4.5098e-04 / Group5: 4.5098e-04 / \n",
      " 170/ 170  <train> Loss:2.4203  Acc:0.1506  fbScore:0.5183   LR -> Group0: 8.8889e-06 / Group1: 1.7778e-05 / Group2: 2.6667e-05 / Group3: 4.4444e-04 / Group4: 4.4444e-04 / Group5: 4.4444e-04 / \n",
      "<train> Loss:2.4203  Acc:0.1506  fbScore:0.5183\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c4cee79bb0d4ce296c3664e55945d9f"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:1.1873  Acc:0.7484  fbScore:0.7903\n",
      "Checkpoints have been updated to the epoch 1 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   2/  5】   LR -> Group0: 8.8889e-06 / Group1: 1.7778e-05 / Group2: 2.6667e-05 / Group3: 4.4444e-04 / Group4: 4.4444e-04 / Group5: 4.4444e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79216f69daa94f22baf6618b1b583a5e"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:1.0751  Acc:0.7000  fbScore:0.7189   LR -> Group0: 8.7582e-06 / Group1: 1.7516e-05 / Group2: 2.6275e-05 / Group3: 4.3791e-04 / Group4: 4.3791e-04 / Group5: 4.3791e-04 / \n",
      "  20/ 170  <train> Loss:1.1111  Acc:0.7973  fbScore:0.7598   LR -> Group0: 8.6275e-06 / Group1: 1.7255e-05 / Group2: 2.5882e-05 / Group3: 4.3137e-04 / Group4: 4.3137e-04 / Group5: 4.3137e-04 / \n",
      "  30/ 170  <train> Loss:1.0848  Acc:0.8172  fbScore:0.7707   LR -> Group0: 8.4967e-06 / Group1: 1.6993e-05 / Group2: 2.5490e-05 / Group3: 4.2484e-04 / Group4: 4.2484e-04 / Group5: 4.2484e-04 / \n",
      "  40/ 170  <train> Loss:1.0975  Acc:0.8053  fbScore:0.7722   LR -> Group0: 8.3660e-06 / Group1: 1.6732e-05 / Group2: 2.5098e-05 / Group3: 4.1830e-04 / Group4: 4.1830e-04 / Group5: 4.1830e-04 / \n",
      "  50/ 170  <train> Loss:1.0423  Acc:0.8137  fbScore:0.7694   LR -> Group0: 8.2353e-06 / Group1: 1.6471e-05 / Group2: 2.4706e-05 / Group3: 4.1176e-04 / Group4: 4.1176e-04 / Group5: 4.1176e-04 / \n",
      "  60/ 170  <train> Loss:0.9708  Acc:0.8188  fbScore:0.7684   LR -> Group0: 8.1046e-06 / Group1: 1.6209e-05 / Group2: 2.4314e-05 / Group3: 4.0523e-04 / Group4: 4.0523e-04 / Group5: 4.0523e-04 / \n",
      "  70/ 170  <train> Loss:0.9384  Acc:0.8271  fbScore:0.7745   LR -> Group0: 7.9739e-06 / Group1: 1.5948e-05 / Group2: 2.3922e-05 / Group3: 3.9869e-04 / Group4: 3.9869e-04 / Group5: 3.9869e-04 / \n",
      "  80/ 170  <train> Loss:0.9534  Acc:0.8351  fbScore:0.7530   LR -> Group0: 7.8431e-06 / Group1: 1.5686e-05 / Group2: 2.3529e-05 / Group3: 3.9216e-04 / Group4: 3.9216e-04 / Group5: 3.9216e-04 / \n",
      "  90/ 170  <train> Loss:0.9317  Acc:0.8296  fbScore:0.7495   LR -> Group0: 7.7124e-06 / Group1: 1.5425e-05 / Group2: 2.3137e-05 / Group3: 3.8562e-04 / Group4: 3.8562e-04 / Group5: 3.8562e-04 / \n",
      " 100/ 170  <train> Loss:0.9340  Acc:0.8345  fbScore:0.7333   LR -> Group0: 7.5817e-06 / Group1: 1.5163e-05 / Group2: 2.2745e-05 / Group3: 3.7908e-04 / Group4: 3.7908e-04 / Group5: 3.7908e-04 / \n",
      " 110/ 170  <train> Loss:0.9406  Acc:0.8310  fbScore:0.7399   LR -> Group0: 7.4510e-06 / Group1: 1.4902e-05 / Group2: 2.2353e-05 / Group3: 3.7255e-04 / Group4: 3.7255e-04 / Group5: 3.7255e-04 / \n",
      " 120/ 170  <train> Loss:0.9408  Acc:0.8247  fbScore:0.7365   LR -> Group0: 7.3203e-06 / Group1: 1.4641e-05 / Group2: 2.1961e-05 / Group3: 3.6601e-04 / Group4: 3.6601e-04 / Group5: 3.6601e-04 / \n",
      " 130/ 170  <train> Loss:0.9339  Acc:0.8302  fbScore:0.7405   LR -> Group0: 7.1895e-06 / Group1: 1.4379e-05 / Group2: 2.1569e-05 / Group3: 3.5948e-04 / Group4: 3.5948e-04 / Group5: 3.5948e-04 / \n",
      " 140/ 170  <train> Loss:0.9042  Acc:0.8347  fbScore:0.7487   LR -> Group0: 7.0588e-06 / Group1: 1.4118e-05 / Group2: 2.1176e-05 / Group3: 3.5294e-04 / Group4: 3.5294e-04 / Group5: 3.5294e-04 / \n",
      " 150/ 170  <train> Loss:0.9072  Acc:0.8370  fbScore:0.7544   LR -> Group0: 6.9281e-06 / Group1: 1.3856e-05 / Group2: 2.0784e-05 / Group3: 3.4641e-04 / Group4: 3.4641e-04 / Group5: 3.4641e-04 / \n",
      " 160/ 170  <train> Loss:0.8839  Acc:0.8384  fbScore:0.7635   LR -> Group0: 6.7974e-06 / Group1: 1.3595e-05 / Group2: 2.0392e-05 / Group3: 3.3987e-04 / Group4: 3.3987e-04 / Group5: 3.3987e-04 / \n",
      " 170/ 170  <train> Loss:0.8915  Acc:0.8429  fbScore:0.7694   LR -> Group0: 6.6667e-06 / Group1: 1.3333e-05 / Group2: 2.0000e-05 / Group3: 3.3333e-04 / Group4: 3.3333e-04 / Group5: 3.3333e-04 / \n",
      "<train> Loss:0.8915  Acc:0.8429  fbScore:0.7694\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6231a02de3e4439baf228eec5d6b23a9"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.6936  Acc:0.8425  fbScore:0.8495\n",
      "Checkpoints have been updated to the epoch 2 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   3/  5】   LR -> Group0: 6.6667e-06 / Group1: 1.3333e-05 / Group2: 2.0000e-05 / Group3: 3.3333e-04 / Group4: 3.3333e-04 / Group5: 3.3333e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "057f98c99e634ffe949a9ebf8172dea7"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:0.6319  Acc:0.7937  fbScore:0.6611   LR -> Group0: 6.5359e-06 / Group1: 1.3072e-05 / Group2: 1.9608e-05 / Group3: 3.2680e-04 / Group4: 3.2680e-04 / Group5: 3.2680e-04 / \n",
      "  20/ 170  <train> Loss:0.5781  Acc:0.8340  fbScore:0.7804   LR -> Group0: 6.4052e-06 / Group1: 1.2810e-05 / Group2: 1.9216e-05 / Group3: 3.2026e-04 / Group4: 3.2026e-04 / Group5: 3.2026e-04 / \n",
      "  30/ 170  <train> Loss:0.5764  Acc:0.8576  fbScore:0.8125   LR -> Group0: 6.2745e-06 / Group1: 1.2549e-05 / Group2: 1.8824e-05 / Group3: 3.1373e-04 / Group4: 3.1373e-04 / Group5: 3.1373e-04 / \n",
      "  40/ 170  <train> Loss:0.5633  Acc:0.8570  fbScore:0.8091   LR -> Group0: 6.1438e-06 / Group1: 1.2288e-05 / Group2: 1.8431e-05 / Group3: 3.0719e-04 / Group4: 3.0719e-04 / Group5: 3.0719e-04 / \n",
      "  50/ 170  <train> Loss:0.5292  Acc:0.8711  fbScore:0.8379   LR -> Group0: 6.0131e-06 / Group1: 1.2026e-05 / Group2: 1.8039e-05 / Group3: 3.0065e-04 / Group4: 3.0065e-04 / Group5: 3.0065e-04 / \n",
      "  60/ 170  <train> Loss:0.5047  Acc:0.8799  fbScore:0.8529   LR -> Group0: 5.8824e-06 / Group1: 1.1765e-05 / Group2: 1.7647e-05 / Group3: 2.9412e-04 / Group4: 2.9412e-04 / Group5: 2.9412e-04 / \n",
      "  70/ 170  <train> Loss:0.4836  Acc:0.8853  fbScore:0.8622   LR -> Group0: 5.7516e-06 / Group1: 1.1503e-05 / Group2: 1.7255e-05 / Group3: 2.8758e-04 / Group4: 2.8758e-04 / Group5: 2.8758e-04 / \n",
      "  80/ 170  <train> Loss:0.4978  Acc:0.8912  fbScore:0.8640   LR -> Group0: 5.6209e-06 / Group1: 1.1242e-05 / Group2: 1.6863e-05 / Group3: 2.8105e-04 / Group4: 2.8105e-04 / Group5: 2.8105e-04 / \n",
      "  90/ 170  <train> Loss:0.4915  Acc:0.8915  fbScore:0.8578   LR -> Group0: 5.4902e-06 / Group1: 1.0980e-05 / Group2: 1.6471e-05 / Group3: 2.7451e-04 / Group4: 2.7451e-04 / Group5: 2.7451e-04 / \n",
      " 100/ 170  <train> Loss:0.4862  Acc:0.8901  fbScore:0.8589   LR -> Group0: 5.3595e-06 / Group1: 1.0719e-05 / Group2: 1.6078e-05 / Group3: 2.6797e-04 / Group4: 2.6797e-04 / Group5: 2.6797e-04 / \n",
      " 110/ 170  <train> Loss:0.4765  Acc:0.8918  fbScore:0.8555   LR -> Group0: 5.2288e-06 / Group1: 1.0458e-05 / Group2: 1.5686e-05 / Group3: 2.6144e-04 / Group4: 2.6144e-04 / Group5: 2.6144e-04 / \n",
      " 120/ 170  <train> Loss:0.4763  Acc:0.8948  fbScore:0.8593   LR -> Group0: 5.0980e-06 / Group1: 1.0196e-05 / Group2: 1.5294e-05 / Group3: 2.5490e-04 / Group4: 2.5490e-04 / Group5: 2.5490e-04 / \n",
      " 130/ 170  <train> Loss:0.4756  Acc:0.8924  fbScore:0.8600   LR -> Group0: 4.9673e-06 / Group1: 9.9346e-06 / Group2: 1.4902e-05 / Group3: 2.4837e-04 / Group4: 2.4837e-04 / Group5: 2.4837e-04 / \n",
      " 140/ 170  <train> Loss:0.4975  Acc:0.8920  fbScore:0.8593   LR -> Group0: 4.8366e-06 / Group1: 9.6732e-06 / Group2: 1.4510e-05 / Group3: 2.4183e-04 / Group4: 2.4183e-04 / Group5: 2.4183e-04 / \n",
      " 150/ 170  <train> Loss:0.4865  Acc:0.8927  fbScore:0.8563   LR -> Group0: 4.7059e-06 / Group1: 9.4118e-06 / Group2: 1.4118e-05 / Group3: 2.3529e-04 / Group4: 2.3529e-04 / Group5: 2.3529e-04 / \n",
      " 160/ 170  <train> Loss:0.4752  Acc:0.8959  fbScore:0.8617   LR -> Group0: 4.5752e-06 / Group1: 9.1503e-06 / Group2: 1.3725e-05 / Group3: 2.2876e-04 / Group4: 2.2876e-04 / Group5: 2.2876e-04 / \n",
      " 170/ 170  <train> Loss:0.4957  Acc:0.8951  fbScore:0.8580   LR -> Group0: 4.4444e-06 / Group1: 8.8889e-06 / Group2: 1.3333e-05 / Group3: 2.2222e-04 / Group4: 2.2222e-04 / Group5: 2.2222e-04 / \n",
      "<train> Loss:0.4957  Acc:0.8951  fbScore:0.8580\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72007942d04745f59926692ee233a2e6"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.5228  Acc:0.8840  fbScore:0.8919\n",
      "Checkpoints have been updated to the epoch 3 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   4/  5】   LR -> Group0: 4.4444e-06 / Group1: 8.8889e-06 / Group2: 1.3333e-05 / Group3: 2.2222e-04 / Group4: 2.2222e-04 / Group5: 2.2222e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b6701f05c7a47d7a0090fc91f952a24"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:0.3580  Acc:0.9125  fbScore:0.9336   LR -> Group0: 4.3137e-06 / Group1: 8.6275e-06 / Group2: 1.2941e-05 / Group3: 2.1569e-04 / Group4: 2.1569e-04 / Group5: 2.1569e-04 / \n",
      "  20/ 170  <train> Loss:0.2692  Acc:0.9344  fbScore:0.8484   LR -> Group0: 4.1830e-06 / Group1: 8.3660e-06 / Group2: 1.2549e-05 / Group3: 2.0915e-04 / Group4: 2.0915e-04 / Group5: 2.0915e-04 / \n",
      "  30/ 170  <train> Loss:0.2604  Acc:0.9435  fbScore:0.8525   LR -> Group0: 4.0523e-06 / Group1: 8.1046e-06 / Group2: 1.2157e-05 / Group3: 2.0261e-04 / Group4: 2.0261e-04 / Group5: 2.0261e-04 / \n",
      "  40/ 170  <train> Loss:0.2477  Acc:0.9469  fbScore:0.8549   LR -> Group0: 3.9216e-06 / Group1: 7.8431e-06 / Group2: 1.1765e-05 / Group3: 1.9608e-04 / Group4: 1.9608e-04 / Group5: 1.9608e-04 / \n",
      "  50/ 170  <train> Loss:0.2546  Acc:0.9475  fbScore:0.8765   LR -> Group0: 3.7908e-06 / Group1: 7.5817e-06 / Group2: 1.1373e-05 / Group3: 1.8954e-04 / Group4: 1.8954e-04 / Group5: 1.8954e-04 / \n",
      "  60/ 170  <train> Loss:0.2672  Acc:0.9441  fbScore:0.8883   LR -> Group0: 3.6601e-06 / Group1: 7.3203e-06 / Group2: 1.0980e-05 / Group3: 1.8301e-04 / Group4: 1.8301e-04 / Group5: 1.8301e-04 / \n",
      "  70/ 170  <train> Loss:0.2704  Acc:0.9426  fbScore:0.8820   LR -> Group0: 3.5294e-06 / Group1: 7.0588e-06 / Group2: 1.0588e-05 / Group3: 1.7647e-04 / Group4: 1.7647e-04 / Group5: 1.7647e-04 / \n",
      "  80/ 170  <train> Loss:0.2664  Acc:0.9451  fbScore:0.8668   LR -> Group0: 3.3987e-06 / Group1: 6.7974e-06 / Group2: 1.0196e-05 / Group3: 1.6993e-04 / Group4: 1.6993e-04 / Group5: 1.6993e-04 / \n",
      "  90/ 170  <train> Loss:0.2845  Acc:0.9447  fbScore:0.8518   LR -> Group0: 3.2680e-06 / Group1: 6.5359e-06 / Group2: 9.8039e-06 / Group3: 1.6340e-04 / Group4: 1.6340e-04 / Group5: 1.6340e-04 / \n",
      " 100/ 170  <train> Loss:0.2943  Acc:0.9409  fbScore:0.8580   LR -> Group0: 3.1373e-06 / Group1: 6.2745e-06 / Group2: 9.4118e-06 / Group3: 1.5686e-04 / Group4: 1.5686e-04 / Group5: 1.5686e-04 / \n",
      " 110/ 170  <train> Loss:0.2984  Acc:0.9384  fbScore:0.8573   LR -> Group0: 3.0065e-06 / Group1: 6.0131e-06 / Group2: 9.0196e-06 / Group3: 1.5033e-04 / Group4: 1.5033e-04 / Group5: 1.5033e-04 / \n",
      " 120/ 170  <train> Loss:0.2970  Acc:0.9391  fbScore:0.8650   LR -> Group0: 2.8758e-06 / Group1: 5.7516e-06 / Group2: 8.6275e-06 / Group3: 1.4379e-04 / Group4: 1.4379e-04 / Group5: 1.4379e-04 / \n",
      " 130/ 170  <train> Loss:0.3021  Acc:0.9384  fbScore:0.8619   LR -> Group0: 2.7451e-06 / Group1: 5.4902e-06 / Group2: 8.2353e-06 / Group3: 1.3725e-04 / Group4: 1.3725e-04 / Group5: 1.3725e-04 / \n",
      " 140/ 170  <train> Loss:0.3023  Acc:0.9373  fbScore:0.8599   LR -> Group0: 2.6144e-06 / Group1: 5.2288e-06 / Group2: 7.8431e-06 / Group3: 1.3072e-04 / Group4: 1.3072e-04 / Group5: 1.3072e-04 / \n",
      " 150/ 170  <train> Loss:0.2985  Acc:0.9371  fbScore:0.8578   LR -> Group0: 2.4837e-06 / Group1: 4.9673e-06 / Group2: 7.4510e-06 / Group3: 1.2418e-04 / Group4: 1.2418e-04 / Group5: 1.2418e-04 / \n",
      " 160/ 170  <train> Loss:0.3206  Acc:0.9379  fbScore:0.8621   LR -> Group0: 2.3529e-06 / Group1: 4.7059e-06 / Group2: 7.0588e-06 / Group3: 1.1765e-04 / Group4: 1.1765e-04 / Group5: 1.1765e-04 / \n",
      " 170/ 170  <train> Loss:0.3154  Acc:0.9383  fbScore:0.8669   LR -> Group0: 2.2222e-06 / Group1: 4.4444e-06 / Group2: 6.6667e-06 / Group3: 1.1111e-04 / Group4: 1.1111e-04 / Group5: 1.1111e-04 / \n",
      "<train> Loss:0.3154  Acc:0.9383  fbScore:0.8669\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d6f1ed8a3c854f1187c33b014423cc1a"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.6820  Acc:0.9396  fbScore:0.8993\n",
      "Checkpoints have been updated to the epoch 4 weights.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【Epoch   5/  5】   LR -> Group0: 2.2222e-06 / Group1: 4.4444e-06 / Group2: 6.6667e-06 / Group3: 1.1111e-04 / Group4: 1.1111e-04 / Group5: 1.1111e-04 / \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af43a1d464fe43c19995d0e8d98eb0c8"
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  10/ 170  <train> Loss:0.2413  Acc:0.9531  fbScore:0.9544   LR -> Group0: 2.0915e-06 / Group1: 4.1830e-06 / Group2: 6.2745e-06 / Group3: 1.0458e-04 / Group4: 1.0458e-04 / Group5: 1.0458e-04 / \n",
      "  20/ 170  <train> Loss:0.2680  Acc:0.9480  fbScore:0.9483   LR -> Group0: 1.9608e-06 / Group1: 3.9216e-06 / Group2: 5.8824e-06 / Group3: 9.8039e-05 / Group4: 9.8039e-05 / Group5: 9.8039e-05 / \n",
      "  30/ 170  <train> Loss:0.2879  Acc:0.9365  fbScore:0.9068   LR -> Group0: 1.8301e-06 / Group1: 3.6601e-06 / Group2: 5.4902e-06 / Group3: 9.1503e-05 / Group4: 9.1503e-05 / Group5: 9.1503e-05 / \n",
      "  40/ 170  <train> Loss:0.3399  Acc:0.9373  fbScore:0.9026   LR -> Group0: 1.6993e-06 / Group1: 3.3987e-06 / Group2: 5.0980e-06 / Group3: 8.4967e-05 / Group4: 8.4967e-05 / Group5: 8.4967e-05 / \n",
      "  50/ 170  <train> Loss:0.3219  Acc:0.9366  fbScore:0.9088   LR -> Group0: 1.5686e-06 / Group1: 3.1373e-06 / Group2: 4.7059e-06 / Group3: 7.8431e-05 / Group4: 7.8431e-05 / Group5: 7.8431e-05 / \n",
      "  60/ 170  <train> Loss:0.3051  Acc:0.9396  fbScore:0.9169   LR -> Group0: 1.4379e-06 / Group1: 2.8758e-06 / Group2: 4.3137e-06 / Group3: 7.1895e-05 / Group4: 7.1895e-05 / Group5: 7.1895e-05 / \n",
      "  70/ 170  <train> Loss:0.2844  Acc:0.9433  fbScore:0.9224   LR -> Group0: 1.3072e-06 / Group1: 2.6144e-06 / Group2: 3.9216e-06 / Group3: 6.5359e-05 / Group4: 6.5359e-05 / Group5: 6.5359e-05 / \n",
      "  80/ 170  <train> Loss:0.2776  Acc:0.9450  fbScore:0.9273   LR -> Group0: 1.1765e-06 / Group1: 2.3529e-06 / Group2: 3.5294e-06 / Group3: 5.8824e-05 / Group4: 5.8824e-05 / Group5: 5.8824e-05 / \n",
      "  90/ 170  <train> Loss:0.2665  Acc:0.9463  fbScore:0.9296   LR -> Group0: 1.0458e-06 / Group1: 2.0915e-06 / Group2: 3.1373e-06 / Group3: 5.2288e-05 / Group4: 5.2288e-05 / Group5: 5.2288e-05 / \n",
      " 100/ 170  <train> Loss:0.2685  Acc:0.9466  fbScore:0.9321   LR -> Group0: 9.1503e-07 / Group1: 1.8301e-06 / Group2: 2.7451e-06 / Group3: 4.5752e-05 / Group4: 4.5752e-05 / Group5: 4.5752e-05 / \n",
      " 110/ 170  <train> Loss:0.2611  Acc:0.9475  fbScore:0.9343   LR -> Group0: 7.8431e-07 / Group1: 1.5686e-06 / Group2: 2.3529e-06 / Group3: 3.9216e-05 / Group4: 3.9216e-05 / Group5: 3.9216e-05 / \n",
      " 120/ 170  <train> Loss:0.2550  Acc:0.9485  fbScore:0.9272   LR -> Group0: 6.5359e-07 / Group1: 1.3072e-06 / Group2: 1.9608e-06 / Group3: 3.2680e-05 / Group4: 3.2680e-05 / Group5: 3.2680e-05 / \n",
      " 130/ 170  <train> Loss:0.2550  Acc:0.9496  fbScore:0.9288   LR -> Group0: 5.2288e-07 / Group1: 1.0458e-06 / Group2: 1.5686e-06 / Group3: 2.6144e-05 / Group4: 2.6144e-05 / Group5: 2.6144e-05 / \n",
      " 140/ 170  <train> Loss:0.2503  Acc:0.9497  fbScore:0.9298   LR -> Group0: 3.9216e-07 / Group1: 7.8431e-07 / Group2: 1.1765e-06 / Group3: 1.9608e-05 / Group4: 1.9608e-05 / Group5: 1.9608e-05 / \n",
      " 150/ 170  <train> Loss:0.2501  Acc:0.9496  fbScore:0.9315   LR -> Group0: 2.6144e-07 / Group1: 5.2288e-07 / Group2: 7.8431e-07 / Group3: 1.3072e-05 / Group4: 1.3072e-05 / Group5: 1.3072e-05 / \n",
      " 160/ 170  <train> Loss:0.2458  Acc:0.9504  fbScore:0.9339   LR -> Group0: 1.3072e-07 / Group1: 2.6144e-07 / Group2: 3.9216e-07 / Group3: 6.5359e-06 / Group4: 6.5359e-06 / Group5: 6.5359e-06 / \n",
      " 170/ 170  <train> Loss:0.2422  Acc:0.9507  fbScore:0.9351   LR -> Group0: 0.0000e+00 / Group1: 0.0000e+00 / Group2: 0.0000e+00 / Group3: 0.0000e+00 / Group4: 0.0000e+00 / Group5: 0.0000e+00 / \n",
      "<train> Loss:0.2422  Acc:0.9507  fbScore:0.9351\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1e676369f6441a1a9cdbab842f99f81"
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:0.9162  Acc:0.9497  fbScore:0.8863\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Evaluate Test Dataset\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7482d0ea216343ec82da86b5b0b3d1fd"
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss:0.3243  Acc:0.9419  fbScore:0.9354\n",
      "fb_score : 0.94359594737638\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "logs.keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['fit_history', 'test_preds_labels', 'test_fb_score'])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "logs['test_fb_score'][1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9067357512953368"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "for i in range(hps.cv_n):\n",
    "    fb_score = logs['test_fb_score'][i]\n",
    "    print(fb_score)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9028831562974203\n",
      "0.9067357512953368\n",
      "0.884621200665356\n",
      "0.892047172664046\n",
      "0.8957654723127035\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "test_pred_df = pd.DataFrame(columns=[f\"cv{i}\" for i in range(hps.cv_n)] + ['cv_ensemble', 'label'])\n",
    "test_pred_df['label'] = logs['test_preds_labels'][0]['labels']\n",
    "for i in range(hps.cv_n):\n",
    "    test_pred_df[f\"cv{i}\"] = logs['test_preds_labels'][i]['preds']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_pred_df['cv_ensemble'] = test_pred_df.loc[:, 'cv0':'cv4'].mean(axis=1).map(lambda x: 1 if x >= 0.5 else 0)\n",
    "\n",
    "\n",
    "display(test_pred_df)\n",
    "display(test_pred_df.describe())"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv0</th>\n",
       "      <th>cv1</th>\n",
       "      <th>cv2</th>\n",
       "      <th>cv3</th>\n",
       "      <th>cv4</th>\n",
       "      <th>cv_ensemble</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5429 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cv0  cv1  cv2  cv3  cv4  cv_ensemble  label\n",
       "0     0.0  0.0  0.0  0.0  0.0            0    0.0\n",
       "1     0.0  0.0  0.0  0.0  0.0            0    0.0\n",
       "2     0.0  0.0  0.0  0.0  0.0            0    0.0\n",
       "3     0.0  0.0  0.0  0.0  0.0            0    0.0\n",
       "4     0.0  0.0  0.0  0.0  0.0            0    0.0\n",
       "...   ...  ...  ...  ...  ...          ...    ...\n",
       "5424  0.0  0.0  0.0  0.0  0.0            0    0.0\n",
       "5425  0.0  0.0  0.0  0.0  1.0            0    0.0\n",
       "5426  0.0  0.0  0.0  0.0  0.0            0    0.0\n",
       "5427  0.0  0.0  0.0  0.0  0.0            0    0.0\n",
       "5428  0.0  0.0  0.0  0.0  0.0            0    0.0\n",
       "\n",
       "[5429 rows x 7 columns]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv0</th>\n",
       "      <th>cv1</th>\n",
       "      <th>cv2</th>\n",
       "      <th>cv3</th>\n",
       "      <th>cv4</th>\n",
       "      <th>cv_ensemble</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5429.000000</td>\n",
       "      <td>5429.000000</td>\n",
       "      <td>5429.000000</td>\n",
       "      <td>5429.000000</td>\n",
       "      <td>5429.000000</td>\n",
       "      <td>5429.000000</td>\n",
       "      <td>5429.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.076626</td>\n",
       "      <td>0.071468</td>\n",
       "      <td>0.080862</td>\n",
       "      <td>0.081046</td>\n",
       "      <td>0.106834</td>\n",
       "      <td>0.076441</td>\n",
       "      <td>0.023209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.266021</td>\n",
       "      <td>0.257629</td>\n",
       "      <td>0.272648</td>\n",
       "      <td>0.272931</td>\n",
       "      <td>0.308930</td>\n",
       "      <td>0.265727</td>\n",
       "      <td>0.150580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cv0          cv1          cv2          cv3          cv4  \\\n",
       "count  5429.000000  5429.000000  5429.000000  5429.000000  5429.000000   \n",
       "mean      0.076626     0.071468     0.080862     0.081046     0.106834   \n",
       "std       0.266021     0.257629     0.272648     0.272931     0.308930   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "       cv_ensemble        label  \n",
       "count  5429.000000  5429.000000  \n",
       "mean      0.076441     0.023209  \n",
       "std       0.265727     0.150580  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     0.000000  \n",
       "50%       0.000000     0.000000  \n",
       "75%       0.000000     0.000000  \n",
       "max       1.000000     1.000000  "
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "cv_ensemble_fb_score = fbeta_score(y_true=test_pred_df['label'], y_pred=test_pred_df['cv_ensemble'], beta=7.0)\n",
    "print(f\"CV_Ensemble_Fb_score : {cv_ensemble_fb_score}\")"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'test_pred_df' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24300/2965301505.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv_ensemble_fb_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfbeta_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_pred_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_pred_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cv_ensemble'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"CV_Ensemble_Fb_score : {cv_ensemble_fb_score}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_pred_df' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Submit"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "class Predicting:\n",
    "    def __init__(self, weights_dir:str):\n",
    "        self.weights_dir = weights_dir\n",
    "        self.logs = {'test_preds_labels':[]}\n",
    "        self.pred_df = pd.DataFrame(columns=[f\"cv{i}\" for i in range(hps.cv_n)] + ['cv_ensemble', 'label'])\n",
    "\n",
    "    def predict(self, df, pred_phase='submit'):\n",
    "\n",
    "        df.reset_index(drop=False, inplace=True)\n",
    "\n",
    "        weights_path_list = os.listdir(self.weights_dir)\n",
    "        for weights_path in weights_path_list:\n",
    "            print('\\033[32m' + weights_path + '\\033[0m')\n",
    "\n",
    "            # load model\n",
    "            if hps.model_type == 'lstm':\n",
    "                print(f\"Choosed BertLstmModel\")\n",
    "                model = BertLstmModel(hidden_size=bert_config.hidden_size)\n",
    "            elif hps.model_type == 'lstm_ex':\n",
    "                print(f\"Choosed BertLstmExModel\")\n",
    "                model = BertLstmExModel(hidden_size=bert_config.hidden_size, config=bert_config, use_hidden_n=4)\n",
    "            \n",
    "            # To GPU\n",
    "            print(f\"Model to GPU ... \", end='')\n",
    "            model = model.to(device)\n",
    "            device_num = torch.cuda.device_count()\n",
    "            if device_num > 1:\n",
    "                print(f\"Use {device_num} GPUs \", end='')\n",
    "                model = nn.DataParallel(model)\n",
    "            print(f\"Done!\")\n",
    "\n",
    "            # load\n",
    "            print(f\"Loading model ... \", end='')\n",
    "            model.load_state_dict(torch.load(os.path.join(self.weights_dir, weights_path)))\n",
    "            print(f\"Done!\")\n",
    "\n",
    "            # Datasets / Dataloaders\n",
    "\n",
    "            phase_param = {\n",
    "                \"argument\":{'test': False, 'submit': False},\n",
    "                \"batch_size\":{'test':hps.batch_size*4, 'submit': hps.batch_size*4},\n",
    "                \"shuffle\":{'test': False, 'submit': False},\n",
    "                \"upsample_pos_n\":{'val': 1, 'test': 1, 'submit': 1},\n",
    "            }\n",
    "            datasets = {phase:TextClassificationDataset(df=df, tokenizer=base_tokenizer, use_col=hps.use_col,\\\n",
    "                                                        token_max_length=hps.token_max_length, argument=phase_param['argument'][phase],\\\n",
    "                                                        upsample_pos_n=phase_param['upsample_pos_n'][phase]) for phase in ['test', 'submit']}\n",
    "            dataloaders = {phase: DataLoader(datasets[phase], batch_size=phase_param['batch_size'][phase], \\\n",
    "                                            shuffle=phase_param['shuffle'][phase]) for phase in ['test', 'submit']}\n",
    "\n",
    "\n",
    "            # inference\n",
    "            preds_labels_dict = inference(model, dataloader=dataloaders[pred_phase], device=device, evaluate=False)\n",
    "            self.logs['test_preds_labels'].append(preds_labels_dict)\n",
    "\n",
    "            del model, datasets, dataloaders\n",
    "            torch.cuda.empty_cache()\n",
    "            print()\n",
    "\n",
    "    def get_logs(self):\n",
    "        return self.logs\n",
    "\n",
    "    def ensemble(self):\n",
    "        \n",
    "        self.pred_df['label'] = self.logs['test_preds_labels'][0]['labels']\n",
    "        for i in range(hps.cv_n):\n",
    "            self.pred_df[f\"cv{i}\"] = self.logs['test_preds_labels'][i]['preds']\n",
    "        self.pred_df['cv_ensemble'] = self.pred_df.loc[:, 'cv0':'cv4'].mean(axis=1).map(lambda x: 1 if x >= 0.5 else 0)\n",
    "        return self.pred_df\n",
    "\n",
    "    def get_fb_score(self):\n",
    "        cv_ensemble_fb_score = fbeta_score(y_true=self.pred_df['label'], y_pred=self.pred_df['cv_ensemble'], beta=7.0)\n",
    "        return cv_ensemble_fb_score\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "predict = Predicting(weights_dir='cross_validation_weights')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "predict.predict(df=submit_df.copy(), pred_phase='submit')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[32mbert_text_classification_cv0.pth\u001b[0m\n",
      "Choosed BertLstmExModel\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model to GPU ... Use 4 GPUs Done!\n",
      "Loading model ... Done!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d2757a0004e4ad3906645b3208b3862"
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\u001b[32mbert_text_classification_cv1.pth\u001b[0m\n",
      "Choosed BertLstmExModel\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model to GPU ... Use 4 GPUs Done!\n",
      "Loading model ... Done!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c09aaa75e50e45e18e2b637ecac89c74"
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\u001b[32mbert_text_classification_cv2.pth\u001b[0m\n",
      "Choosed BertLstmExModel\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model to GPU ... Use 4 GPUs Done!\n",
      "Loading model ... Done!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "10937d8717db4be392612fb8125858bd"
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\u001b[32mbert_text_classification_cv3.pth\u001b[0m\n",
      "Choosed BertLstmExModel\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model to GPU ... Use 4 GPUs Done!\n",
      "Loading model ... Done!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45d5dfb69c864873a19e942182fe4ae9"
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\u001b[32mbert_text_classification_cv4.pth\u001b[0m\n",
      "Choosed BertLstmExModel\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model to GPU ... Use 4 GPUs Done!\n",
      "Loading model ... Done!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad7a10bf60ae4800981873a67e50820f"
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "pred_df = predict.ensemble()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "pred_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv0</th>\n",
       "      <th>cv1</th>\n",
       "      <th>cv2</th>\n",
       "      <th>cv3</th>\n",
       "      <th>cv4</th>\n",
       "      <th>cv_ensemble</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27145</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27146</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27147</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27148</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27149</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67974</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67975</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67976</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67977</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67978</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40834 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cv0  cv1  cv2  cv3  cv4  cv_ensemble  label\n",
       "27145  0.0  0.0  0.0  0.0  0.0            0   -1.0\n",
       "27146  0.0  0.0  0.0  0.0  0.0            0   -1.0\n",
       "27147  0.0  0.0  0.0  0.0  0.0            0   -1.0\n",
       "27148  0.0  0.0  0.0  0.0  0.0            0   -1.0\n",
       "27149  0.0  0.0  0.0  0.0  0.0            0   -1.0\n",
       "...    ...  ...  ...  ...  ...          ...    ...\n",
       "67974  0.0  0.0  0.0  0.0  0.0            0   -1.0\n",
       "67975  0.0  0.0  0.0  0.0  0.0            0   -1.0\n",
       "67976  0.0  0.0  0.0  0.0  0.0            0   -1.0\n",
       "67977  0.0  0.0  0.0  0.0  0.0            0   -1.0\n",
       "67978  0.0  0.0  0.0  0.0  0.0            0   -1.0\n",
       "\n",
       "[40834 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "pred_df.describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv0</th>\n",
       "      <th>cv1</th>\n",
       "      <th>cv2</th>\n",
       "      <th>cv3</th>\n",
       "      <th>cv4</th>\n",
       "      <th>cv_ensemble</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40834.000000</td>\n",
       "      <td>40834.000000</td>\n",
       "      <td>40834.000000</td>\n",
       "      <td>40834.000000</td>\n",
       "      <td>40834.000000</td>\n",
       "      <td>40834.000000</td>\n",
       "      <td>40834.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.082750</td>\n",
       "      <td>0.063379</td>\n",
       "      <td>0.074766</td>\n",
       "      <td>0.078415</td>\n",
       "      <td>0.080595</td>\n",
       "      <td>0.072978</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.275507</td>\n",
       "      <td>0.243646</td>\n",
       "      <td>0.263017</td>\n",
       "      <td>0.268827</td>\n",
       "      <td>0.272215</td>\n",
       "      <td>0.260104</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cv0           cv1           cv2           cv3           cv4  \\\n",
       "count  40834.000000  40834.000000  40834.000000  40834.000000  40834.000000   \n",
       "mean       0.082750      0.063379      0.074766      0.078415      0.080595   \n",
       "std        0.275507      0.243646      0.263017      0.268827      0.272215   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "        cv_ensemble    label  \n",
       "count  40834.000000  40834.0  \n",
       "mean       0.072978     -1.0  \n",
       "std        0.260104      0.0  \n",
       "min        0.000000     -1.0  \n",
       "25%        0.000000     -1.0  \n",
       "50%        0.000000     -1.0  \n",
       "75%        0.000000     -1.0  \n",
       "max        1.000000     -1.0  "
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "pred_df.index += len(orig_df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "sample_submit_df['judgement'] = pred_df['cv_ensemble']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "sample_submit_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judgement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27145</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27146</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27147</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27148</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27149</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67974</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67975</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67976</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67977</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67978</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40834 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       judgement\n",
       "27145          0\n",
       "27146          0\n",
       "27147          0\n",
       "27148          0\n",
       "27149          0\n",
       "...          ...\n",
       "67974          0\n",
       "67975          0\n",
       "67976          0\n",
       "67977          0\n",
       "67978          0\n",
       "\n",
       "[40834 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "cv_ensemble_fb_score = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "jst = dt.timezone(dt.timedelta(hours=+9), 'JST')\n",
    "dt_now = dt.datetime.now(jst)\n",
    "dt_now_str = dt_now.strftime('%Y%m%d_%H%M')\n",
    "submit_str = f\"{dt_now_str}_{cv_ensemble_fb_score:.4f}\".replace('.', '-')\n",
    "submit_str = f\"{submit_str}.csv\"\n",
    "print(submit_str)\n",
    "\n",
    "os.makedirs('./submit', exist_ok=True)\n",
    "sample_submit_df.to_csv(os.path.join('submit', submit_str), header=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "20211002_0045_0-0000.csv\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('srws': conda)"
  },
  "interpreter": {
   "hash": "7f2d3241de56b0fa9ccb32ec1dbd92e097a59df5b8abdff3a1f1414152af23a6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}