{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime as dt\n",
    "import copy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1,2,3,4'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class Hparams:\n",
    "    def __init__(self):\n",
    "        self.random_seed = 2021\n",
    "        self.data_dir = './data'\n",
    "        self.output_dir = './outputs'\n",
    "        self.batch_size = 256\n",
    "        self.token_max_length = 256\n",
    "        self.model_name = \"allenai/biomed_roberta_base\"\n",
    "        self.num_epochs = 10\n",
    "        self.class_1_weight = 100\n",
    "\n",
    "hps = Hparams()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def seed_torch(seed:int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(hps.random_seed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataframe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "orig_df = pd.read_csv(os.path.join(hps.data_dir, 'train.csv'), index_col=0)\n",
    "submit_df = pd.read_csv(os.path.join(hps.data_dir, 'test.csv'), index_col=0)\n",
    "sample_submit_df = pd.read_csv(os.path.join(hps.data_dir, 'sample_submit.csv'), index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "orig_df['abstract'].fillna('', inplace=True)\n",
    "orig_df['title_abstract'] = orig_df.title + orig_df.abstract\n",
    "display(orig_df)\n",
    "display(orig_df.isna().sum())"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>judgement</th>\n",
       "      <th>title_abstract</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One-year age changes in MRI brain volumes in o...</td>\n",
       "      <td>Longitudinal studies indicate that declines in...</td>\n",
       "      <td>0</td>\n",
       "      <td>One-year age changes in MRI brain volumes in o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supportive CSF biomarker evidence to enhance t...</td>\n",
       "      <td>The present study was undertaken to validate t...</td>\n",
       "      <td>0</td>\n",
       "      <td>Supportive CSF biomarker evidence to enhance t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n",
       "      <td>Objective: To report a case series in which ba...</td>\n",
       "      <td>0</td>\n",
       "      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New developments in diagnosis and therapy of C...</td>\n",
       "      <td>The etiology and pathogenesis of idiopathic ch...</td>\n",
       "      <td>0</td>\n",
       "      <td>New developments in diagnosis and therapy of C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27140</th>\n",
       "      <td>The amyloidogenic pathway of amyloid precursor...</td>\n",
       "      <td>Amyloid beta-protein (A beta) is the main cons...</td>\n",
       "      <td>0</td>\n",
       "      <td>The amyloidogenic pathway of amyloid precursor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27141</th>\n",
       "      <td>Technologic developments in radiotherapy and s...</td>\n",
       "      <td>We present a review of current technological p...</td>\n",
       "      <td>0</td>\n",
       "      <td>Technologic developments in radiotherapy and s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27142</th>\n",
       "      <td>Novel screening cascade identifies MKK4 as key...</td>\n",
       "      <td>Phosphorylation of Tau at serine 422 promotes ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Novel screening cascade identifies MKK4 as key...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27143</th>\n",
       "      <td>Visualization of the gall bladder on F-18 FDOP...</td>\n",
       "      <td>The ability to label dihydroxyphenylalanine (D...</td>\n",
       "      <td>0</td>\n",
       "      <td>Visualization of the gall bladder on F-18 FDOP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27144</th>\n",
       "      <td>Multidetector CT findings and differential dia...</td>\n",
       "      <td>OBJECTIVE: To compare the multidetector CT (MD...</td>\n",
       "      <td>0</td>\n",
       "      <td>Multidetector CT findings and differential dia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27145 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "id                                                         \n",
       "0      One-year age changes in MRI brain volumes in o...   \n",
       "1      Supportive CSF biomarker evidence to enhance t...   \n",
       "2      Occurrence of basal ganglia germ cell tumors w...   \n",
       "3      New developments in diagnosis and therapy of C...   \n",
       "4      Prolonged shedding of SARS-CoV-2 in an elderly...   \n",
       "...                                                  ...   \n",
       "27140  The amyloidogenic pathway of amyloid precursor...   \n",
       "27141  Technologic developments in radiotherapy and s...   \n",
       "27142  Novel screening cascade identifies MKK4 as key...   \n",
       "27143  Visualization of the gall bladder on F-18 FDOP...   \n",
       "27144  Multidetector CT findings and differential dia...   \n",
       "\n",
       "                                                abstract  judgement  \\\n",
       "id                                                                    \n",
       "0      Longitudinal studies indicate that declines in...          0   \n",
       "1      The present study was undertaken to validate t...          0   \n",
       "2      Objective: To report a case series in which ba...          0   \n",
       "3      The etiology and pathogenesis of idiopathic ch...          0   \n",
       "4                                                                 0   \n",
       "...                                                  ...        ...   \n",
       "27140  Amyloid beta-protein (A beta) is the main cons...          0   \n",
       "27141  We present a review of current technological p...          0   \n",
       "27142  Phosphorylation of Tau at serine 422 promotes ...          0   \n",
       "27143  The ability to label dihydroxyphenylalanine (D...          0   \n",
       "27144  OBJECTIVE: To compare the multidetector CT (MD...          0   \n",
       "\n",
       "                                          title_abstract  \n",
       "id                                                        \n",
       "0      One-year age changes in MRI brain volumes in o...  \n",
       "1      Supportive CSF biomarker evidence to enhance t...  \n",
       "2      Occurrence of basal ganglia germ cell tumors w...  \n",
       "3      New developments in diagnosis and therapy of C...  \n",
       "4      Prolonged shedding of SARS-CoV-2 in an elderly...  \n",
       "...                                                  ...  \n",
       "27140  The amyloidogenic pathway of amyloid precursor...  \n",
       "27141  Technologic developments in radiotherapy and s...  \n",
       "27142  Novel screening cascade identifies MKK4 as key...  \n",
       "27143  Visualization of the gall bladder on F-18 FDOP...  \n",
       "27144  Multidetector CT findings and differential dia...  \n",
       "\n",
       "[27145 rows x 4 columns]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "title             0\n",
       "abstract          0\n",
       "judgement         0\n",
       "title_abstract    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "train_df, test_df = train_test_split(orig_df, test_size=0.2, random_state=hps.random_seed, shuffle=True, stratify=orig_df.judgement)\n",
    "train_df, valid_df = train_test_split(train_df, test_size=0.25, random_state=hps.random_seed, shuffle=True, stratify=train_df.judgement)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "valid_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "print(f\"Train  ->  label_1:{train_df.judgement.sum()} / all:{train_df.judgement.count()}   ({train_df.judgement.sum() / train_df.judgement.count() * 100:.3f}%)\")\n",
    "print(f\"Valid  ->  label_1:{valid_df.judgement.sum()} / all:{valid_df.judgement.count()}   ({valid_df.judgement.sum() / valid_df.judgement.count() * 100:.3f}%)\")\n",
    "print(f\"Test   ->  label_1:{test_df.judgement.sum()} / all:{test_df.judgement.count()}   ({test_df.judgement.sum() / test_df.judgement.count() * 100:.3f}%)\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train  ->  label_1:380 / all:16287   (2.333%)\n",
      "Valid  ->  label_1:126 / all:5429   (2.321%)\n",
      "Test   ->  label_1:126 / all:5429   (2.321%)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BaseModel"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "base_tokenizer = transformers.AutoTokenizer.from_pretrained(hps.model_name)\n",
    "base_model = transformers.AutoModel.from_pretrained(hps.model_name)\n",
    "base_model_config = transformers.AutoConfig.from_pretrained(hps.model_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at allenai/biomed_roberta_base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(base_model_config)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RobertaConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.10.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset / DataLoader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, token_max_length=512):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.title_tokenized = tokenizer.batch_encode_plus(\n",
    "            df.title_abstract.to_list(),\n",
    "            padding = 'max_length',            \n",
    "            max_length = token_max_length,\n",
    "            truncation = True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = dict(\n",
    "            input_ids=self.title_tokenized['input_ids'][idx],\n",
    "            attention_mask=self.title_tokenized['attention_mask'][idx]\n",
    "        )\n",
    "        label = torch.tensor(self.df.loc[idx, 'judgement'], dtype=torch.float32)\n",
    "        return sample, label\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "datasets = {phase:TextClassificationDataset(df={'train': train_df, 'val': valid_df}[phase], tokenizer=base_tokenizer, \\\n",
    "                                            token_max_length=hps.token_max_length) for phase in ['train', 'val']}\n",
    "\n",
    "dataloaders = {phase: DataLoader(datasets[phase], batch_size=hps.batch_size, \\\n",
    "                                 shuffle={'train': True, 'val': False}[phase]) for phase in ['train', 'val']}\n",
    "\n",
    "print(len(datasets['train']), len(datasets['val']))\n",
    "print(len(dataloaders['train']), len(dataloaders['val']))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "16287 5429\n",
      "64 22\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, base_model, hidden_size):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.conv1d_1 = nn.Conv1d(hidden_size, 256, kernel_size=2, padding=1)\n",
    "        self.conv1d_2 = nn.Conv1d(256, 1, kernel_size=2, padding=1)\n",
    "        self.linear = nn.Linear(258, 1)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = out['last_hidden_state'].permute(0, 2, 1)\n",
    "        conv_embed = torch.relu(self.conv1d_1(last_hidden_state))\n",
    "        conv_embed = self.conv1d_2(conv_embed).squeeze()\n",
    "        #out = self.linear(conv_embed).squeeze()\n",
    "        logits = torch.sigmoid(self.linear(conv_embed)).squeeze()\n",
    "        return logits"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "model = TextClassificationModel(base_model=base_model, hidden_size=base_model_config.hidden_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "class ModelCheckpoint:\n",
    "    def __init__(self, save_dir:str, model_name:str):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        self.save_dir = save_dir\n",
    "        self.model_name = model_name\n",
    "        jst = dt.timezone(dt.timedelta(hours=+9), 'JST')\n",
    "        dt_now = dt.datetime.now(jst)\n",
    "        self.dt_now_str = dt_now.strftime('%Y%m%d_%H%M')\n",
    "        self.best_loss = self.best_acc = self.best_fbeta_score = 0.0\n",
    "        self.best_epoch = 0\n",
    "\n",
    "    def get_checkpoint_name(self, epoch):\n",
    "        checkpoint_name = f\"{self.model_name.replace('/', '_')}__epoch{epoch:03}__{self.dt_now_str}.pth\"\n",
    "        checkpoint_name = os.path.join(self.save_dir, checkpoint_name)\n",
    "        return checkpoint_name\n",
    "\n",
    "    def save_checkpoint(self, model, epoch):\n",
    "        torch.save(model.state_dict(), self.get_checkpoint_name(epoch))\n",
    "\n",
    "    def load_checkpoint(self, model=None, epoch=1, manual_name=None):\n",
    "        if manual_name is None:\n",
    "            checkpoint_name = self.get_checkpoint_name(epoch)\n",
    "        else:\n",
    "            checkpoint_name = manual_name\n",
    "        print(checkpoint_name)\n",
    "        model.load_state_dict(torch.load(checkpoint_name))\n",
    "        return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "def fit(dataloaders, model, optimizer, num_epochs, device, batch_size, lr_scheduler):\n",
    "\n",
    "    checkpoint = ModelCheckpoint(save_dir='model_weights', model_name=hps.model_name)\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    print(f\"Using device : {device}\")\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"【 Epoch {epoch+1: 3}/{num_epochs: 3} 】 LR:{optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            running_fbeta_score = 0.0\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            for i, (inputs, labels) in enumerate(tqdm(dataloaders[phase])):\n",
    "                input_ids = inputs['input_ids']\n",
    "                attention_mask = inputs['attention_mask']\n",
    "                input_ids = input_ids.to(device)\n",
    "                attention_mask = attention_mask.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    preds = torch.where(outputs >= 0.5, 1, 0)\n",
    "                    pos_weight = torch.tensor([hps.class_1_weight for i in range(input_ids.size(0))]).to(device)\n",
    "                    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() + input_ids.size(0)\n",
    "                running_corrects += torch.sum(preds == labels)\n",
    "                running_fbeta_score += fbeta_score(labels.to('cpu').detach().numpy(), preds.to('cpu').detach().numpy(), beta=7.0, zero_division=0)                    \n",
    "\n",
    "                if phase == 'train':\n",
    "                    if i % 50 == 49:\n",
    "                        total_num = float((i * batch_size) + input_ids.size(0))\n",
    "                        print(f\"{i+1: 4}/{len(dataloaders[phase]): 4}  <{phase}> Loss:{(running_loss/(i+1)):.4f}  Acc:{(running_corrects/total_num):.4f}  fbScore:{(running_fbeta_score/(i+1)):.4f}\")\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase])\n",
    "            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n",
    "            epoch_fbscore = running_fbeta_score / len(dataloaders[phase])\n",
    "            \n",
    "            print(f\"<{phase}> Loss:{epoch_loss:.4f}  Acc:{epoch_acc:.4f}  fbScore:{epoch_fbscore:.4f}\")\n",
    "\n",
    "            if phase == 'val' and epoch_fbscore > checkpoint.best_fbeta_score:\n",
    "                checkpoint.best_loss = epoch_loss\n",
    "                checkpoint.best_acc = epoch_acc\n",
    "                checkpoint.best_fbeta_score = epoch_fbscore\n",
    "                checkpoint.best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        lr_scheduler.step()\n",
    "        print('-' * 150)\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    checkpoint.save_checkpoint(model, epoch)\n",
    "\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "device_num = torch.cuda.device_count()\n",
    "if device_num > 1:\n",
    "    print(f\"Use {device_num} GPUs\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
    "\n",
    "model = fit(dataloaders=dataloaders, model=model,\n",
    "              optimizer=optimizer, num_epochs=hps.num_epochs, device=device, batch_size=hps.batch_size, lr_scheduler=exp_lr_scheduler)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Use 4 GPUs\n",
      "Using device : cuda\n",
      "【 Epoch   1/ 10 】 LR:2e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "31c17e1fd6434be9816ac2ac3ac6dadc"
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  50/  64  <train> Loss:257.9182  Acc:0.1965  fbScore:0.5530\n",
      "<train> Loss:256.3665  Acc:0.3228  fbScore:0.5975\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f974c5fa65d54962aff631c708e8289d"
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:248.3887  Acc:0.8342  fbScore:0.7491\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【 Epoch   2/ 10 】 LR:1.9e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "022c405c11fe46e4bf08f7030216e5be"
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  50/  64  <train> Loss:257.6028  Acc:0.8479  fbScore:0.7873\n",
      "<train> Loss:256.0711  Acc:0.8564  fbScore:0.7918\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff253e0467194699a621ac6a6515feff"
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:248.3708  Acc:0.9114  fbScore:0.7546\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【 Epoch   3/ 10 】 LR:1.805e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe2f6f9e9b4c4737bdec751238d22792"
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  50/  64  <train> Loss:257.5381  Acc:0.8743  fbScore:0.8218\n",
      "<train> Loss:256.0292  Acc:0.8805  fbScore:0.8293\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "032c06850bc34ccda4b4bcd46eff3055"
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:248.3125  Acc:0.8589  fbScore:0.8121\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【 Epoch   4/ 10 】 LR:1.71475e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fff29997e1114c9bbb639525168f4dca"
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  50/  64  <train> Loss:257.5431  Acc:0.8984  fbScore:0.8208\n",
      "<train> Loss:256.0348  Acc:0.8585  fbScore:0.8107\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae2175c6ef8a4c08b722c750d1a70087"
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:248.3236  Acc:0.8574  fbScore:0.7932\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【 Epoch   5/ 10 】 LR:1.6290125e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "867d56042a8144bf8aa73f6008a9366c"
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  50/  64  <train> Loss:257.5090  Acc:0.8727  fbScore:0.8302\n",
      "<train> Loss:256.0186  Acc:0.8827  fbScore:0.8398\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68a998e6e47e4bcbbe6cd632ac04df23"
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:248.3575  Acc:0.9011  fbScore:0.7792\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【 Epoch   6/ 10 】 LR:1.547561875e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2e60d29f8c747efbffc547d7e966243"
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  50/  64  <train> Loss:257.4661  Acc:0.9063  fbScore:0.8678\n",
      "<train> Loss:255.9934  Acc:0.9114  fbScore:0.8715\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8cd97104af2c4e17aa1d28619afb4b77"
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:248.3236  Acc:0.8418  fbScore:0.7886\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【 Epoch   7/ 10 】 LR:1.47018378125e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e89e1a1812b046689433484f2ee35fca"
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  50/  64  <train> Loss:257.5669  Acc:0.7866  fbScore:0.8194\n",
      "<train> Loss:256.0278  Acc:0.8192  fbScore:0.8147\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e00ebc6eaddf4c7888f1e18d5b3ef125"
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:248.2885  Acc:0.8996  fbScore:0.8432\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【 Epoch   8/ 10 】 LR:1.3966745921874999e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2029408b3c8f40b1954a29b8ccaea7fa"
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  50/  64  <train> Loss:257.4816  Acc:0.9217  fbScore:0.8935\n",
      "<train> Loss:255.9778  Acc:0.8944  fbScore:0.8771\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9757bc2b7bb541daa7d0ed384e1b3d6e"
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:248.3036  Acc:0.8178  fbScore:0.8178\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【 Epoch   9/ 10 】 LR:1.3268408625781248e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e39d871b87543988c3655b033143b35"
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  50/  64  <train> Loss:257.4672  Acc:0.9186  fbScore:0.9013\n",
      "<train> Loss:255.9653  Acc:0.9244  fbScore:0.9071\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "15d158a8a3e24d1abdeb4797f8a60e98"
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:248.2867  Acc:0.9234  fbScore:0.8514\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【 Epoch  10/ 10 】 LR:1.2604988194492186e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b8c25f8e43742c1a7316020942dedca"
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  50/  64  <train> Loss:257.5364  Acc:0.8935  fbScore:0.8895\n",
      "<train> Loss:255.9668  Acc:0.9042  fbScore:0.8934\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "597aacbf42e0473ab5b065e6453a61be"
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:248.2796  Acc:0.9344  fbScore:0.8498\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('srws': conda)"
  },
  "interpreter": {
   "hash": "7f2d3241de56b0fa9ccb32ec1dbd92e097a59df5b8abdff3a1f1414152af23a6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}