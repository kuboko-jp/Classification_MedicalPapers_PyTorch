{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1,2,3,4'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class Hparams:\n",
    "    def __init__(self):\n",
    "        self.random_seed = 2021\n",
    "        self.data_dir = './data'\n",
    "        self.output_dir = './outputs'\n",
    "        self.batch_size = 128\n",
    "        self.token_max_length = 256\n",
    "        self.model_name = \"allenai/biomed_roberta_base\"\n",
    "        self.num_epochs = 10\n",
    "        self.class_1_weight = 49.0\n",
    "\n",
    "hps = Hparams()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def seed_torch(seed:int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(hps.random_seed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataframe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "orig_df = pd.read_csv(os.path.join(hps.data_dir, 'train.csv'), index_col=0)\n",
    "submit_df = pd.read_csv(os.path.join(hps.data_dir, 'test.csv'), index_col=0)\n",
    "sample_submit_df = pd.read_csv(os.path.join(hps.data_dir, 'sample_submit.csv'), index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "orig_df['abstract'].fillna('', inplace=True)\n",
    "orig_df['title_abstract'] = orig_df.title + orig_df.abstract\n",
    "display(orig_df)\n",
    "display(orig_df.isna().sum())"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>judgement</th>\n",
       "      <th>title_abstract</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One-year age changes in MRI brain volumes in o...</td>\n",
       "      <td>Longitudinal studies indicate that declines in...</td>\n",
       "      <td>0</td>\n",
       "      <td>One-year age changes in MRI brain volumes in o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supportive CSF biomarker evidence to enhance t...</td>\n",
       "      <td>The present study was undertaken to validate t...</td>\n",
       "      <td>0</td>\n",
       "      <td>Supportive CSF biomarker evidence to enhance t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n",
       "      <td>Objective: To report a case series in which ba...</td>\n",
       "      <td>0</td>\n",
       "      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New developments in diagnosis and therapy of C...</td>\n",
       "      <td>The etiology and pathogenesis of idiopathic ch...</td>\n",
       "      <td>0</td>\n",
       "      <td>New developments in diagnosis and therapy of C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27140</th>\n",
       "      <td>The amyloidogenic pathway of amyloid precursor...</td>\n",
       "      <td>Amyloid beta-protein (A beta) is the main cons...</td>\n",
       "      <td>0</td>\n",
       "      <td>The amyloidogenic pathway of amyloid precursor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27141</th>\n",
       "      <td>Technologic developments in radiotherapy and s...</td>\n",
       "      <td>We present a review of current technological p...</td>\n",
       "      <td>0</td>\n",
       "      <td>Technologic developments in radiotherapy and s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27142</th>\n",
       "      <td>Novel screening cascade identifies MKK4 as key...</td>\n",
       "      <td>Phosphorylation of Tau at serine 422 promotes ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Novel screening cascade identifies MKK4 as key...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27143</th>\n",
       "      <td>Visualization of the gall bladder on F-18 FDOP...</td>\n",
       "      <td>The ability to label dihydroxyphenylalanine (D...</td>\n",
       "      <td>0</td>\n",
       "      <td>Visualization of the gall bladder on F-18 FDOP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27144</th>\n",
       "      <td>Multidetector CT findings and differential dia...</td>\n",
       "      <td>OBJECTIVE: To compare the multidetector CT (MD...</td>\n",
       "      <td>0</td>\n",
       "      <td>Multidetector CT findings and differential dia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27145 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "id                                                         \n",
       "0      One-year age changes in MRI brain volumes in o...   \n",
       "1      Supportive CSF biomarker evidence to enhance t...   \n",
       "2      Occurrence of basal ganglia germ cell tumors w...   \n",
       "3      New developments in diagnosis and therapy of C...   \n",
       "4      Prolonged shedding of SARS-CoV-2 in an elderly...   \n",
       "...                                                  ...   \n",
       "27140  The amyloidogenic pathway of amyloid precursor...   \n",
       "27141  Technologic developments in radiotherapy and s...   \n",
       "27142  Novel screening cascade identifies MKK4 as key...   \n",
       "27143  Visualization of the gall bladder on F-18 FDOP...   \n",
       "27144  Multidetector CT findings and differential dia...   \n",
       "\n",
       "                                                abstract  judgement  \\\n",
       "id                                                                    \n",
       "0      Longitudinal studies indicate that declines in...          0   \n",
       "1      The present study was undertaken to validate t...          0   \n",
       "2      Objective: To report a case series in which ba...          0   \n",
       "3      The etiology and pathogenesis of idiopathic ch...          0   \n",
       "4                                                                 0   \n",
       "...                                                  ...        ...   \n",
       "27140  Amyloid beta-protein (A beta) is the main cons...          0   \n",
       "27141  We present a review of current technological p...          0   \n",
       "27142  Phosphorylation of Tau at serine 422 promotes ...          0   \n",
       "27143  The ability to label dihydroxyphenylalanine (D...          0   \n",
       "27144  OBJECTIVE: To compare the multidetector CT (MD...          0   \n",
       "\n",
       "                                          title_abstract  \n",
       "id                                                        \n",
       "0      One-year age changes in MRI brain volumes in o...  \n",
       "1      Supportive CSF biomarker evidence to enhance t...  \n",
       "2      Occurrence of basal ganglia germ cell tumors w...  \n",
       "3      New developments in diagnosis and therapy of C...  \n",
       "4      Prolonged shedding of SARS-CoV-2 in an elderly...  \n",
       "...                                                  ...  \n",
       "27140  The amyloidogenic pathway of amyloid precursor...  \n",
       "27141  Technologic developments in radiotherapy and s...  \n",
       "27142  Novel screening cascade identifies MKK4 as key...  \n",
       "27143  Visualization of the gall bladder on F-18 FDOP...  \n",
       "27144  Multidetector CT findings and differential dia...  \n",
       "\n",
       "[27145 rows x 4 columns]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "title             0\n",
       "abstract          0\n",
       "judgement         0\n",
       "title_abstract    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "train_df, test_df = train_test_split(orig_df, test_size=0.2, random_state=hps.random_seed, shuffle=True, stratify=orig_df.judgement)\n",
    "train_df, valid_df = train_test_split(train_df, test_size=0.25, random_state=hps.random_seed, shuffle=True, stratify=train_df.judgement)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "valid_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "print(f\"Train  ->  label_1:{train_df.judgement.sum()} / all:{train_df.judgement.count()}   ({train_df.judgement.sum() / train_df.judgement.count() * 100:.3f}%)\")\n",
    "print(f\"Valid  ->  label_1:{valid_df.judgement.sum()} / all:{valid_df.judgement.count()}   ({valid_df.judgement.sum() / valid_df.judgement.count() * 100:.3f}%)\")\n",
    "print(f\"Test   ->  label_1:{test_df.judgement.sum()} / all:{test_df.judgement.count()}   ({test_df.judgement.sum() / test_df.judgement.count() * 100:.3f}%)\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train  ->  label_1:380 / all:16287   (2.333%)\n",
      "Valid  ->  label_1:126 / all:5429   (2.321%)\n",
      "Test   ->  label_1:126 / all:5429   (2.321%)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BaseModel"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "base_tokenizer = transformers.AutoTokenizer.from_pretrained(hps.model_name)\n",
    "base_model = transformers.AutoModel.from_pretrained(hps.model_name)\n",
    "base_model_config = transformers.AutoConfig.from_pretrained(hps.model_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at allenai/biomed_roberta_base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(base_model_config)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RobertaConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.10.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset / DataLoader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, token_max_length=512):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.title_tokenized = tokenizer.batch_encode_plus(\n",
    "            df.title_abstract.to_list(),\n",
    "            padding = 'max_length',            \n",
    "            max_length = token_max_length,\n",
    "            truncation = True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = dict(\n",
    "            input_ids=self.title_tokenized['input_ids'][idx],\n",
    "            attention_mask=self.title_tokenized['attention_mask'][idx]\n",
    "        )\n",
    "        label = torch.tensor(self.df.loc[idx, 'judgement'], dtype=torch.float32)\n",
    "        return sample, label\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "datasets = {phase:TextClassificationDataset(df={'train': train_df, 'val': valid_df}[phase], tokenizer=base_tokenizer, \\\n",
    "                                            token_max_length=hps.token_max_length) for phase in ['train', 'val']}\n",
    "\n",
    "dataloaders = {phase: DataLoader(datasets[phase], batch_size=hps.batch_size, \\\n",
    "                                 shuffle={'train': True, 'val': False}[phase]) for phase in ['train', 'val']}\n",
    "\n",
    "print(len(datasets['train']), len(datasets['val']))\n",
    "print(len(dataloaders['train']), len(dataloaders['val']))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "16287 5429\n",
      "128 43\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, base_model, hidden_size):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.conv1d_1 = nn.Conv1d(hidden_size, 256, kernel_size=2, padding=1)\n",
    "        self.conv1d_2 = nn.Conv1d(256, 1, kernel_size=2, padding=1)\n",
    "        self.linear = nn.Linear(258, 1)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = out['last_hidden_state'].permute(0, 2, 1)\n",
    "        conv_embed = torch.relu(self.conv1d_1(last_hidden_state))\n",
    "        conv_embed = self.conv1d_2(conv_embed).squeeze()\n",
    "        #out = self.linear(conv_embed).squeeze()\n",
    "        logits = torch.sigmoid(self.linear(conv_embed)).squeeze()\n",
    "        return logits\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "model = TextClassificationModel(base_model=base_model, hidden_size=base_model_config.hidden_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "inputs, labels = next(iter(dataloaders['train']))\n",
    "outputs = model(inputs['input_ids'], inputs['attention_mask'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def fit(dataloaders, model, optimizer, num_epochs, device, batch_size, lr_scheduler):\n",
    "\n",
    "    print(f\"Using device : {device}\")\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"【 Epoch {epoch+1: 3}/{num_epochs: 3} 】 LR:{optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            running_fbeta_score = 0.0\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            for i, (inputs, labels) in enumerate(tqdm(dataloaders[phase])):\n",
    "                input_ids = inputs['input_ids']\n",
    "                attention_mask = inputs['attention_mask']\n",
    "                input_ids = input_ids.to(device)\n",
    "                attention_mask = attention_mask.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    preds = torch.where(outputs >= 0.5, 1, 0)\n",
    "                    pos_weight = torch.tensor([hps.class_1_weight for i in range(input_ids.size(0))]).to(device)\n",
    "                    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() + input_ids.size(0)\n",
    "                running_corrects += torch.sum(preds == labels)\n",
    "                running_fbeta_score += fbeta_score(labels.to('cpu').detach().numpy(), preds.to('cpu').detach().numpy(), beta=7.0, zero_division=0)                    \n",
    "\n",
    "                if phase == 'train':\n",
    "                    if i % 50 == 49:\n",
    "                        total_num = float((i * batch_size) + input_ids.size(0))\n",
    "                        print(f\"{i+1: 4}/{len(dataloaders[phase]): 4}  <{phase}> Loss:{(running_loss/(i+1)):.4f}  Acc:{(running_corrects/total_num):.4f}  fbScore:{(running_fbeta_score/(i+1)):.4f}\")\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase])\n",
    "            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n",
    "            epoch_fbscore = running_fbeta_score / len(dataloaders[phase])\n",
    "            \n",
    "            print(f\"<{phase}> Loss:{epoch_loss:.4f}  Acc:{epoch_acc:.4f}  fbScore:{epoch_fbscore:.4f}\")\n",
    "\n",
    "        lr_scheduler.step()\n",
    "        print('-' * 150)\n",
    "\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "device_num = torch.cuda.device_count()\n",
    "if device_num > 1:\n",
    "    print(f\"Use {device_num} GPUs\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
    "\n",
    "model = fit(dataloaders=dataloaders, model=model,\n",
    "              optimizer=optimizer, num_epochs=hps.num_epochs, device=device, batch_size=hps.batch_size, lr_scheduler=exp_lr_scheduler)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Use 4 GPUs\n",
      "Using device : cuda\n",
      "【 Epoch   1/ 10 】 LR:2e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92aa8662eb2340c98e28bdda9a2b6cea"
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  50/ 128  <train> Loss:129.3948  Acc:0.9402  fbScore:0.2400\n",
      " 100/ 128  <train> Loss:129.3037  Acc:0.9127  fbScore:0.4205\n",
      "<train> Loss:128.5289  Acc:0.9023  fbScore:0.4801\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eead5bc7c24645e180f8302a793aaae8"
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:127.4209  Acc:0.9096  fbScore:0.7063\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【 Epoch   2/ 10 】 LR:1.9e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eaf1053a9aa24c9a89629719348d98fb"
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  50/ 128  <train> Loss:129.1714  Acc:0.8681  fbScore:0.7001\n",
      " 100/ 128  <train> Loss:129.1786  Acc:0.9027  fbScore:0.6862\n",
      "<train> Loss:128.4144  Acc:0.8953  fbScore:0.6857\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4a953dd956d43219220da987a7d8550"
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:127.4099  Acc:0.8950  fbScore:0.7242\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【 Epoch   3/ 10 】 LR:1.805e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "15b73cf829c64f7ebbfa80f2c71c44de"
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  50/ 128  <train> Loss:129.1291  Acc:0.9361  fbScore:0.8096\n",
      " 100/ 128  <train> Loss:129.1505  Acc:0.8938  fbScore:0.7705\n",
      "<train> Loss:128.4116  Acc:0.8972  fbScore:0.7388\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8bab4cd8a27b4190834be4df44e2e367"
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:127.4078  Acc:0.8871  fbScore:0.7243\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【 Epoch   4/ 10 】 LR:1.71475e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "edd53b2457854c6d98a15db1741ed6b4"
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  50/ 128  <train> Loss:129.1602  Acc:0.9102  fbScore:0.6815\n",
      " 100/ 128  <train> Loss:129.1594  Acc:0.9186  fbScore:0.7140\n",
      "<train> Loss:128.3909  Acc:0.9215  fbScore:0.7294\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "743411ef25e94d9ea7e83be9dba872b6"
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:127.4231  Acc:0.8497  fbScore:0.7211\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【 Epoch   5/ 10 】 LR:1.6290125e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3be1799bcb974397ab8244294044bab7"
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  50/ 128  <train> Loss:129.1451  Acc:0.9347  fbScore:0.7805\n",
      " 100/ 128  <train> Loss:129.1164  Acc:0.9365  fbScore:0.7850\n",
      "<train> Loss:128.3863  Acc:0.9414  fbScore:0.7571\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a04bb6d425514bd188f927a30731d496"
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:127.4285  Acc:0.9431  fbScore:0.6766\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【 Epoch   6/ 10 】 LR:1.547561875e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cef639fd9b94446681e66ccce6f418c6"
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  50/ 128  <train> Loss:129.1164  Acc:0.9628  fbScore:0.6950\n",
      " 100/ 128  <train> Loss:129.1196  Acc:0.9425  fbScore:0.7447\n",
      "<train> Loss:128.3743  Acc:0.9447  fbScore:0.7569\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "98f505ed8e514e6985c456c1f17cd9b3"
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:127.4249  Acc:0.9576  fbScore:0.6680\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【 Epoch   7/ 10 】 LR:1.47018378125e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ace5a38c9ff478ab66d27a14a9b3e18"
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  50/ 128  <train> Loss:129.2011  Acc:0.9703  fbScore:0.8002\n",
      " 100/ 128  <train> Loss:129.1328  Acc:0.9601  fbScore:0.8136\n",
      "<train> Loss:128.3679  Acc:0.9542  fbScore:0.7986\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a09bb2fcef147e197b324e32800e38f"
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:127.4061  Acc:0.8838  fbScore:0.7400\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【 Epoch   8/ 10 】 LR:1.3966745921874999e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2d60ccde4224601a700c6bfb9404e5b"
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  50/ 128  <train> Loss:129.1215  Acc:0.9520  fbScore:0.8127\n",
      " 100/ 128  <train> Loss:129.1148  Acc:0.9477  fbScore:0.8159\n",
      "<train> Loss:128.3601  Acc:0.9451  fbScore:0.8129\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d5203e370e1d4ce0b531cfdc92430841"
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:127.4063  Acc:0.9569  fbScore:0.7020\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【 Epoch   9/ 10 】 LR:1.3268408625781248e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d56b8c75f5c42d68f54314be05749bb"
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  50/ 128  <train> Loss:129.0746  Acc:0.9461  fbScore:0.8454\n",
      " 100/ 128  <train> Loss:129.1000  Acc:0.9482  fbScore:0.8415\n",
      "<train> Loss:128.3501  Acc:0.9517  fbScore:0.8362\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ea293c664f749eab8ff862b22b42f54"
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:127.4084  Acc:0.9438  fbScore:0.6974\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "【 Epoch  10/ 10 】 LR:1.2604988194492186e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b89aa91c027f4560b2cf77f20fe43bcc"
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  50/ 128  <train> Loss:129.1219  Acc:0.9492  fbScore:0.7615\n",
      " 100/ 128  <train> Loss:129.1415  Acc:0.9430  fbScore:0.8103\n",
      "<train> Loss:128.3590  Acc:0.9452  fbScore:0.7958\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c5a1f6053064b71b3fb569512ed2aef"
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<val> Loss:127.4197  Acc:0.9379  fbScore:0.6838\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('srws': conda)"
  },
  "interpreter": {
   "hash": "7f2d3241de56b0fa9ccb32ec1dbd92e097a59df5b8abdff3a1f1414152af23a6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}